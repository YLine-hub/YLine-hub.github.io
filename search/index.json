[{"content":"前置环境 Sublime Test 已安装 破解sublime test 4169（2025-11-29 已失效） 修改十六进制数据 找到SublimeText.app 执行程序 sublime_text\n打开十六进制在线编辑工具\n浏览器打开在线编辑工具： https://hexed.it/ 。\n将执行程序sublime_txt拖入在线编辑工具中 搜索十六进制码80 78 05 00 0F 94 C1 输入进制码，数据类型中仅勾选“十六进制数值”， 搜索方案勾选“列出全部匹配项”，然后点击“立即搜索”，可以看到下方搜索结果以及编辑区域匹配的进制码信息。\n替换为C6 40 05 01 48 85 C9 将替换后的信息，另存为到 Mac 上，注意保存时的名称为 sublime_text , 与原程序一致。\n将步骤6中保存的文件，覆盖原文件。\n使用终端命令进行复制, 打开终端执行以下命令，赋予sublime_text权限\n1 2 cd /Applications/Sublime\\ Text.app/Contents/MacOS/ sudo chmod 775 sublime_text 重签认证 打开终端\n使用codesign命令对SublimeText.app应用进行重签名。 提示“replacing existing signature”，即表明成功。\n1 sudo codesign --force --deep --sign - /Applications/Sublime\\ Text.app 使用xatrr 命令将应用com.apple.quarantine属性移除 1 sudo xattr -rd com.apple.quarantine /Applications/Sublime\\ Text.app 右键文件，打开，然后选择打开 使用sublime Text远程服务器步骤 打开Package Control 按下command + shift +p，输入Install Package\n在出现的输入框中输入sftp并点击安装\n重启后就会在File中出现SFTP/FTP\n点击SFTP/FTP -\u0026gt; Setup Server...\n配置远程服务器相关信息\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 { // The tab key will cycle through the settings when first created // Visit https://codexns.io/products/sftp_for_subime/settings for help // sftp, ftp or ftps \u0026#34;type\u0026#34;: \u0026#34;sftp\u0026#34;, \u0026#34;sync_down_on_open\u0026#34;: true, \u0026#34;sync_same_age\u0026#34;: true, \u0026#34;host\u0026#34;: \u0026#34;172.16.140.111\u0026#34;, // 远程服务器ip或者域名 \u0026#34;user\u0026#34;: \u0026#34;root\u0026#34;, // 登陆的用户名 \u0026#34;password\u0026#34;: \u0026#34;123456\u0026#34;, // 登陆密码或者用\u0026#34;ssh_key_file\u0026#34; \u0026#34;port\u0026#34;: \u0026#34;22\u0026#34;, // 连接的端口号 \u0026#34;remote_path\u0026#34;: \u0026#34;/\u0026#34;, // 远程连接的目录 //\u0026#34;file_permissions\u0026#34;: \u0026#34;664\u0026#34;, //\u0026#34;dir_permissions\u0026#34;: \u0026#34;775\u0026#34;, //\u0026#34;extra_list_connections\u0026#34;: 0, \u0026#34;connect_timeout\u0026#34;: 30, // 连接超时时间 //\u0026#34;keepalive\u0026#34;: 120, //\u0026#34;ftp_passive_mode\u0026#34;: true, //\u0026#34;ftp_obey_passive_host\u0026#34;: false, //\u0026#34;ssh_key_file\u0026#34;: \u0026#34;~/.ssh/id_rsa\u0026#34;, //\u0026#34;sftp_sudo\u0026#34;: false, //\u0026#34;sftp_debug\u0026#34;: false, //\u0026#34;sftp_flags\u0026#34;: [\u0026#34;-F\u0026#34;, \u0026#34;/path/to/ssh_config\u0026#34;], //\u0026#34;preserve_modification_times\u0026#34;: false, //\u0026#34;remote_time_offset_in_hours\u0026#34;: 0, //\u0026#34;remote_encoding\u0026#34;: \u0026#34;utf-8\u0026#34;, //\u0026#34;remote_locale\u0026#34;: \u0026#34;C\u0026#34;, //\u0026#34;allow_config_upload\u0026#34;: false, } 保存并命名\n远程连接，选择相应的文件\n对文件进行相应操作 点击Edit ","date":"2025-11-28T15:30:38+08:00","permalink":"https://YLine-hub.github.io/p/mac%E4%BD%BF%E7%94%A8sublime-test-2%E8%BF%9E%E6%8E%A5%E8%BF%9C%E7%A8%8B%E6%9C%8D%E5%8A%A1%E5%99%A8/","title":"[Mac]使用Sublime Test 2连接远程服务器"},{"content":"使用VSCode通过Remote-SSH连接远程服务器 前置环境 Visual Studio Code 已安装 步骤 安装 Remote-SSH 插件 启动 Remote-SSH 连接 点击左下角的open a remote window 在弹出的菜单中，选择Connect to Host 添加新的 SSH 主机 点击Add New SSH Host... 输入 SSH 连接命令 1 ssh root@172.16.140.111 如果服务器使用的是自定义端口（如 2200），需要指定端口 1 ssh root@172.16.140.111 -p 2200 选择 SSH 配置文件位置 建议选择默认的 SSH 配置文件\n连接远程主机 点击左下角的open a remote window 在弹出的菜单选择添加的主机 在弹出来的窗口中输入密码 ","date":"2025-11-28T04:37:57+08:00","permalink":"https://YLine-hub.github.io/p/mac%E4%BD%BF%E7%94%A8vscode%E9%80%9A%E8%BF%87remote-ssh%E8%BF%9E%E6%8E%A5%E8%BF%9C%E7%A8%8B%E6%9C%8D%E5%8A%A1%E5%99%A8/","title":"[Mac]使用VSCode通过Remote-SSH连接远程服务器"},{"content":"","date":"2025-11-27T23:07:46+08:00","permalink":"https://YLine-hub.github.io/p/mysqlshardingsphere5%E5%AE%9E%E6%88%98/","title":"[MySQL]ShardingSphere5实战"},{"content":"MySQL运维-分库分表 介绍 问题分析 随着互联网及移动互联网的发展，应用系统的数据量也是成指数式增长，若采用单数据库进行数据存储，存在以下性能瓶颈:\nIO瓶颈:热点数据太多，数据库缓存不足，产生大量磁盘IO，效率较低。 请求数据太多，带宽 不够，网络IO瓶颈。 CPU瓶颈:排序、分组、连接查询、聚合统计等SQL会耗费大量的CPU资源，请求数太多，CPU出 现瓶颈。 为了解决上述问题，我们需要对数据库进行分库分表处理。\n分库分表的中心思想都是将数据分散存储，使得单一数据库/表的数据量变小来缓解单一数据库的性能 问题，从而达到提升数据库性能的目的。\n拆分策略 分库分表的形式，主要是两种:垂直拆分和水平拆分。而拆分的粒度，一般又分为分库和分表，所以组成的拆分策略最终如下:\n垂直拆分 垂直分库 垂直分库:以表为依据，根据业务将不同表拆分到不同库中。\n特点:\n每个库的表结构都不一样。 每个库的数据也不一样。 所有库的并集是全量数据。 垂直分表 垂直分表:以字段为依据，根据字段属性将不同字段拆分到不同表中。 特点:\n每个表的结构都不一样。 每个表的数据也不一样，一般通过一列(主键/外键)关联。 所有表的并集是全量数据。 水平拆分 水平分库 水平分库:以字段为依据，按照一定策略，将一个库的数据拆分到多个库中。\n特点:\n每个库的表结构都一样。 每个库的数据都不一样。 所有库的并集是全量数据。 水平分表 水平分表:以字段为依据，按照一定策略，将一个表的数据拆分到多个表中。\n特点:\n每个表的表结构都一样。 每个表的数据都不一样。 所有表的并集是全量数据。 在业务系统中，为了缓解磁盘IO及CPU的性能瓶颈，到底是垂直拆分，还是水平拆分;具体是分库，还是分表，都需要根据具体的业务需求具体分析。\n实现技术 shardingJDBC : 基于AOP原理，在应用程序中对本地执行的SQL进行拦截，解析、改写、路由处理。需要自行编码配置实现，只支持java语言，性能较高。 MyCat : 数据库分库分表中间件，不用调整代码即可实现分库分表，支持多种语言，性能不及前者。 本次课程，我们选择了是MyCat数据库中间件，通过MyCat中间件来完成分库分表操作。\nMyCat概述 介绍 Mycat是开源的、活跃的、基于Java语言编写的MySQL数据库中间件。可以像使用mysql一样来使用mycat，对于开发人员来说根本感觉不到mycat的存在。\n开发人员只需要连接MyCat即可，而具体底层用到几台数据库，每一台数据库服务器里面存储了什么数据，都无需关心。具体的分库分表的策略，只需要在MyCat中配置即可。\n优势:\n性能可靠稳定 强大的技术团队 体系完善 社区活跃 下载 下载地址：MyCat\n安装 Mycat是采用java语言开发的开源的数据库中间件，支持Windows和Linux运行环境，下面介绍MyCat的Linux中的环境搭建。我们需要在准备好的服务器中安装如下软件。\nMySQL JDK Mycat 服务器 安装软件 说明 172.16.140.111 JDK、MyCat MyCat中间件服务器 172.16.140.111 MySQL 分片服务器 172.16.140.112 MySQL 分片服务器 172.16.140.113 MySQL 分片服务器 JDK安装 上传安装包 使用ssh自带的上传工具将jdk的二进制发布包上传到Linux\n1 scp jdk-8u461-linux-aarch64.tar.gz root@172.16.140.111:/opt 由于上述在进行文件上传时，选择的上传目录为根目录 /opt，上传完毕后，我们执行指令 cd /opt 切换到根目录下，查看上传的安装包。\n解压安装包 执行如下指令，将上传上来的压缩包进行解压，并通过-C参数指定解压文件存放目录为 /usr/local。\n1 tar -zxvf jdk-8u461-linux-aarch64.tar.gz -C /usr/local/ 配置环境变量 使用vim命令修改/etc/profile文件，在文件末尾加入如下配置\n1 2 JAVA_HOME=/usr/local/jdk1.8.0_461 PATH=$JAVA_HOME/bin:$PATH 具体操作指令如下:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 1). 编辑/etc/profile文件，进入命令模式 vim /etc/profile 2). 在命令模式中，输入指令 G ， 切换到文件最后 G 3). 在命令模式中输入 i/a/o 进入插入模式，然后切换到文件最后一行 i 4). 将上述的配置拷贝到文件中 export JAVA_HOME=/usr/local/jdk1.8.0_171 export PATH=$JAVA_HOME/bin:$PATH 5). 从插入模式，切换到指令模式 ESC 6). 按:进入底行模式，然后输入wq，回车保存 :wq 重新加载profile文件 为了使更改的配置立即生效，需要重新加载profile文件，执行命令:\n1 source /etc/profile 检查安装是否成功 1 java -version MyCat安装 上传Mycat压缩包到服务器 1 2 scp Mycat-server-1.6.7.3-release-20210913163959-linux.tar.gz root@172.16.140.1 11:/opt 解压MyCat的压缩包 1 tar -zxvf Mycat-server-1.6.7.3-release-20210913163959-linux.tar.gz -C /usr/local/ 进入 /usr/local/mycat/lib 目录 1 cd /usr/local/mycat/lib 将 mysql-connector-java-5.1.35.jar 替换成 mysql-connector-java-8.0+ 版本 设置权限 1 chmod 777 mysql-connector-java-8.0.22.jar 目录介绍 bin : 存放可执行文件，用于启动停止mycat conf : 存放mycat的配置文件 lib : 存放mycat的项目依赖包(jar) logs : 存放mycat的日志文件 概念介绍 在MyCat的整体结构中，分为两个部分:上面的逻辑结构、下面的物理结构。\n在MyCat的逻辑结构主要负责逻辑库、逻辑表、分片规则、分片节点等逻辑结构的处理，而具体的数据 存储还是在物理结构，也就是数据库服务器中存储的。\n在后面讲解MyCat入门以及MyCat分片时，还会讲到上面所提到的概念。\nMyCat入门 需求 由于 tb_order 表中数据量很大，磁盘IO及容量都到达了瓶颈，现在需要对 tb_order 表进行数 据分片，分为三个数据节点，每一个节点主机位于不同的服务器上, 具体的结构，参考下图:\n环境准备 测试环境 arm64 centos7 虚拟机：3台 mysql：mysql-8.0.26-1.el7.aarch64.rpm-bundle.tar jdk：jdk-8u171-linux-arm64-vfp-hflt.tar.gz Mycat：Mycat-server-1.6.7.3-release-20210913163959-linux.tar.gz wrapper：wrapper-linux-armhf-64-3.5.40.tar.gz 相关下载直链 mysql：mysql-download jdk：jdk1.8_171 Mycat：Mycat-Server-releases wrapper：wrapper-3.5.40 3台服务器 172.16.140.111:MyCat中间件服务器，同时也是第一个分片服务器。 172.16.140.112:第二个分片服务器。 172.16.140.114:第三个分片服务器。 并且在上述3台数据库中创建数据库 db01 。\n1 create database db01; 配置 1). mycat/conf/schema.xml 在schema.xml中配置逻辑库、逻辑表、数据节点、节点主机等相关信息。具体的配置如下:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 \u0026lt;?xml version=\u0026#34;1.0\u0026#34;?\u0026gt; \u0026lt;!DOCTYPE mycat:schema SYSTEM \u0026#34;schema.dtd\u0026#34;\u0026gt; \u0026lt;mycat:schema xmlns:mycat=\u0026#34;http://io.mycat/\u0026#34;\u0026gt; \u0026lt;schema name=\u0026#34;DB01\u0026#34; checkSQLschema=\u0026#34;true\u0026#34; sqlMaxLimit=\u0026#34;100\u0026#34;\u0026gt; \u0026lt;table name=\u0026#34;TB_ORDER\u0026#34; dataNode=\u0026#34;dn1,dn2,dn3\u0026#34; rule=\u0026#34;auto-sharding-long\u0026#34; /\u0026gt; \u0026lt;/schema\u0026gt; \u0026lt;dataNode name=\u0026#34;dn1\u0026#34; dataHost=\u0026#34;dhost1\u0026#34; database=\u0026#34;db01\u0026#34; /\u0026gt; \u0026lt;dataNode name=\u0026#34;dn2\u0026#34; dataHost=\u0026#34;dhost2\u0026#34; database=\u0026#34;db01\u0026#34; /\u0026gt; \u0026lt;dataNode name=\u0026#34;dn3\u0026#34; dataHost=\u0026#34;dhost3\u0026#34; database=\u0026#34;db01\u0026#34; /\u0026gt; \u0026lt;dataHost name=\u0026#34;dhost1\u0026#34; maxCon=\u0026#34;1000\u0026#34; minCon=\u0026#34;10\u0026#34; balance=\u0026#34;0\u0026#34; writeType=\u0026#34;0\u0026#34; dbType=\u0026#34;mysql\u0026#34; dbDriver=\u0026#34;jdbc\u0026#34; switchType=\u0026#34;1\u0026#34; slaveThreshold=\u0026#34;100\u0026#34;\u0026gt; \u0026lt;heartbeat\u0026gt;select user()\u0026lt;/heartbeat\u0026gt; \u0026lt;writeHost host=\u0026#34;master\u0026#34; url=\u0026#34;jdbc:mysql://172.16.140.111:3306?allowPublicKeyRetrieval=true\u0026amp;amp;useSSL=false\u0026amp;amp;serverTimezone=Asia/Shanghai\u0026amp;amp;characterEncoding=utf8\u0026#34; user=\u0026#34;root\u0026#34; password=\u0026#34;123456\u0026#34; /\u0026gt; \u0026lt;/dataHost\u0026gt; \u0026lt;dataHost name=\u0026#34;dhost2\u0026#34; maxCon=\u0026#34;1000\u0026#34; minCon=\u0026#34;10\u0026#34; balance=\u0026#34;0\u0026#34; writeType=\u0026#34;0\u0026#34; dbType=\u0026#34;mysql\u0026#34; dbDriver=\u0026#34;jdbc\u0026#34; switchType=\u0026#34;1\u0026#34; slaveThreshold=\u0026#34;100\u0026#34;\u0026gt; \u0026lt;heartbeat\u0026gt;select user()\u0026lt;/heartbeat\u0026gt; \u0026lt;writeHost host=\u0026#34;master\u0026#34; url=\u0026#34;jdbc:mysql://172.16.140.112:3306?allowPublicKeyRetrieval=true\u0026amp;amp;useSSL=false\u0026amp;amp;serverTimezone=Asia/Shanghai\u0026amp;amp;characterEncoding=utf8\u0026#34; user=\u0026#34;root\u0026#34; password=\u0026#34;123456\u0026#34; /\u0026gt; \u0026lt;/dataHost\u0026gt; \u0026lt;dataHost name=\u0026#34;dhost3\u0026#34; maxCon=\u0026#34;1000\u0026#34; minCon=\u0026#34;10\u0026#34; balance=\u0026#34;0\u0026#34; writeType=\u0026#34;0\u0026#34; dbType=\u0026#34;mysql\u0026#34; dbDriver=\u0026#34;jdbc\u0026#34; switchType=\u0026#34;1\u0026#34; slaveThreshold=\u0026#34;100\u0026#34;\u0026gt; \u0026lt;heartbeat\u0026gt;select user()\u0026lt;/heartbeat\u0026gt; \u0026lt;writeHost host=\u0026#34;master\u0026#34; url=\u0026#34;jdbc:mysql://172.16.140.113:3306?allowPublicKeyRetrieval=true\u0026amp;amp;useSSL=false\u0026amp;amp;serverTimezone=Asia/Shanghai\u0026amp;amp;characterEncoding=utf8\u0026#34; user=\u0026#34;root\u0026#34; password=\u0026#34;123456\u0026#34; /\u0026gt; \u0026lt;/dataHost\u0026gt; \u0026lt;/mycat:schema\u0026gt; 1). mycat/conf/server.xml 需要在server.xml中配置用户名、密码，以及用户的访问权限信息，具体的配置如下:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 \u0026lt;user name=\u0026#34;root\u0026#34; defaultAccount=\u0026#34;true\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;password\u0026#34;\u0026gt;123456\u0026lt;/property\u0026gt; \u0026lt;property name=\u0026#34;schemas\u0026#34;\u0026gt;DB01\u0026lt;/property\u0026gt; \u0026lt;!-- 表级 DML 权限设置 --\u0026gt; \u0026lt;!-- \u0026lt;privileges check=\u0026#34;false\u0026#34;\u0026gt; \u0026lt;schema name=\u0026#34;TESTDB\u0026#34; dml=\u0026#34;0110\u0026#34; \u0026gt; \u0026lt;table name=\u0026#34;tb01\u0026#34; dml=\u0026#34;0000\u0026#34;\u0026gt;\u0026lt;/table\u0026gt; \u0026lt;table name=\u0026#34;tb02\u0026#34; dml=\u0026#34;1111\u0026#34;\u0026gt;\u0026lt;/table\u0026gt; \u0026lt;/schema\u0026gt; \u0026lt;/privileges\u0026gt;\t--\u0026gt; \u0026lt;/user\u0026gt; \u0026lt;user name=\u0026#34;user\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;password\u0026#34;\u0026gt;123456\u0026lt;/property\u0026gt; \u0026lt;property name=\u0026#34;schemas\u0026#34;\u0026gt;DB01\u0026lt;/property\u0026gt; \u0026lt;property name=\u0026#34;readOnly\u0026#34;\u0026gt;true\u0026lt;/property\u0026gt; \u0026lt;/user\u0026gt; 上述的配置表示，定义了两个用户 root 和 user ，这两个用户都可以访问 DB01 这个逻辑库，访 问密码都是123456，但是root用户访问DB01逻辑库，既可以读，又可以写，但是 user用户访问 DB01逻辑库是只读的。\n测试 启动 配置完毕后，先启动涉及到的3台分片服务器，然后启动MyCat服务器。切换到Mycat的安装目录，执行如下指令，启动Mycat:\n启动 1 bin/mycat start 停止 1 bin/mycat stop Mycat启动之后，占用端口 8066\n启动报错：\n1 2 3 4 5 [root@localhost mycat]# bin/mycat start Unable to locate any of the following operational binaries: /usr/local/mycat/bin/./wrapper-linux-aarch64-64 /usr/local/mycat/bin/./wrapper-linux-aarch64-32 /usr/local/mycat/bin/./wrapper 原因： 缺少wrapper-linux-aarch64-64、wrapper-linux-aarch64-32、wrapper\n下载地址：wrapper 解决 下载wrapper 1 wget https://download.tanukisoftware.com/wrapper/3.5.40/wrapper-linux-armhf-64-3.5.40.tar.gz 解压wrapper，并将其复制到mycat/bin目录下 1 2 3 tar -zxvf wrapper-linux-armhf-64-3.5.40.tar.gz cd wrapper-linux-armhf-64-3.5.40/bin cp wrapper /usr/local/mycat/bin 重新启动 mycat 1 /usr/local/mycat/bin/mycat start 启动完毕之后，可以查看logs目录下的启动日志，查看Mycat是否启动完成。\n1 tail -f logs/wrapper.log 启动报错：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 [root@localhost mycat]# tail -f logs/wrapper.log STATUS | wrapper | 2025/11/29 04:33:08 | --\u0026gt; Wrapper Started as Daemon STATUS | wrapper | 2025/11/29 04:33:08 | Java Service Wrapper Community Edition 64-bit 3.5.40 STATUS | wrapper | 2025/11/29 04:33:08 | Copyright (C) 1999-2019 Tanuki Software, Ltd. All Rights Reserved. STATUS | wrapper | 2025/11/29 04:33:08 | http://wrapper.tanukisoftware.com STATUS | wrapper | 2025/11/29 04:33:08 | STATUS | wrapper | 2025/11/29 04:33:08 | Launching a JVM... INFO | jvm 1 | 2025/11/29 04:33:08 | Java HotSpot(TM) 64-Bit Server VM warning: ignoring option MaxPermSize=64M; support was removed in 8.0 ERROR | wrapper | 2025/11/29 04:33:38 | Startup failed: Timed out waiting for a signal from the JVM. ERROR | wrapper | 2025/11/29 04:33:38 | JVM did not exit on request, termination requested. STATUS | wrapper | 2025/11/29 04:33:38 | JVM received a signal SIGKILL (9). STATUS | wrapper | 2025/11/29 04:33:38 | JVM process is gone. STATUS | wrapper | 2025/11/29 04:33:38 | JVM exited after being requested to terminate. STATUS | wrapper | 2025/11/29 04:33:44 | JVM process is gone. 原因： JVM 启动时间过长。\n解决； 延长JVM启动时间\n编辑wrapper.conf文件 1 vim /usr/local/mycat/conf/wrapper.conf 添加以下配置 1 2 # 增加超时时间 wrapper.startup.timeout=300 启动成功\n测试 连接MyCat 通过如下指令，就可以连接并登陆MyCat。\n1 mysql -h 172.16.140.111 -P 8066 -uroot -p123456 我们看到我们是通过MySQL的指令来连接的MyCat，因为MyCat在底层实际上是模拟了MySQL的协议。\n查看MyCat中的数据库 1 show databases; 查看DB01中的表 1 2 use DB01; show tables; 但是这张表目前在三个mysql数据库中不存在，只是逻辑存在于MyCat中\n数据测试 然后就可以在MyCat中来创建表，并往表结构中插入数据，查看数据在MySQL中的分布情况。\n1 2 3 4 5 6 7 8 9 10 11 12 13 CREATE TABLE TB_ORDER ( id BIGINT(20) NOT NULL, title VARCHAR(100) NOT NULL , PRIMARY KEY (id) ) ENGINE=INNODB DEFAULT CHARSET=utf8 ; INSERT INTO TB_ORDER(id,title) VALUES(1,\u0026#39;goods1\u0026#39;); INSERT INTO TB_ORDER(id,title) VALUES(2,\u0026#39;goods2\u0026#39;); INSERT INTO TB_ORDER(id,title) VALUES(3,\u0026#39;goods3\u0026#39;); INSERT INTO TB_ORDER(id,title) VALUES(5000000,\u0026#39;goods5000000\u0026#39;); INSERT INTO TB_ORDER(id,title) VALUES(10000000,\u0026#39;goods10000000\u0026#39;); INSERT INTO TB_ORDER(id,title) VALUES(10000001,\u0026#39;goods10000001\u0026#39;); INSERT INTO TB_ORDER(id,title) VALUES(15000000,\u0026#39;goods15000000\u0026#39;); INSERT INTO TB_ORDER(id,title) VALUES(15000001,\u0026#39;goods15000001\u0026#39;); 创建TB_ORDER表 1 2 3 4 5 CREATE TABLE TB_ORDER ( id BIGINT(20) NOT NULL, title VARCHAR(100) NOT NULL , PRIMARY KEY (id) ) ENGINE=INNODB DEFAULT CHARSET=utf8 ; 此时可以看到三个数据库中同时创建出了tb_order表\n插入数据 1 2 3 INSERT INTO TB_ORDER(id,title) VALUES(1,\u0026#39;goods1\u0026#39;); INSERT INTO TB_ORDER(id,title) VALUES(2,\u0026#39;goods2\u0026#39;); INSERT INTO TB_ORDER(id,title) VALUES(3,\u0026#39;goods3\u0026#39;); 可以看到数据只保存在第一个MySQL数据库中\n那么，为什么数据这样分布呢？\n这就与数据分片规则有关\n该规则配置在conf/rule.xml中\n可以看到这个规则是根据id字段进行分配数据，引用rang-long函数进行分配，函数rang-long映射了文件autopartition-long.txt，该文件就在con目录下\nautopartition-long.txt 1 2 3 4 5 6 7 8 9 10 11 12 # 上面两行前面有#的为注释 # range start-end ,data node index # 说明范围为0(start)-500M(end)=0(data node index：数据节点的索引) # K=1000,M=10000. # K的值为1000，M的值为10000 0-500M=0 # 0到500万的数据存放在第一个节点 500M-1000M=1 # 500万到1000万的数据存放在第二个节点 1000M-1500M=2 # 1000万到1500万的数据存放在第三个节点 分别插入id为5000000、5000001、10000000、10000001、15000000的数据 1 2 3 4 5 INSERT INTO TB_ORDER(id,title) VALUES(5000000,\u0026#39;goods5000000\u0026#39;); INSERT INTO TB_ORDER(id,title) VALUES(5000001,\u0026#39;goods5000001\u0026#39;); INSERT INTO TB_ORDER(id,title) VALUES(10000000,\u0026#39;goods10000000\u0026#39;); INSERT INTO TB_ORDER(id,title) VALUES(10000001,\u0026#39;goods10000001\u0026#39;); INSERT INTO TB_ORDER(id,title) VALUES(15000000,\u0026#39;goods15000000\u0026#39;); 可以看到id为5000000的数据存放在第一个节点数据库\nid为5000001、10000000的数据存放在第二个节点数据库\nid为10000001、15000000的数据存放在第三个节点数据库\n那么插入id为15000001会存放在哪个数据库呢？\n插入id为15000001的数据 1 INSERT INTO TB_ORDER(id,title) VALUES(15000001,\u0026#39;goods15000001\u0026#39;); 可以看到当存放id为15000001的数据时，出现报错，没有节点数据库给id为15000001的数据存放。\n总结 经过测试，我们发现，在往 TB_ORDER 表中插入数据时:\n如果id的值在1-500w之间，数据将会存储在第一个分片数据库中。 如果id的值在500w-1000w之间，数据将会存储在第二个分片数据库中。 如果id的值在1000w-1500w之间，数据将会存储在第三个分片数据库中。 如果id的值超出1500w，在插入数据时，将会报错。 为什么会出现这种现象，数据到底落在哪一个分片服务器到底是如何决定的呢? 这是由逻辑表配置时 的一个参数 rule 决定的，而这个参数配置的就是分片规则，关于分片规则的配置，在后面会详细讲解。\nMyCat配置 schema.xml schema.xml 作为MyCat中最重要的配置文件之一 , 涵盖了MyCat的逻辑库、逻辑表、分片规则、分片节点及数据源的配置。\n主要包含以下三组标签:\nschema标签 datanode标签 datahost标签 schema标签 schema 定义逻辑库 schema 标签用于定义 MyCat实例中的逻辑库 , 一个MyCat实例中, 可以有多个逻辑库 , 可以通 过 schema 标签来划分不同的逻辑库。MyCat中的逻辑库的概念，等同于MySQL中的database概念 , 需要操作某个逻辑库下的表时, 也需要切换逻辑库(use xxx)。\n核心属性:\nname : 指定自定义的逻辑库库名 checkSQLschema : 在SQL语句操作时指定了数据库名称，执行时是否自动去除;true:自动去除，false:不自动去除 sqlMaxLimit : 如果未指定limit进行查询，列表查询模式查询会自动加上对应的值。（比如上图，当sql查询语句没有加limit条件时，只会查询100条数据。） 当checkSQLschema设置为true时，执行以下语句能正常查询出来，会自动去除DB01这个名称\n1 select * from DB01.TB_ORDER; 但是checkSQLschema设置为true时，将会报错，只能执行以下语句查询。\n1 2 use DB01; select * from TB_ORDER; schema 中的table定义逻辑表 table 标签定义了MyCat中逻辑库schema下的逻辑表 , 所有需要拆分的表都需要在table标签中定义。\n核心属性:\nname : 定义逻辑表表名，在该逻辑库下唯一 dataNode : 定义逻辑表所属的dataNode，该属性需要与dataNode标签中name对应;多个dataNode逗号分隔 rule : 分片规则的名字，分片规则名字是在rule.xml中定义的 primaryKey : 逻辑表对应真实表的主键 type : 逻辑表的类型，目前逻辑表只有全局表和普通表，如果未配置，就是普通表;全局表配置为global datanode标签 核心属性:\nname : 定义数据节点名称 dataHost : 数据库实例主机名称，引用自 dataHost 标签中name属性 database : 定义分片所属数据库 datahost标签 该标签在MyCat逻辑库中作为底层标签存在, 直接定义了具体的数据库实例、读写分离、心跳语句。\n核心属性:\nname : 唯一标识，供上层标签使用 maxCon/minCon : 最大连接数/最小连接数 balance : 负载均衡策略，取值 0,1,2,3 writeType : 写操作分发方式(0:写操作转发到第一个writeHost，第一个挂了，切换到第二 个;1:写操作随机分发到配置的writeHost) dbDriver : 数据库驱动，支持 native、jdbc rule.xml rule.xml 中定义所有拆分表的规则, 在使用过程中可以灵活的使用分片算法, 或者对同一个分片算法使用不同的参数, 它让分片过程可配置化。主要包含两类标签: tableRule、Function。\nserver.xml server.xml 配置文件包含了MyCat的系统配置信息，主要有两个重要的标签: system、user。\nsystem 标签 主要配置MyCat中的系统配置信息，对应的系统配置项及其含义，如下:\n属性 取值 含义 charset utf8 设置Mycat的字符集, 字符集需要与MySQL的 字符集保持一致 nonePasswordLogin 0,1 0为需要密码登陆、1为不需要密码登陆 ,默认 为0，设置为1则需要指定默认账户 useHandshakeV10 0,1 使用该选项主要的目的是为了能够兼容高版本 的jdbc驱动, 是否采用 HandshakeV10Packet来与client进行通 信, 1:是, 0:否 useSqlStat 0,1 开启SQL实时统计, 1 为开启 , 0 为关闭 ; 开启之后, MyCat会自动统计SQL语句的执行 情况 ; mysql -h 127.0.0.1 -P 9066 -u root -p 查看MyCat执行的SQL, 执行 效率比较低的SQL , SQL的整体执行情况、读 写比例等 ; show @@sql ; show @@sql.slow ; show @@sql.sum ; useGlobleTableCheck 0,1 是否开启全局表的一致性检测。1为开启，0为关闭。 sqlExecuteTimeout 1000 SQL语句执行的超时时间 , 单位为s; sequnceHandlerType 0,1,2 用来指定Mycat全局序列类型，0 为本地文件，1为数据库方式，2为时间戳列方式，默认使用本地文件方式，文件方式主要用于测试 sequnceHandlerPattern 正则表达式 必须带有MYCATSEQ或者 mycatseq进入序列匹配流程注意MYCATSEQ_有空格的情况 subqueryRelationshipCheck true,false 子查询中存在关联查询的情况下,检查关联字段中是否有分片字段。默认false useCompression 0,1 开启mysql压缩协议 , 0 : 关闭, 1 : 开启 fakeMySQLVersion 5.5,5.6 设置模拟的MySQL版本号 defaultSqlParser 由于MyCat的最初版本使用了FoundationDB 的SQL解析器, 在MyCat1.3后增加了Druid 解析器, 所以要设置defaultSqlParser属 性来指定默认的解析器; 解析器有两个 : druidparser 和 fdbparser, 在 MyCat1.4之后,默认是druidparser, fdbparser已经废除了 processors 1,2\u0026hellip;. 指定系统可用的线程数量, 默认值为CPU核心 x 每个核心运行线程数量; processors 会 影响processorBufferPool, processorBufferLocalPercent, processorExecutor属性, 所有, 在性能 调优时, 可以适当地修改processors值 processorBufferChunk 指定每次分配Socket Direct Buffer默认 值为4096字节, 也会影响BufferPool长度, 如果一次性获取字节过多而导致buffer不够 用, 则会出现警告, 可以调大该值 processorExecutor 指定NIOProcessor上共享 businessExecutor固定线程池的大小; MyCat把异步任务交给 businessExecutor 线程池中, 在新版本的MyCat中这个连接池使 用频次不高, 可以适当地把该值调小 packetHeaderSize 指定MySQL协议中的报文头长度, 默认4个字节 maxPacketSize 指定MySQL协议可以携带的数据最大大小, 默认值为16M idleTimeout 30 指定连接的空闲时间的超时长度;如果超时,将关闭资源并回收, 默认30分钟 txIsolation 1,2,3,4 初始化前端连接的事务隔离级别,默认为 REPEATED_READ , 对应数字为3 READ_UNCOMMITED=1; READ_COMMITTED=2; REPEATED_READ=3; SERIALIZABLE=4; sqlExecuteTimeout 300 执行SQL的超时时间, 如果SQL语句执行超时, 将关闭连接; 默认300秒; serverPort 8066 定义MyCat的使用端口, 默认8066 managerPort 9066 定义MyCat的管理端口, 默认9066 user 标签 配置MyCat中的用户、访问密码，以及用户针对于逻辑库、逻辑表的权限信息，具体的权限描述方式及配置说明如下:\n在测试权限操作时，我们只需要将 privileges 标签的注释放开。 在 privileges 下的schema 标签中配置的dml属性配置的是逻辑库的权限。 在privileges的schema下的table标签的dml属性 中配置逻辑表的权限。\n测试 设置 DML 权限配置(没有开启的话默认权限全开，即check=\u0026ldquo;false\u0026rdquo;) 1 2 3 4 5 6 7 \u0026lt;!-- 表级 DML 权限设置 --\u0026gt; \u0026lt;privileges check=\u0026#34;false\u0026#34;\u0026gt; \u0026lt;schema name=\u0026#34;DB01\u0026#34; dml=\u0026#34;0110\u0026#34; \u0026gt; \u0026lt;!-- 修改，查询 --\u0026gt; \u0026lt;table name=\u0026#34;TB_ORDER\u0026#34; dml=\u0026#34;1110\u0026#34;\u0026gt;\u0026lt;/table\u0026gt; \u0026lt;!-- 增加，修改，查询。--\u0026gt; \u0026lt;!-- 当逻辑库与逻辑表的权限不同时，因为就近原则，使用逻辑表的权限 --\u0026gt; \u0026lt;/schema\u0026gt; \u0026lt;/privileges\u0026gt;\t重启mycat 停止 1 bin/mycat stop 启动 1 bin/mycat start 在mycat中查询TB_ORDER表全部数据 1 select * from TB_ORDER: 在mycat中插入数据 1 insert into TB_ORDER(id,title) values (4,\u0026#39;goods4\u0026#39;); 在mycat中修改数据 1 update TB_ORDER set title = \u0026#39;4\u0026#39; where id = 4; 在mycat中删除数据 1 delete from TB_ORDER where id = 4; 可以看到root用户没有删除权限。\nMyCat 分片 垂直拆分 场景 在业务系统中, 涉及以下表结构 ,但是由于用户与订单每天都会产生大量的数据, 单台服务器的数据存储及处理能力是有限的, 可以对数据库表进行拆分, 原有的数据库表如下。\n现在考虑将其进行垂直分库操作，将商品相关的表拆分到一个数据库服务器，订单表拆分的一个数据库服务器，用户及省市区表拆分到一个服务器。最终结构如下:\n准备 准备三台服务器：\n172.16.140.111:MyCat中间件服务器，同时也是第一个分片服务器。 172.16.140.112:第二个分片服务器。 172.16.140.114:第三个分片服务器。 并且在172.16.140.111，172.16.140.112, 172.16.140.113上面创建数据库 shopping。\n配置 schema.xml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 \u0026lt;schema name=\u0026#34;SHOPPING\u0026#34; checkSQLschema=\u0026#34;true\u0026#34; sqlMaxLimit=\u0026#34;100\u0026#34;\u0026gt; \u0026lt;table name=\u0026#34;tb_goods_base\u0026#34; dataNode=\u0026#34;dn1\u0026#34; primaryKey=\u0026#34;id\u0026#34; /\u0026gt; \u0026lt;table name=\u0026#34;tb_goods_brand\u0026#34; dataNode=\u0026#34;dn1\u0026#34; primaryKey=\u0026#34;id\u0026#34; /\u0026gt; \u0026lt;table name=\u0026#34;tb_goods_cat\u0026#34; dataNode=\u0026#34;dn1\u0026#34; primaryKey=\u0026#34;id\u0026#34; /\u0026gt; \u0026lt;table name=\u0026#34;tb_goods_desc\u0026#34; dataNode=\u0026#34;dn1\u0026#34; primaryKey=\u0026#34;goods_id\u0026#34; /\u0026gt; \u0026lt;table name=\u0026#34;tb_goods_item\u0026#34; dataNode=\u0026#34;dn1\u0026#34; primaryKey=\u0026#34;id\u0026#34; /\u0026gt; \u0026lt;table name=\u0026#34;tb_order_item\u0026#34; dataNode=\u0026#34;dn2\u0026#34; primaryKey=\u0026#34;id\u0026#34; /\u0026gt; \u0026lt;table name=\u0026#34;tb_order_master\u0026#34; dataNode=\u0026#34;dn2\u0026#34; primaryKey=\u0026#34;order_id\u0026#34; /\u0026gt; \u0026lt;table name=\u0026#34;tb_order_pay_log\u0026#34; dataNode=\u0026#34;dn2\u0026#34; primaryKey=\u0026#34;out_trade_no\u0026#34; /\u0026gt; \u0026lt;table name=\u0026#34;tb_user\u0026#34; dataNode=\u0026#34;dn3\u0026#34; primaryKey=\u0026#34;id\u0026#34; /\u0026gt; \u0026lt;table name=\u0026#34;tb_user_address\u0026#34; dataNode=\u0026#34;dn3\u0026#34; primaryKey=\u0026#34;id\u0026#34; /\u0026gt; \u0026lt;table name=\u0026#34;tb_areas_provinces\u0026#34; dataNode=\u0026#34;dn3\u0026#34; primaryKey=\u0026#34;id\u0026#34;/\u0026gt; \u0026lt;table name=\u0026#34;tb_areas_city\u0026#34; dataNode=\u0026#34;dn3\u0026#34; primaryKey=\u0026#34;id\u0026#34;/\u0026gt; \u0026lt;table name=\u0026#34;tb_areas_region\u0026#34; dataNode=\u0026#34;dn3\u0026#34; primaryKey=\u0026#34;id\u0026#34;/\u0026gt; \u0026lt;/schema\u0026gt; \u0026lt;dataNode name=\u0026#34;dn1\u0026#34; dataHost=\u0026#34;dhost1\u0026#34; database=\u0026#34;shopping\u0026#34; /\u0026gt; \u0026lt;dataNode name=\u0026#34;dn2\u0026#34; dataHost=\u0026#34;dhost2\u0026#34; database=\u0026#34;shopping\u0026#34; /\u0026gt; \u0026lt;dataNode name=\u0026#34;dn3\u0026#34; dataHost=\u0026#34;dhost3\u0026#34; database=\u0026#34;shopping\u0026#34; /\u0026gt; \u0026lt;dataHost name=\u0026#34;dhost1\u0026#34; maxCon=\u0026#34;1000\u0026#34; minCon=\u0026#34;10\u0026#34; balance=\u0026#34;0\u0026#34; writeType=\u0026#34;0\u0026#34; dbType=\u0026#34;mysql\u0026#34; dbDriver=\u0026#34;jdbc\u0026#34; switchType=\u0026#34;1\u0026#34; slaveThreshold=\u0026#34;100\u0026#34;\u0026gt; \u0026lt;heartbeat\u0026gt;select user()\u0026lt;/heartbeat\u0026gt; \u0026lt;writeHost host=\u0026#34;master\u0026#34; url=\u0026#34;jdbc:mysql://172.16.140.111:3306?allowPublicKeyRetrieval=true\u0026amp;amp;useSSL=false\u0026amp;amp;serverTimezone=Asia/Shanghai\u0026amp;amp;characterEncoding=utf8\u0026#34; user=\u0026#34;root\u0026#34; password=\u0026#34;123456\u0026#34; /\u0026gt; \u0026lt;/dataHost\u0026gt; \u0026lt;dataHost name=\u0026#34;dhost2\u0026#34; maxCon=\u0026#34;1000\u0026#34; minCon=\u0026#34;10\u0026#34; balance=\u0026#34;0\u0026#34; writeType=\u0026#34;0\u0026#34; dbType=\u0026#34;mysql\u0026#34; dbDriver=\u0026#34;jdbc\u0026#34; switchType=\u0026#34;1\u0026#34; slaveThreshold=\u0026#34;100\u0026#34;\u0026gt; \u0026lt;heartbeat\u0026gt;select user()\u0026lt;/heartbeat\u0026gt; \u0026lt;writeHost host=\u0026#34;master\u0026#34; url=\u0026#34;jdbc:mysql://172.16.140.112:3306?allowPublicKeyRetrieval=true\u0026amp;amp;useSSL=false\u0026amp;amp;serverTimezone=Asia/Shanghai\u0026amp;amp;characterEncoding=utf8\u0026#34; user=\u0026#34;root\u0026#34; password=\u0026#34;123456\u0026#34; /\u0026gt; \u0026lt;/dataHost\u0026gt; \u0026lt;dataHost name=\u0026#34;dhost3\u0026#34; maxCon=\u0026#34;1000\u0026#34; minCon=\u0026#34;10\u0026#34; balance=\u0026#34;0\u0026#34; writeType=\u0026#34;0\u0026#34; dbType=\u0026#34;mysql\u0026#34; dbDriver=\u0026#34;jdbc\u0026#34; switchType=\u0026#34;1\u0026#34; slaveThreshold=\u0026#34;100\u0026#34;\u0026gt; \u0026lt;heartbeat\u0026gt;select user()\u0026lt;/heartbeat\u0026gt; \u0026lt;writeHost host=\u0026#34;master\u0026#34; url=\u0026#34;jdbc:mysql://172.16.140.113:3306?allowPublicKeyRetrieval=true\u0026amp;amp;useSSL=false\u0026amp;amp;serverTimezone=Asia/Shanghai\u0026amp;amp;characterEncoding=utf8\u0026#34; user=\u0026#34;root\u0026#34; password=\u0026#34;123456\u0026#34; /\u0026gt; \u0026lt;/dataHost\u0026gt; server.xml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 \u0026lt;user name=\u0026#34;root\u0026#34; defaultAccount=\u0026#34;true\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;password\u0026#34;\u0026gt;123456\u0026lt;/property\u0026gt; \u0026lt;property name=\u0026#34;schemas\u0026#34;\u0026gt;SHOPPING\u0026lt;/property\u0026gt; \u0026lt;!-- 表级 DML 权限设置 --\u0026gt; \u0026lt;!-- \u0026lt;privileges check=\u0026#34;true\u0026#34;\u0026gt; \u0026lt;schema name=\u0026#34;DB01\u0026#34; dml=\u0026#34;0110\u0026#34; \u0026gt; \u0026lt;table name=\u0026#34;TB_ORDER\u0026#34; dml=\u0026#34;1110\u0026#34;\u0026gt;\u0026lt;/table\u0026gt; \u0026lt;/schema\u0026gt; \u0026lt;/privileges\u0026gt; --\u0026gt; \u0026lt;/user\u0026gt; \u0026lt;user name=\u0026#34;user\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;password\u0026#34;\u0026gt;123456\u0026lt;/property\u0026gt; \u0026lt;property name=\u0026#34;schemas\u0026#34;\u0026gt;SHOPPING\u0026lt;/property\u0026gt; \u0026lt;property name=\u0026#34;readOnly\u0026#34;\u0026gt;true\u0026lt;/property\u0026gt; \u0026lt;/user\u0026gt; 测试 上传测试SQL脚本到服务器的/root/sql目录 1 2 scp shopping-insert.sql root@172.16.140.111:/root/sql scp shopping-table.sql root@172.16.140.111:/root/sql 执行指令导入测试数据 重新启动MyCat后，在mycat的命令行中，通过source指令导入表结构，以及对应的数据，查看数据分布情况。\n1 2 source /root/sql/shopping-table.sql source /root/sql/shopping-insert.sql 将表结构及对应的测试数据导入之后，可以检查一下各个数据库服务器中的表结构分布情况。 检查是否和我们准备工作中规划的服务器一致。\n查询用户的收件人及收件人地址信息(包含省、市、区)。 在MyCat的命令行中，当我们执行以下多表联查的SQL语句时，可以正常查询出数据。\n1 select ua.user_id, ua.contact, p.province, c.city, r.area , ua.address from tb_user_address ua ,tb_areas_city c , tb_areas_provinces p ,tb_areas_region r where ua.province_id = p.provinceid and ua.city_id = c.cityid and ua.town_id = r.areaid ; 查询每一笔订单及订单的收件地址信息(包含省、市、区)。 实现该需求对应的SQL语句如下:\n1 SELECT order_id , payment ,receiver, province , city , area FROM tb_order_master o , tb_areas_provinces p , tb_areas_city c , tb_areas_region r WHERE o.receiver_province = p.provinceid AND o.receiver_city = c.cityid AND o.receiver_region = r.areaid ; 但是现在存在一个问题，订单相关的表结构是在 172.16.140.112 数据库服务器中，而省市区的数 据库表是在 172.16.140.113 数据库服务器中。那么在MyCat中执行是否可以成功呢?\n经过测试，我们看到，SQL语句执行报错。原因就是因为MyCat在执行该SQL语句时，需要往具体的数 据库服务器中路由，而当前没有一个数据库服务器完全包含了订单以及省市区的表结构，造成SQL语句 失败，报错。\n对于上述的这种现象，我们如何来解决呢? 下面我们介绍的全局表，就可以轻松解决这个问题。\n全局表 对于省、市、区/县表tb_areas_provinces , tb_areas_city , tb_areas_region，是属于 数据字典表，在多个业务模块中都可能会遇到，可以将其设置为全局表，利于业务操作。\n修改schema.xml中的逻辑表的配置，修改 tb_areas_provinces、tb_areas_city、 tb_areas_region 三个逻辑表，增加 type 属性，配置为global，就代表该表是全局表，就会在 所涉及到的dataNode中创建给表。对于当前配置来说，也就意味着所有的节点中都有该表了。\n修改schema.xml中的逻辑表的配置 1 2 3 \u0026lt;table name=\u0026#34;tb_areas_provinces\u0026#34; dataNode=\u0026#34;dn1,dn2,dn3\u0026#34; primaryKey=\u0026#34;id\u0026#34; type=\u0026#34;global\u0026#34;/\u0026gt; \u0026lt;table name=\u0026#34;tb_areas_city\u0026#34; dataNode=\u0026#34;dn1,dn2,dn3\u0026#34; primaryKey=\u0026#34;id\u0026#34; type=\u0026#34;global\u0026#34;/\u0026gt; \u0026lt;table name=\u0026#34;tb_areas_region\u0026#34; dataNode=\u0026#34;dn1,dn2,dn3\u0026#34; primaryKey=\u0026#34;id\u0026#34; type=\u0026#34;global\u0026#34;/\u0026gt; 修改逻辑表配置：\n修改逻辑表配置 停止mycat 删除原来每一个数据库服务器中的所有表结构 启动mycat 通过source指令，导入表及数据 1 2 source /root/shopping-table.sql source /root/shopping-insert.sql 检查每一个数据库服务器中的表及数据分布，看到三个节点中都有这三张全局表 然后再次执行上面的多表联查的SQL语句 1 2 3 4 5 6 SELECT order_id , payment ,receiver, province , city , area FROM tb_order_master o , tb_areas_provinces p , tb_areas_city c , tb_areas_region r WHERE o.receiver_province = p.provinceid AND o.receiver_city = c.cityid AND o.receiver_region = r.areaid ; 是可以正常执行成功的。\n在MyCat中更新全局表 1 update tb_areas_provinces set province = \u0026#39;北京\u0026#39; where id = 1; 当在MyCat中更新全局表的时候，我们可以看到，所有分片节点中的数据都发生了变化，每个节点的全局表数据时刻保持一致。\n水平拆分 场景 在业务系统中, 有一张表(日志表), 业务系统每天都会产生大量的日志数据 , 单台服务器的数据存储及处理能力是有限的, 可以对数据库表进行拆分。\n准备三台服务器:\n172.16.140.111:MyCat中间件服务器，同时也是第一个分片服务器。 172.16.140.112:第二个分片服务器。 172.16.140.114:第三个分片服务器。 并且，在三台数据库服务器中分表创建一个数据库itcast。\n配置 schema.xml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 \u0026lt;?xml version=\u0026#34;1.0\u0026#34;?\u0026gt; \u0026lt;!DOCTYPE mycat:schema SYSTEM \u0026#34;schema.dtd\u0026#34;\u0026gt; \u0026lt;mycat:schema xmlns:mycat=\u0026#34;http://io.mycat/\u0026#34;\u0026gt; \u0026lt;schema name=\u0026#34;SHOPPING\u0026#34; checkSQLschema=\u0026#34;true\u0026#34; sqlMaxLimit=\u0026#34;100\u0026#34;\u0026gt; \u0026lt;table name=\u0026#34;tb_goods_base\u0026#34; dataNode=\u0026#34;dn1\u0026#34; primaryKey=\u0026#34;id\u0026#34; /\u0026gt; \u0026lt;table name=\u0026#34;tb_goods_brand\u0026#34; dataNode=\u0026#34;dn1\u0026#34; primaryKey=\u0026#34;id\u0026#34; /\u0026gt; \u0026lt;table name=\u0026#34;tb_goods_cat\u0026#34; dataNode=\u0026#34;dn1\u0026#34; primaryKey=\u0026#34;id\u0026#34; /\u0026gt; \u0026lt;table name=\u0026#34;tb_goods_desc\u0026#34; dataNode=\u0026#34;dn1\u0026#34; primaryKey=\u0026#34;goods_id\u0026#34; /\u0026gt; \u0026lt;table name=\u0026#34;tb_goods_item\u0026#34; dataNode=\u0026#34;dn1\u0026#34; primaryKey=\u0026#34;id\u0026#34; /\u0026gt; \u0026lt;table name=\u0026#34;tb_order_item\u0026#34; dataNode=\u0026#34;dn2\u0026#34; primaryKey=\u0026#34;id\u0026#34; /\u0026gt; \u0026lt;table name=\u0026#34;tb_order_master\u0026#34; dataNode=\u0026#34;dn2\u0026#34; primaryKey=\u0026#34;order_id\u0026#34; /\u0026gt; \u0026lt;table name=\u0026#34;tb_order_pay_log\u0026#34; dataNode=\u0026#34;dn2\u0026#34; primaryKey=\u0026#34;out_trade_no\u0026#34; /\u0026gt; \u0026lt;table name=\u0026#34;tb_user\u0026#34; dataNode=\u0026#34;dn3\u0026#34; primaryKey=\u0026#34;id\u0026#34; /\u0026gt; \u0026lt;table name=\u0026#34;tb_user_address\u0026#34; dataNode=\u0026#34;dn3\u0026#34; primaryKey=\u0026#34;id\u0026#34; /\u0026gt; \u0026lt;table name=\u0026#34;tb_areas_provinces\u0026#34; dataNode=\u0026#34;dn1,dn2,dn3\u0026#34; primaryKey=\u0026#34;id\u0026#34; type=\u0026#34;global\u0026#34;/\u0026gt; \u0026lt;table name=\u0026#34;tb_areas_city\u0026#34; dataNode=\u0026#34;dn1,dn2,dn3\u0026#34; primaryKey=\u0026#34;id\u0026#34; type=\u0026#34;global\u0026#34;/\u0026gt; \u0026lt;table name=\u0026#34;tb_areas_region\u0026#34; dataNode=\u0026#34;dn1,dn2,dn3\u0026#34; primaryKey=\u0026#34;id\u0026#34; type=\u0026#34;global\u0026#34;/\u0026gt; \u0026lt;/schema\u0026gt; \u0026lt;schema name=\u0026#34;ITCAST\u0026#34; checkSQLschema=\u0026#34;true\u0026#34; sqlMaxLimit=\u0026#34;100\u0026#34;\u0026gt; \u0026lt;table name=\u0026#34;tb_log\u0026#34; dataNode=\u0026#34;dn4,dn5,dn6\u0026#34; primaryKey=\u0026#34;id\u0026#34; rule=\u0026#34;mod-long\u0026#34; /\u0026gt; \u0026lt;/schema\u0026gt; \u0026lt;dataNode name=\u0026#34;dn1\u0026#34; dataHost=\u0026#34;dhost1\u0026#34; database=\u0026#34;shopping\u0026#34; /\u0026gt; \u0026lt;dataNode name=\u0026#34;dn2\u0026#34; dataHost=\u0026#34;dhost2\u0026#34; database=\u0026#34;shopping\u0026#34; /\u0026gt; \u0026lt;dataNode name=\u0026#34;dn3\u0026#34; dataHost=\u0026#34;dhost3\u0026#34; database=\u0026#34;shopping\u0026#34; /\u0026gt; \u0026lt;dataNode name=\u0026#34;dn4\u0026#34; dataHost=\u0026#34;dhost1\u0026#34; database=\u0026#34;itcast\u0026#34; /\u0026gt; \u0026lt;dataNode name=\u0026#34;dn5\u0026#34; dataHost=\u0026#34;dhost2\u0026#34; database=\u0026#34;itcast\u0026#34; /\u0026gt; \u0026lt;dataNode name=\u0026#34;dn6\u0026#34; dataHost=\u0026#34;dhost3\u0026#34; database=\u0026#34;itcast\u0026#34; /\u0026gt; \u0026lt;dataHost name=\u0026#34;dhost1\u0026#34; maxCon=\u0026#34;1000\u0026#34; minCon=\u0026#34;10\u0026#34; balance=\u0026#34;0\u0026#34; writeType=\u0026#34;0\u0026#34; dbType=\u0026#34;mysql\u0026#34; dbDriver=\u0026#34;jdbc\u0026#34; switchType=\u0026#34;1\u0026#34; slaveThreshold=\u0026#34;100\u0026#34;\u0026gt; \u0026lt;heartbeat\u0026gt;select user()\u0026lt;/heartbeat\u0026gt; \u0026lt;writeHost host=\u0026#34;master\u0026#34; url=\u0026#34;jdbc:mysql://172.16.140.111:3306?allowPublicKeyRetrieval=true\u0026amp;amp;useSSL=false\u0026amp;amp;serverTimezone=Asia/Shanghai\u0026amp;amp;characterEncoding=utf8\u0026#34; user=\u0026#34;root\u0026#34; password=\u0026#34;123456\u0026#34; /\u0026gt; \u0026lt;/dataHost\u0026gt; \u0026lt;dataHost name=\u0026#34;dhost2\u0026#34; maxCon=\u0026#34;1000\u0026#34; minCon=\u0026#34;10\u0026#34; balance=\u0026#34;0\u0026#34; writeType=\u0026#34;0\u0026#34; dbType=\u0026#34;mysql\u0026#34; dbDriver=\u0026#34;jdbc\u0026#34; switchType=\u0026#34;1\u0026#34; slaveThreshold=\u0026#34;100\u0026#34;\u0026gt; \u0026lt;heartbeat\u0026gt;select user()\u0026lt;/heartbeat\u0026gt; \u0026lt;writeHost host=\u0026#34;master\u0026#34; url=\u0026#34;jdbc:mysql://172.16.140.112:3306?allowPublicKeyRetrieval=true\u0026amp;amp;useSSL=false\u0026amp;amp;serverTimezone=Asia/Shanghai\u0026amp;amp;characterEncoding=utf8\u0026#34; user=\u0026#34;root\u0026#34; password=\u0026#34;123456\u0026#34; /\u0026gt; \u0026lt;/dataHost\u0026gt; \u0026lt;dataHost name=\u0026#34;dhost3\u0026#34; maxCon=\u0026#34;1000\u0026#34; minCon=\u0026#34;10\u0026#34; balance=\u0026#34;0\u0026#34; writeType=\u0026#34;0\u0026#34; dbType=\u0026#34;mysql\u0026#34; dbDriver=\u0026#34;jdbc\u0026#34; switchType=\u0026#34;1\u0026#34; slaveThreshold=\u0026#34;100\u0026#34;\u0026gt; \u0026lt;heartbeat\u0026gt;select user()\u0026lt;/heartbeat\u0026gt; \u0026lt;writeHost host=\u0026#34;master\u0026#34; url=\u0026#34;jdbc:mysql://172.16.140.113:3306?allowPublicKeyRetrieval=true\u0026amp;amp;useSSL=false\u0026amp;amp;serverTimezone=Asia/Shanghai\u0026amp;amp;characterEncoding=utf8\u0026#34; user=\u0026#34;root\u0026#34; password=\u0026#34;123456\u0026#34; /\u0026gt; \u0026lt;/dataHost\u0026gt; \u0026lt;/mycat:schema\u0026gt; 其中，可以看到tb_log表的规则为mod-long。\n它调用了mod-long函数\n这个规则表示，它会根据主键id求模，模于3。结果为0，则落于第一个节点；结果为1，则落在第二个节点；结果为2，则落在第三个节点。\ntb_log表最终落在3个节点中，分别是 dn4、dn5、dn6 ，而具体的数据分别存储在 dhost1、 dhost2、dhost3的itcast数据库中。\nserver.xml 配置root用户既可以访问 SHOPPING 逻辑库，又可以访问ITCAST逻辑库。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 \u0026lt;user name=\u0026#34;root\u0026#34; defaultAccount=\u0026#34;true\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;password\u0026#34;\u0026gt;123456\u0026lt;/property\u0026gt; \u0026lt;property name=\u0026#34;schemas\u0026#34;\u0026gt;SHOPPING,ITCAST\u0026lt;/property\u0026gt; \u0026lt;!-- 表级 DML 权限设置 --\u0026gt; \u0026lt;!-- \u0026lt;privileges check=\u0026#34;true\u0026#34;\u0026gt; \u0026lt;schema name=\u0026#34;DB01\u0026#34; dml=\u0026#34;0110\u0026#34; \u0026gt; \u0026lt;table name=\u0026#34;TB_ORDER\u0026#34; dml=\u0026#34;1110\u0026#34;\u0026gt;\u0026lt;/table\u0026gt; \u0026lt;/schema\u0026gt; \u0026lt;/privileges\u0026gt;\t--\u0026gt;\t\u0026lt;/user\u0026gt; \u0026lt;user name=\u0026#34;user\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;password\u0026#34;\u0026gt;123456\u0026lt;/property\u0026gt; \u0026lt;property name=\u0026#34;schemas\u0026#34;\u0026gt;SHOPPING,ITCAST\u0026lt;/property\u0026gt; \u0026lt;property name=\u0026#34;readOnly\u0026#34;\u0026gt;true\u0026lt;/property\u0026gt; \u0026lt;/user\u0026gt; 测试 配置完毕后，重新启动MyCat\n查看逻辑库和逻辑表 1 2 3 show databases; use ITCAST; show tables; 可以看到逻辑库和逻辑表都正常添加了。\n创建表结构 1 2 3 4 5 6 7 8 9 10 11 12 13 14 CREATE TABLE tb_log ( id bigint(20) NOT NULL COMMENT \u0026#39;ID\u0026#39;, model_name varchar(200) DEFAULT NULL COMMENT \u0026#39;模块名\u0026#39;, model_value varchar(200) DEFAULT NULL COMMENT \u0026#39;模块值\u0026#39;, return_value varchar(200) DEFAULT NULL COMMENT \u0026#39;返回值\u0026#39;, return_class varchar(200) DEFAULT NULL COMMENT \u0026#39;返回值类型\u0026#39;, operate_user varchar(20) DEFAULT NULL COMMENT \u0026#39;操作用户\u0026#39;, operate_time varchar(20) DEFAULT NULL COMMENT \u0026#39;操作时间\u0026#39;, param_and_value varchar(500) DEFAULT NULL COMMENT \u0026#39;请求参数名及参数值\u0026#39;, operate_class varchar(200) DEFAULT NULL COMMENT \u0026#39;操作类\u0026#39;, operate_method varchar(200) DEFAULT NULL COMMENT \u0026#39;操作方法\u0026#39;, cost_time bigint(20) DEFAULT NULL COMMENT \u0026#39;执行方法耗时, 单位 ms\u0026#39;, source int(1) DEFAULT NULL COMMENT \u0026#39;来源 : 1 PC , 2 Android , 3 IOS\u0026#39;, PRIMARY KEY (id) ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4; 插入数据 1 2 3 4 5 6 INSERT INTO tb_log (id, model_name, model_value, return_value, return_class, operate_user, operate_time, param_and_value, operate_class, operate_method, cost_time，source) VALUES(\u0026#39;1\u0026#39;,\u0026#39;user\u0026#39;,\u0026#39;insert\u0026#39;,\u0026#39;success\u0026#39;,\u0026#39;java.lang.String\u0026#39;,\u0026#39;10001\u0026#39;,\u0026#39;2022-01-06 18:12:28\u0026#39;,\u0026#39;{\\\u0026#34;age\\\u0026#34;:\\\u0026#34;20\\\u0026#34;,\\\u0026#34;name\\\u0026#34;:\\\u0026#34;Tom\\\u0026#34;,\\\u0026#34;gender\\\u0026#34;:\\\u0026#34;1\\\u0026#34;}\u0026#39;,\u0026#39;cn.itcast.contro ller.UserController\u0026#39;,\u0026#39;insert\u0026#39;,\u0026#39;10\u0026#39;,1); INSERT INTO tb_log (id, model_name, model_value, return_value, return_class, operate_user, operate_time, param_and_value, operate_class, operate_method, cost_time，source) VALUES(\u0026#39;2\u0026#39;,\u0026#39;user\u0026#39;,\u0026#39;insert\u0026#39;,\u0026#39;success\u0026#39;,\u0026#39;java.lang.String\u0026#39;,\u0026#39;10001\u0026#39;,\u0026#39;2022-01-06 18:12:27\u0026#39;,\u0026#39;{\\\u0026#34;age\\\u0026#34;:\\\u0026#34;20\\\u0026#34;,\\\u0026#34;name\\\u0026#34;:\\\u0026#34;Tom\\\u0026#34;,\\\u0026#34;gender\\\u0026#34;:\\\u0026#34;1\\\u0026#34;}\u0026#39;,\u0026#39;cn.itcast.contro ller.UserController\u0026#39;,\u0026#39;insert\u0026#39;,\u0026#39;23\u0026#39;,1); INSERT INTO tb_log (id, model_name, model_value, return_value, return_class, operate_user, operate_time, param_and_value, operate_class, operate_method, cost_time，source) VALUES(\u0026#39;3\u0026#39;,\u0026#39;user\u0026#39;,\u0026#39;update\u0026#39;,\u0026#39;success\u0026#39;,\u0026#39;java.lang.String\u0026#39;,\u0026#39;10001\u0026#39;,\u0026#39;2022-01-06 18:16:45\u0026#39;,\u0026#39;{\\\u0026#34;age\\\u0026#34;:\\\u0026#34;20\\\u0026#34;,\\\u0026#34;name\\\u0026#34;:\\\u0026#34;Tom\\\u0026#34;,\\\u0026#34;gender\\\u0026#34;:\\\u0026#34;1\\\u0026#34;}\u0026#39;,\u0026#39;cn.itcast.contro ller.UserController\u0026#39;,\u0026#39;update\u0026#39;,\u0026#39;34\u0026#39;,1); INSERT INTO tb_log (id, model_name, model_value, return_value, return_class, operate_user, operate_time, param_and_value, operate_class, operate_method, cost_time，source) VALUES(\u0026#39;4\u0026#39;,\u0026#39;user\u0026#39;,\u0026#39;update\u0026#39;,\u0026#39;success\u0026#39;,\u0026#39;java.lang.String\u0026#39;,\u0026#39;10001\u0026#39;,\u0026#39;2022-01-06 18:16:45\u0026#39;,\u0026#39;{\\\u0026#34;age\\\u0026#34;:\\\u0026#34;20\\\u0026#34;,\\\u0026#34;name\\\u0026#34;:\\\u0026#34;Tom\\\u0026#34;,\\\u0026#34;gender\\\u0026#34;:\\\u0026#34;1\\\u0026#34;}\u0026#39;,\u0026#39;cn.itcast.contro ller.UserController\u0026#39;,\u0026#39;update\u0026#39;,\u0026#39;13\u0026#39;,2); INSERT INTO tb_log (id, model_name, model_value, return_value, return_class, operate_user, operate_time, param_and_value, operate_class, operate_method, cost_time，source) VALUES(\u0026#39;5\u0026#39;,\u0026#39;user\u0026#39;,\u0026#39;insert\u0026#39;,\u0026#39;success\u0026#39;,\u0026#39;java.lang.String\u0026#39;,\u0026#39;10001\u0026#39;,\u0026#39;2022-01-06 18:30:31\u0026#39;,\u0026#39;{\\\u0026#34;age\\\u0026#34;:\\\u0026#34;200\\\u0026#34;,\\\u0026#34;name\\\u0026#34;:\\\u0026#34;TomCat\\\u0026#34;,\\\u0026#34;gender\\\u0026#34;:\\\u0026#34;0\\\u0026#34;}\u0026#39;,\u0026#39;cn.itcast.co ntroller.UserController\u0026#39;,\u0026#39;insert\u0026#39;,\u0026#39;29\u0026#39;,3); INSERT INTO tb_log (id, model_name, model_value, return_value, return_class, operate_user, operate_time, param_and_value, operate_class, operate_method, cost_time，source) VALUES(\u0026#39;6\u0026#39;,\u0026#39;user\u0026#39;,\u0026#39;find\u0026#39;,\u0026#39;success\u0026#39;,\u0026#39;java.lang.String\u0026#39;,\u0026#39;10001\u0026#39;,\u0026#39;2022-01-06 18:30:31\u0026#39;,\u0026#39;{\\\u0026#34;age\\\u0026#34;:\\\u0026#34;200\\\u0026#34;,\\\u0026#34;name\\\u0026#34;:\\\u0026#34;TomCat\\\u0026#34;,\\\u0026#34;gender\\\u0026#34;:\\\u0026#34;0\\\u0026#34;}\u0026#39;,\u0026#39;cn.itcast.co ntroller.UserController\u0026#39;,\u0026#39;find\u0026#39;,\u0026#39;29\u0026#39;,2); 可以看到第一个节点中存放了id为3、6的数据\n第二个节点中存放了id为1、4的数据\n第三个节点中存放了id为2、5的数据\n分片规则 范围分片 介绍 根据指定的字段及其配置的范围与数据节点的对应情况，来决定该数据属于哪一个分片。\n配置 schema.xml 逻辑表配置 1 \u0026lt;table name=\u0026#34;TB_ORDER\u0026#34; dataNode=\u0026#34;dn1,dn2,dn3\u0026#34; rule=\u0026#34;auto-sharding-long\u0026#34; /\u0026gt; schema.xml 数据节点配置 1 2 3 \u0026lt;dataNode name=\u0026#34;dn1\u0026#34; dataHost=\u0026#34;dhost1\u0026#34; database=\u0026#34;db01\u0026#34; /\u0026gt; \u0026lt;dataNode name=\u0026#34;dn2\u0026#34; dataHost=\u0026#34;dhost2\u0026#34; database=\u0026#34;db01\u0026#34; /\u0026gt; \u0026lt;dataNode name=\u0026#34;dn3\u0026#34; dataHost=\u0026#34;dhost3\u0026#34; database=\u0026#34;db01\u0026#34; /\u0026gt; rule.xml 分片规则配置 1 2 3 4 5 6 7 8 9 10 11 \u0026lt;tableRule name=\u0026#34;auto-sharding-long\u0026#34;\u0026gt; \u0026lt;rule\u0026gt; \u0026lt;columns\u0026gt;id\u0026lt;/columns\u0026gt; \u0026lt;algorithm\u0026gt;rang-long\u0026lt;/algorithm\u0026gt; \u0026lt;/rule\u0026gt; \u0026lt;/tableRule\u0026gt; \u0026lt;function name=\u0026#34;rang-long\u0026#34; class=\u0026#34;io.mycat.route.function.AutoPartitionByLong\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;mapFile\u0026#34;\u0026gt;autopartition-long.txt\u0026lt;/property\u0026gt; \u0026lt;property name=\u0026#34;defaultNode\u0026#34;\u0026gt;0\u0026lt;/property\u0026gt; \u0026lt;/function\u0026gt; 分片规则配置属性含义: 属性 描述 columns 标识将要分片的表字段 algorithm 指定分片函数与function的对应关系 class 指定该分片算法对应的类 mapFile 对应的外部配置文件 type 默认值为0 ; 0 表示Integer , 1 表示String defaultNode 默认节点默认节点的所用:枚举分片时,如果碰到不识别的枚举值, 就让它路由到默认节点 ; 如果没有默认值,碰到不识别的则报错 。 在rule.xml中配置分片规则时，关联了一个映射配置文件 autopartition-long.txt，该配置文件的配置如下: 1 2 3 4 5 # range start-end ,data node index # K=1000,M=10000. 0-500M=0 500M-1000M=1 1000M-1500M=2 含义:0-500万之间的值，存储在0号数据节点(数据节点的索引从0开始);500万-1000万之间的数据存储在1号数据节点; 1000万-1500万的数据节点存储在2号节点;\n该分片规则，主要是针对于数字类型的字段适用。 在MyCat的入门程序中，我们使用的就是该分片规则。\n取模分片 介绍 根据指定的字段值与节点数量进行求模运算，根据运算结果，来决定该数据属于哪一个分片。\n配置 schema.xml 逻辑表配置: 1 2 3 4 \u0026lt;schema name=\u0026#34;ITCAST\u0026#34; checkSQLschema=\u0026#34;true\u0026#34; sqlMaxLimit=\u0026#34;100\u0026#34;\u0026gt; \u0026lt;!-- 取模 --\u0026gt; \u0026lt;table name=\u0026#34;tb_log\u0026#34; dataNode=\u0026#34;dn4,dn5,dn6\u0026#34; primaryKey=\u0026#34;id\u0026#34; rule=\u0026#34;mod-long\u0026#34; /\u0026gt; \u0026lt;/schema\u0026gt; schema.xml 数据节点配置: 1 2 3 \u0026lt;dataNode name=\u0026#34;dn4\u0026#34; dataHost=\u0026#34;dhost1\u0026#34; database=\u0026#34;itcast\u0026#34; /\u0026gt; \u0026lt;dataNode name=\u0026#34;dn5\u0026#34; dataHost=\u0026#34;dhost2\u0026#34; database=\u0026#34;itcast\u0026#34; /\u0026gt; \u0026lt;dataNode name=\u0026#34;dn6\u0026#34; dataHost=\u0026#34;dhost3\u0026#34; database=\u0026#34;itcast\u0026#34; /\u0026gt; rule.xml 分片规则配置: 1 2 3 4 5 6 7 8 9 \u0026lt;tableRule name=\u0026#34;mod-long\u0026#34;\u0026gt; \u0026lt;rule\u0026gt; \u0026lt;columns\u0026gt;id\u0026lt;/columns\u0026gt; \u0026lt;algorithm\u0026gt;mod-long\u0026lt;/algorithm\u0026gt; \u0026lt;/rule\u0026gt; \u0026lt;/tableRule\u0026gt; \u0026lt;function name=\u0026#34;mod-long\u0026#34; class=\u0026#34;io.mycat.route.function.PartitionByMod\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;count\u0026#34;\u0026gt;3\u0026lt;/property\u0026gt; \u0026lt;/function\u0026gt; 分片规则属性说明如下: 属性 描述 columns 标识将要分片的表字段 algorithm 指定分片函数与function的对应关系 class 指定该分片算法对应的类 count 数据节点的数量 该分片规则，主要是针对于数字类型的字段适用。在前面水平拆分的演示中，我们选择的就是取模分片。\n一致性hash分片 介绍 所谓一致性哈希，相同的哈希因子计算值总是被划分到相同的分区表中，不会因为分区节点的增加而改变原来数据的分区位置，有效的解决了分布式数据的拓容问题。\n配置 schema.xml 中逻辑表配置: 1 2 3 4 5 \u0026lt;schema name=\u0026#34;ITCAST\u0026#34; checkSQLschema=\u0026#34;true\u0026#34; sqlMaxLimit=\u0026#34;100\u0026#34;\u0026gt; \u0026lt;table name=\u0026#34;tb_log\u0026#34; dataNode=\u0026#34;dn4,dn5,dn6\u0026#34; primaryKey=\u0026#34;id\u0026#34; rule=\u0026#34;mod-long\u0026#34; /\u0026gt; \u0026lt;!-- 一致性hash --\u0026gt; \u0026lt;table name=\u0026#34;tb_order\u0026#34; dataNode=\u0026#34;dn4,dn5,dn6\u0026#34; rule=\u0026#34;sharding-by-murmur\u0026#34; /\u0026gt; \u0026lt;/schema\u0026gt; schema.xml 中数据节点配置: 1 2 3 \u0026lt;dataNode name=\u0026#34;dn4\u0026#34; dataHost=\u0026#34;dhost1\u0026#34; database=\u0026#34;itcast\u0026#34; /\u0026gt; \u0026lt;dataNode name=\u0026#34;dn5\u0026#34; dataHost=\u0026#34;dhost2\u0026#34; database=\u0026#34;itcast\u0026#34; /\u0026gt; \u0026lt;dataNode name=\u0026#34;dn6\u0026#34; dataHost=\u0026#34;dhost3\u0026#34; database=\u0026#34;itcast\u0026#34; /\u0026gt; rule.xml 中分片规则配置: 1 2 3 4 5 6 7 8 9 10 11 \u0026lt;tableRule name=\u0026#34;sharding-by-murmur\u0026#34;\u0026gt; \u0026lt;rule\u0026gt; \u0026lt;columns\u0026gt;id\u0026lt;/columns\u0026gt; \u0026lt;algorithm\u0026gt;murmur\u0026lt;/algorithm\u0026gt; \u0026lt;/rule\u0026gt; \u0026lt;/tableRule\u0026gt; \u0026lt;function name=\u0026#34;murmur\u0026#34; class=\u0026#34;io.mycat.route.function.PartitionByMurmurHash\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;seed\u0026#34;\u0026gt;0\u0026lt;/property\u0026gt;\u0026lt;!-- 默认是0 --\u0026gt; \u0026lt;property name=\u0026#34;count\u0026#34;\u0026gt;3\u0026lt;/property\u0026gt; \u0026lt;property name=\u0026#34;virtualBucketTimes\u0026#34;\u0026gt;160\u0026lt;/property\u0026gt; \u0026lt;/function\u0026gt; 分片规则属性含义: 属性 描述 columns 标识将要分片的表字段 algorithm 指定分片函数与function的对应关系 class 指定该分片算法对应的类 seed 创建murmur_hash对象的种子，默认0 count 要分片的数据库节点数量，必须指定，否则没法分片 virtualBucketTimes 一个实际的数据库节点被映射为这么多虚拟节点，默认是160倍，也就是虚拟节点数是物理节点数的160 倍;virtualBucketTimes*count就是虚拟结点数量 ; weightMapFile 节点的权重，没有指定权重的节点默认是1。以properties文件的 格式填写，以从0开始到count-1的整数值也就是节点索引为key， 以节点权重值为值。所有权重值必须是正整数，否则以1代替 bucketMapPath 用于测试时观察各物理节点与虚拟节点的分布情况，如果指定了这个属性，会把虚拟节点的murmur hash值与物理节点的映射按行输出到这个文件，没有默认值，如果不指定，就不会输出任何东西。 测试 配置完毕后，重新启动MyCat，然后在mycat的命令行中，执行如下SQL创建表、并插入数据，查看数据分布情况。\n查看逻辑表 1 show tables; 可以看到在逻辑库ITCAST中已经出现逻辑表。\n创建表结构 1 2 3 4 5 create table tb_order( id varchar(100) not null primary key, money int null, content varchar(200) null ); 插入数据 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 INSERT INTO tb_order (id, money, content) VALUES (\u0026#39;b92fdaaf-6fc4-11ec-b831-482ae33c4a2d\u0026#39;, 10, \u0026#39;b92fdaf8-6fc4-11ec-b831-482ae33c4a2d\u0026#39;); INSERT INTO tb_order (id, money, content) VALUES (\u0026#39;b93482b6-6fc4-11ec-b831-482ae33c4a2d\u0026#39;, 20, \u0026#39;b93482d5-6fc4-11ec-b831-482ae33c4a2d\u0026#39;); INSERT INTO tb_order (id, money, content) VALUES (\u0026#39;b937e246-6fc4-11ec-b831-482ae33c4a2d\u0026#39;, 50, \u0026#39;b937e25d-6fc4-11ec-b831-482ae33c4a2d\u0026#39;); INSERT INTO tb_order (id, money, content) VALUES (\u0026#39;b93be2dd-6fc4-11ec-b831-482ae33c4a2d\u0026#39;, 100, \u0026#39;b93be2f9-6fc4-11ec-b831-482ae33c4a2d\u0026#39;); INSERT INTO tb_order (id, money, content) VALUES (\u0026#39;b93f2d68-6fc4-11ec-b831-482ae33c4a2d\u0026#39;, 130, \u0026#39;b93f2d7d-6fc4-11ec-b831-482ae33c4a2d\u0026#39;); INSERT INTO tb_order (id, money, content) VALUES (\u0026#39;b9451b98-6fc4-11ec-b831-482ae33c4a2d\u0026#39;, 30, \u0026#39;b9451bcc-6fc4-11ec-b831-482ae33c4a2d\u0026#39;); INSERT INTO tb_order (id, money, content) VALUES (\u0026#39;b9488ec1-6fc4-11ec-b831-482ae33c4a2d\u0026#39;, 560, \u0026#39;b9488edb-6fc4-11ec-b831-482ae33c4a2d\u0026#39;); INSERT INTO tb_order (id, money, content) VALUES (\u0026#39;b94be6e6-6fc4-11ec-b831-482ae33c4a2d\u0026#39;, 10, \u0026#39;b94be6ff-6fc4-11ec-b831-482ae33c4a2d\u0026#39;); INSERT INTO tb_order (id, money, content) VALUES (\u0026#39;b94ee10d-6fc4-11ec-b831-482ae33c4a2d\u0026#39;, 123, \u0026#39;b94ee12c-6fc4-11ec-b831-482ae33c4a2d\u0026#39;); INSERT INTO tb_order (id, money, content) VALUES (\u0026#39;b952492a-6fc4-11ec-b831-482ae33c4a2d\u0026#39;, 145, \u0026#39;b9524945-6fc4-11ec-b831-482ae33c4a2d\u0026#39;); INSERT INTO tb_order (id, money, content) VALUES (\u0026#39;b95553ac-6fc4-11ec-b831-482ae33c4a2d\u0026#39;, 543, \u0026#39;b95553c8-6fc4-11ec-b831-482ae33c4a2d\u0026#39;); INSERT INTO tb_order (id, money, content) VALUES (\u0026#39;b9581cdd-6fc4-11ec-b831-482ae33c4a2d\u0026#39;, 17, \u0026#39;b9581cfa-6fc4-11ec-b831-482ae33c4a2d\u0026#39;); INSERT INTO tb_order (id, money, content) VALUES (\u0026#39;b95afc0f-6fc4-11ec-b831-482ae33c4a2d\u0026#39;, 18, \u0026#39;b95afc2a-6fc4-11ec-b831-482ae33c4a2d\u0026#39;); INSERT INTO tb_order (id, money, content) VALUES (\u0026#39;b95daa99-6fc4-11ec-b831-482ae33c4a2d\u0026#39;, 134, \u0026#39;b95daab2-6fc4-11ec-b831-482ae33c4a2d\u0026#39;); INSERT INTO tb_order (id, money, content) VALUES (\u0026#39;b9667e3c-6fc4-11ec-b831-482ae33c4a2d\u0026#39;, 156, \u0026#39;b9667e60-6fc4-11ec-b831-482ae33c4a2d\u0026#39;); INSERT INTO tb_order (id, money, content) VALUES (\u0026#39;b96ab489-6fc4-11ec-b831-482ae33c4a2d\u0026#39;, 175, \u0026#39;b96ab4a5-6fc4-11ec-b831-482ae33c4a2d\u0026#39;); INSERT INTO tb_order (id, money, content) VALUES (\u0026#39;b96e2942-6fc4-11ec-b831-482ae33c4a2d\u0026#39;, 180, \u0026#39;b96e295b-6fc4-11ec-b831-482ae33c4a2d\u0026#39;); INSERT INTO tb_order (id, money, content) VALUES (\u0026#39;b97092ec-6fc4-11ec-b831-482ae33c4a2d\u0026#39;, 123, \u0026#39;b9709306-6fc4-11ec-b831-482ae33c4a2d\u0026#39;); INSERT INTO tb_order (id, money, content) VALUES (\u0026#39;b973727a-6fc4-11ec-b831-482ae33c4a2d\u0026#39;, 230, \u0026#39;b9737293-6fc4-11ec-b831-482ae33c4a2d\u0026#39;); INSERT INTO tb_order (id, money, content) VALUES (\u0026#39;b978840f-6fc4-11ec-b831-482ae33c4a2d\u0026#39;, 560, \u0026#39;b978843c-6fc4-11ec-b831-482ae33c4a2d\u0026#39;); 可以看到第一个节点数据库存放了5条数据，第二个节点数据库存放了6条数据，第三个节点数据库存放了9条数据。MyCat会根据id字段的hash值来分配去哪个节点数据库。\n枚举分片 介绍 通过在配置文件中配置可能的枚举值, 指定数据分布到不同数据节点上, 本规则适用于按照省份、性别、状态拆分数据等业务 。\n配置 schema.xml 中逻辑表配置: 1 2 3 4 5 6 \u0026lt;schema name=\u0026#34;ITCAST\u0026#34; checkSQLschema=\u0026#34;true\u0026#34; sqlMaxLimit=\u0026#34;100\u0026#34;\u0026gt; \u0026lt;table name=\u0026#34;tb_log\u0026#34; dataNode=\u0026#34;dn4,dn5,dn6\u0026#34; primaryKey=\u0026#34;id\u0026#34; rule=\u0026#34;mod-long\u0026#34; /\u0026gt; \u0026lt;table name=\u0026#34;tb_order\u0026#34; dataNode=\u0026#34;dn4,dn5,dn6\u0026#34; rule=\u0026#34;sharding-by-murmur\u0026#34; /\u0026gt; \u0026lt;!-- 枚举 --\u0026gt; \u0026lt;table name=\u0026#34;tb_user\u0026#34; dataNode=\u0026#34;dn4,dn5,dn6\u0026#34; rule=\u0026#34;sharding-by-intfile-enumstatus\u0026#34; /\u0026gt; \u0026lt;/schema\u0026gt; schema.xml 中数据节点配置: 1 2 3 \u0026lt;dataNode name=\u0026#34;dn4\u0026#34; dataHost=\u0026#34;dhost1\u0026#34; database=\u0026#34;itcast\u0026#34; /\u0026gt; \u0026lt;dataNode name=\u0026#34;dn5\u0026#34; dataHost=\u0026#34;dhost2\u0026#34; database=\u0026#34;itcast\u0026#34; /\u0026gt; \u0026lt;dataNode name=\u0026#34;dn6\u0026#34; dataHost=\u0026#34;dhost3\u0026#34; database=\u0026#34;itcast\u0026#34; /\u0026gt; rule.xml 中分片规则配置: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 \u0026lt;tableRule name=\u0026#34;sharding-by-intfile\u0026#34;\u0026gt; \u0026lt;rule\u0026gt; \u0026lt;columns\u0026gt;sharding_id\u0026lt;/columns\u0026gt; \u0026lt;algorithm\u0026gt;hash-int\u0026lt;/algorithm\u0026gt; \u0026lt;/rule\u0026gt; \u0026lt;/tableRule\u0026gt; \u0026lt;!-- 自己增加 tableRule --\u0026gt; \u0026lt;tableRule name=\u0026#34;sharding-by-intfile-enumstatus\u0026#34;\u0026gt; \u0026lt;rule\u0026gt; \u0026lt;columns\u0026gt;status\u0026lt;/columns\u0026gt; \u0026lt;algorithm\u0026gt;hash-int\u0026lt;/algorithm\u0026gt; \u0026lt;/rule\u0026gt; \u0026lt;/tableRule\u0026gt; \u0026lt;function name=\u0026#34;hash-int\u0026#34; class=\u0026#34;io.mycat.route.function.PartitionByFileMap\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;mapFile\u0026#34;\u0026gt;partition-hash-int.txt\u0026lt;/property\u0026gt; \u0026lt;/function\u0026gt; partition-hash-int.txt ，内容如下 : 1 2 3 1=0 2=1 3=2 分片规则属性含义: 属性 描述 columns 标识将要分片的表字段 algorithm 指定分片函数与function的对应关系 class 指定该分片算法对应的类 mapFile 对应的外部配置文件 type 默认值为0 ; 0 表示Integer , 1 表示String defaultNode 默认节点; 小于0标识不设置默认节点,大于等于0代表设置默认节点;默认节点的所用:枚举分片时,如果碰到不识别的枚举值,就让它路由到默认节点;如果没有默认值,碰到不识别的则报错。 测试 配置完毕后，重新启动MyCat，然后在mycat的命令行中，执行如下SQL创建表、并插入数据，查看数据分布情况。\n可以看到出现了新的逻辑表\n创建表结构 1 2 3 4 5 CREATE TABLE tb_user ( id bigint(20) NOT NULL COMMENT \u0026#39;ID\u0026#39;, username varchar(200) DEFAULT NULL COMMENT \u0026#39;姓名\u0026#39;, status int(2) DEFAULT \u0026#39;1\u0026#39; COMMENT \u0026#39;1: 未启用, 2: 已启用, 3: 已关闭\u0026#39;, PRIMARY KEY (`id`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4; 插入数据 1 2 3 4 5 6 7 8 9 10 insert into tb_user (id,username ,status) values(1,\u0026#39;Tom\u0026#39;,1); insert into tb_user (id,username ,status) values(2,\u0026#39;Cat\u0026#39;,2); insert into tb_user (id,username ,status) values(3,\u0026#39;Rose\u0026#39;,3); insert into tb_user (id,username ,status) values(4,\u0026#39;Coco\u0026#39;,2); insert into tb_user (id,username ,status) values(5,\u0026#39;Lily\u0026#39;,1); insert into tb_user (id,username ,status) values(6,\u0026#39;Tom\u0026#39;,1); insert into tb_user (id,username ,status) values(7,\u0026#39;Cat\u0026#39;,2); insert into tb_user (id,username ,status) values(8,\u0026#39;Rose\u0026#39;,3); insert into tb_user (id,username ,status) values(9,\u0026#39;Coco\u0026#39;,2); insert into tb_user (id,username ,status) values(10,\u0026#39;Lily\u0026#39;,1); status为1的数据在第一个节点数据库。\nstatus为2的数据在第二个节点数据库。\nstatus为3的数据在第三个节点数据库。\n插入status为4的数据 1 insert into tb_user (id,username ,status) values(11,\u0026#39;Itcast\u0026#39;,4); rule.xml 中分片规则添加配置： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \u0026lt;tableRule name=\u0026#34;sharding-by-intfile\u0026#34;\u0026gt; \u0026lt;rule\u0026gt; \u0026lt;columns\u0026gt;sharding_id\u0026lt;/columns\u0026gt; \u0026lt;algorithm\u0026gt;hash-int\u0026lt;/algorithm\u0026gt; \u0026lt;/rule\u0026gt; \u0026lt;/tableRule\u0026gt; \u0026lt;tableRule name=\u0026#34;sharding-by-intfile-enumstatus\u0026#34;\u0026gt; \u0026lt;rule\u0026gt; \u0026lt;columns\u0026gt;status\u0026lt;/columns\u0026gt; \u0026lt;algorithm\u0026gt;hash-int\u0026lt;/algorithm\u0026gt; \u0026lt;/rule\u0026gt; \u0026lt;/tableRule\u0026gt; \u0026lt;function name=\u0026#34;hash-int\u0026#34; class=\u0026#34;io.mycat.route.function.PartitionByFileMap\u0026#34;\u0026gt; \u0026lt;!-- 追加的配置：defaultNode --\u0026gt; \u0026lt;property name=\u0026#34;defaultNode\u0026#34;\u0026gt;2\u0026lt;/property\u0026gt; \u0026lt;property name=\u0026#34;mapFile\u0026#34;\u0026gt;partition-hash-int.txt\u0026lt;/property\u0026gt; \u0026lt;/function\u0026gt; 重启服务器后再次插入测试 1 insert into tb_user (id,username ,status) values(11,\u0026#39;Itcast\u0026#39;,4); 数据被插入到第三节点数据库中。\n应用指定算法 介绍 运行阶段由应用自主决定路由到那个分片, 直接根据字符子串(必须是数字)计算分片号。\n配置 schema.xml中逻辑表配置: 1 2 3 4 5 6 7 8 9 \u0026lt;schema name=\u0026#34;ITCAST\u0026#34; checkSQLschema=\u0026#34;true\u0026#34; sqlMaxLimit=\u0026#34;100\u0026#34;\u0026gt; \u0026lt;table name=\u0026#34;tb_log\u0026#34; dataNode=\u0026#34;dn4,dn5,dn6\u0026#34; primaryKey=\u0026#34;id\u0026#34; rule=\u0026#34;mod-long\u0026#34; /\u0026gt; \u0026lt;!-- 一致性hash --\u0026gt; \u0026lt;table name=\u0026#34;tb_order\u0026#34; dataNode=\u0026#34;dn4,dn5,dn6\u0026#34; rule=\u0026#34;sharding-by-murmur\u0026#34; /\u0026gt; \u0026lt;!-- 枚举 --\u0026gt; \u0026lt;table name=\u0026#34;tb_user\u0026#34; dataNode=\u0026#34;dn4,dn5,dn6\u0026#34; rule=\u0026#34;sharding-by-intfile-enumstatus\u0026#34; /\u0026gt; \u0026lt;!-- 应用指定算法 --\u0026gt; \u0026lt;table name=\u0026#34;tb_app\u0026#34; dataNode=\u0026#34;dn4,dn5,dn6\u0026#34; rule=\u0026#34;sharding-by-substring\u0026#34; /\u0026gt; \u0026lt;/schema\u0026gt; schema.xml 中数据节点配置: 1 2 3 \u0026lt;dataNode name=\u0026#34;dn4\u0026#34; dataHost=\u0026#34;dhost1\u0026#34; database=\u0026#34;itcast\u0026#34; /\u0026gt; \u0026lt;dataNode name=\u0026#34;dn5\u0026#34; dataHost=\u0026#34;dhost2\u0026#34; database=\u0026#34;itcast\u0026#34; /\u0026gt; \u0026lt;dataNode name=\u0026#34;dn6\u0026#34; dataHost=\u0026#34;dhost3\u0026#34; database=\u0026#34;itcast\u0026#34; /\u0026gt; rule.xml 中分片规则配置: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 \u0026lt;tableRule name=\u0026#34;sharding-by-substring\u0026#34;\u0026gt; \u0026lt;rule\u0026gt; \u0026lt;columns\u0026gt;id\u0026lt;/columns\u0026gt; \u0026lt;algorithm\u0026gt;sharding-by-substring\u0026lt;/algorithm\u0026gt; \u0026lt;/rule\u0026gt; \u0026lt;/tableRule\u0026gt; \u0026lt;function name=\u0026#34;sharding-by-substring\u0026#34; class=\u0026#34;io.mycat.route.function.PartitionDirectBySubString\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;startIndex\u0026#34;\u0026gt;0\u0026lt;/property\u0026gt; \u0026lt;!-- zero-based --\u0026gt; \u0026lt;property name=\u0026#34;size\u0026#34;\u0026gt;2\u0026lt;/property\u0026gt; \u0026lt;property name=\u0026#34;partitionCount\u0026#34;\u0026gt;3\u0026lt;/property\u0026gt; \u0026lt;property name=\u0026#34;defaultPartition\u0026#34;\u0026gt;0\u0026lt;/property\u0026gt; \u0026lt;/function\u0026gt; 分片规则属性含义: 属性 描述 columns 标识将要分片的表字段 algorithm 指定分片函数与function的对应关系 class 指定该分片算法对应的类 startIndex 字符子串起始索引 size 字符长度 partitionCount 分区(分片)数量 defaultPartition 默认分片(在分片数量定义时, 字符标示的分片编号不在分片数量内时, 使用默认分片) 示例说明：\nid=05-100000002 , 在此配置中代表根据id中从 startIndex=0，开始，截取siz=2位数字即 05，05就是获取的分区，如果没找到对应的分片则默认分配到defaultPartition。\n测试 配置完毕后，重新启动MyCat，然后在mycat的命令行中，执行如下SQL创建表、并插入数据，查看数据分布情况。\n创建表结构 1 2 3 4 5 CREATE TABLE tb_app ( id varchar(10) NOT NULL COMMENT \u0026#39;ID\u0026#39;, name varchar(200) DEFAULT NULL COMMENT \u0026#39;名称\u0026#39;, PRIMARY KEY (`id`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4; 插入数据 1 2 3 4 5 insert into tb_app (id,name) values(\u0026#39;0000001\u0026#39;,\u0026#39;Testx00001\u0026#39;); insert into tb_app (id,name) values(\u0026#39;0100001\u0026#39;,\u0026#39;Test100001\u0026#39;); insert into tb_app (id,name) values(\u0026#39;0100002\u0026#39;,\u0026#39;Test200001\u0026#39;); insert into tb_app (id,name) values(\u0026#39;0200001\u0026#39;,\u0026#39;Test300001\u0026#39;); insert into tb_app (id,name) values(\u0026#39;0200002\u0026#39;,\u0026#39;TesT400001\u0026#39;); id为00开头的数据在第一个节点数据库。\nid为01开头的数据在第二个节点数据库。\nid为02开头的数据在第三个节点数据库。\n固定分片hash算法 介绍 该算法类似于十进制的求模运算，但是为二进制的操作，例如，取 id 的二进制低 10 位 与 1111111111 进行位 \u0026amp; 运算，位与运算最小值为 0000000000，最大值为1111111111，转换为十 进制，也就是位于0-1023之间。\n特点:\n如果是求模，连续的值，分别分配到各个不同的分片;但是此算法会将连续的值可能分配到相同的 分片，降低事务处理的难度。 可以均匀分配，也可以非均匀分配。 分片字段必须为数字类型。 配置 schema.xml 中逻辑表配置: 1 2 \u0026lt;!-- 固定分片hash算法 --\u0026gt; \u0026lt;table name=\u0026#34;tb_longhash\u0026#34; dataNode=\u0026#34;dn4,dn5,dn6\u0026#34; rule=\u0026#34;sharding-by-long-hash\u0026#34; /\u0026gt; schema.xml 中数据节点配置: 1 2 3 \u0026lt;dataNode name=\u0026#34;dn4\u0026#34; dataHost=\u0026#34;dhost1\u0026#34; database=\u0026#34;itcast\u0026#34; /\u0026gt; \u0026lt;dataNode name=\u0026#34;dn5\u0026#34; dataHost=\u0026#34;dhost2\u0026#34; database=\u0026#34;itcast\u0026#34; /\u0026gt; \u0026lt;dataNode name=\u0026#34;dn6\u0026#34; dataHost=\u0026#34;dhost3\u0026#34; database=\u0026#34;itcast\u0026#34; /\u0026gt; rule.xml 中分片规则配置: 1 2 3 4 5 6 7 8 9 10 11 12 13 \u0026lt;tableRule name=\u0026#34;sharding-by-long-hash\u0026#34;\u0026gt; \u0026lt;rule\u0026gt; \u0026lt;columns\u0026gt;id\u0026lt;/columns\u0026gt; \u0026lt;algorithm\u0026gt;sharding-by-long-hash\u0026lt;/algorithm\u0026gt; \u0026lt;/rule\u0026gt; \u0026lt;/tableRule\u0026gt; \u0026lt;!-- 分片总长度为1024，count与length数组长度必须一致; --\u0026gt; \u0026lt;function name=\u0026#34;sharding-by-long-hash\u0026#34; class=\u0026#34;io.mycat.route.function.PartitionByLong\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;partitionCount\u0026#34;\u0026gt;2,1\u0026lt;/property\u0026gt; \u0026lt;property name=\u0026#34;partitionLength\u0026#34;\u0026gt;256,512\u0026lt;/property\u0026gt; \u0026lt;/function\u0026gt; 分片规则属性含义: 属性 描述 columns 标识将要分片的表字段名 algorithm 指定分片函数与function的对应关系 class 指定该分片算法对应的类 partitionCount 分片个数列表 partitionLength 分片范围列表 约束: 1). 分片长度 : 默认最大2^10 , 为 1024 ; 2). count, length的数组长度必须是一致的 ;\n以上分为三个分区:0-255,256-511,512-1023\n测试 配置完毕后，重新启动MyCat，然后在mycat的命令行中，执行如下SQL创建表、并插入数据，查看数据分布情况。\n创建表结构 1 2 3 4 5 6 CREATE TABLE tb_longhash ( id int(11) NOT NULL COMMENT \u0026#39;ID\u0026#39;, name varchar(200) DEFAULT NULL COMMENT \u0026#39;名称\u0026#39;, firstChar char(1) COMMENT \u0026#39;首字母\u0026#39;, PRIMARY KEY (`id`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4; 插入数据 1 2 3 4 5 6 7 8 9 10 11 12 insert into tb_longhash (id,name,firstChar) values(1,\u0026#39;七匹狼\u0026#39;,\u0026#39;Q\u0026#39;); insert into tb_longhash (id,name,firstChar) values(2,\u0026#39;八匹狼\u0026#39;,\u0026#39;B\u0026#39;); insert into tb_longhash (id,name,firstChar) values(3,\u0026#39;九匹狼\u0026#39;,\u0026#39;J\u0026#39;); insert into tb_longhash (id,name,firstChar) values(4,\u0026#39;十匹狼\u0026#39;,\u0026#39;S\u0026#39;); insert into tb_longhash (id,name,firstChar) values(5,\u0026#39;六匹狼\u0026#39;,\u0026#39;L\u0026#39;); insert into tb_longhash (id,name,firstChar) values(6,\u0026#39;五匹狼\u0026#39;,\u0026#39;W\u0026#39;); insert into tb_longhash (id,name,firstChar) values(7,\u0026#39;四匹狼\u0026#39;,\u0026#39;S\u0026#39;); insert into tb_longhash (id,name,firstChar) values(8,\u0026#39;三匹狼\u0026#39;,\u0026#39;S\u0026#39;); insert into tb_longhash (id,name,firstChar) values(9,\u0026#39;两匹狼\u0026#39;,\u0026#39;L\u0026#39;); insert into tb_longhash (id,name,firstChar) values(256,\u0026#39;两匹狼\u0026#39;,\u0026#39;L\u0026#39;); insert into tb_longhash (id,name,firstChar) values(889,\u0026#39;两匹狼\u0026#39;,\u0026#39;L\u0026#39;); insert into tb_longhash (id,name,firstChar) values(1089,\u0026#39;两匹狼\u0026#39;,\u0026#39;L\u0026#39;); id为1-9和1089的数据在第一个节点数据库上。\nid为256的数据在第二个节点数据库上。\nid为889的数据在第三个节点数据库上。\n字符串hash解析算法 介绍 截取字符串中的指定位置的子字符串，进行hash算法，算出分片。\n配置 schema.xml 中逻辑表配置: 1 2 \u0026lt;!-- 字符串hash解析算法 --\u0026gt; \u0026lt;table name=\u0026#34;tb_strhash\u0026#34; dataNode=\u0026#34;dn4,dn5\u0026#34; rule=\u0026#34;sharding-by-stringhash\u0026#34; /\u0026gt; schema.xml 中数据节点配置: 1 2 \u0026lt;dataNode name=\u0026#34;dn4\u0026#34; dataHost=\u0026#34;dhost1\u0026#34; database=\u0026#34;itcast\u0026#34; /\u0026gt; \u0026lt;dataNode name=\u0026#34;dn5\u0026#34; dataHost=\u0026#34;dhost2\u0026#34; database=\u0026#34;itcast\u0026#34; /\u0026gt; rule.xml 中分片规则配置: 1 2 3 4 5 6 7 8 9 10 11 12 \u0026lt;tableRule name=\u0026#34;sharding-by-stringhash\u0026#34;\u0026gt; \u0026lt;rule\u0026gt; \u0026lt;columns\u0026gt;name\u0026lt;/columns\u0026gt; \u0026lt;algorithm\u0026gt;sharding-by-stringhash\u0026lt;/algorithm\u0026gt; \u0026lt;/rule\u0026gt; \u0026lt;/tableRule\u0026gt; \u0026lt;function name=\u0026#34;sharding-by-stringhash\u0026#34; class=\u0026#34;io.mycat.route.function.PartitionByString\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;partitionLength\u0026#34;\u0026gt;512\u0026lt;/property\u0026gt; \u0026lt;!-- zero-based --\u0026gt; \u0026lt;property name=\u0026#34;partitionCount\u0026#34;\u0026gt;2\u0026lt;/property\u0026gt; \u0026lt;property name=\u0026#34;hashSlice\u0026#34;\u0026gt;0:2\u0026lt;/property\u0026gt;\u0026lt;!-- 这里表示从索引为0的位置，截取到索引为2的位置 --\u0026gt; \u0026lt;/function\u0026gt; 分片规则属性含义: 属性 描述 columns 标识将要分片的表字段 algorithm 指定分片函数与function的对应关系 class 指定该分片算法对应的类 partitionLength hash求模基数 ; length*count=1024 (出于性能考虑) partitionCount 分区数 hashSlice hash运算位 , 根据子字符串的hash运算 ; 0 代表 str.length() , -1 代表 str.length()-1 , 大于0只代表数字自身 ; 可以理解 为substring(start，end)，start为0则只表示0 示例说明： 测试 配置完毕后，重新启动MyCat，然后在mycat的命令行中，执行如下SQL创建表、并插入数据，查看数据分布情况。\n创建表结构 1 2 3 4 create table tb_strhash( name varchar(20) primary key, content varchar(100) )engine=InnoDB DEFAULT CHARSET=utf8mb4; 插入数据 1 2 3 4 5 INSERT INTO tb_strhash (name,content) VALUES(\u0026#39;T1001\u0026#39;, UUID()); INSERT INTO tb_strhash (name,content) VALUES(\u0026#39;ROSE\u0026#39;, UUID()); INSERT INTO tb_strhash (name,content) VALUES(\u0026#39;JERRY\u0026#39;, UUID()); INSERT INTO tb_strhash (name,content) VALUES(\u0026#39;CRISTINA\u0026#39;, UUID()); INSERT INTO tb_strhash (name,content) VALUES(\u0026#39;TOMCAT\u0026#39;, UUID()); 第一个节点数据库存放了两个数据。\n第二个节点数据库存放了三个数据。\n按天分片算法 介绍 按照日期及对应的时间周期来分片。\n配置 schema.xml 中逻辑表配置: 1 2 \u0026lt;!-- 按天分片 --\u0026gt; \u0026lt;table name=\u0026#34;tb_datepart\u0026#34; dataNode=\u0026#34;dn4,dn5,dn6\u0026#34; rule=\u0026#34;sharding-by-date\u0026#34; /\u0026gt; schema.xml 中数据节点配置: 1 2 3 \u0026lt;dataNode name=\u0026#34;dn4\u0026#34; dataHost=\u0026#34;dhost1\u0026#34; database=\u0026#34;itcast\u0026#34; /\u0026gt; \u0026lt;dataNode name=\u0026#34;dn5\u0026#34; dataHost=\u0026#34;dhost2\u0026#34; database=\u0026#34;itcast\u0026#34; /\u0026gt; \u0026lt;dataNode name=\u0026#34;dn6\u0026#34; dataHost=\u0026#34;dhost3\u0026#34; database=\u0026#34;itcast\u0026#34; /\u0026gt; rule.xml 中分片规则配置: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 \u0026lt;tableRule name=\u0026#34;sharding-by-date\u0026#34;\u0026gt; \u0026lt;rule\u0026gt; \u0026lt;columns\u0026gt;create_time\u0026lt;/columns\u0026gt; \u0026lt;algorithm\u0026gt;sharding-by-date\u0026lt;/algorithm\u0026gt; \u0026lt;/rule\u0026gt; \u0026lt;/tableRule\u0026gt; \u0026lt;function name=\u0026#34;sharding-by-date\u0026#34; class=\u0026#34;io.mycat.route.function.PartitionByDate\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;dateFormat\u0026#34;\u0026gt;yyyy-MM-dd\u0026lt;/property\u0026gt; \u0026lt;property name=\u0026#34;sBeginDate\u0026#34;\u0026gt;2022-01-01\u0026lt;/property\u0026gt; \u0026lt;property name=\u0026#34;sEndDate\u0026#34;\u0026gt;2022-01-30\u0026lt;/property\u0026gt; \u0026lt;property name=\u0026#34;sPartionDay\u0026#34;\u0026gt;10\u0026lt;/property\u0026gt; \u0026lt;/function\u0026gt; \u0026lt;!-- 从开始时间开始，每10天为一个分片，到达结束时间之后，会重复开始分片插入配置表的 dataNode 的分片，必须和分片规则数量一致，例如 2022-01-01 到 2022-12-31 ，每 10天一个分片，一共需要37个分片。 --\u0026gt; 分片规则属性含义: 属性 描述 columns 标识将要分片的表字段 algorithm 指定分片函数与function的对应关系 class 指定该分片算法对应的类 dateFormat 日期格式 sBeginDate 开始日期 sEndDate 结束日期，如果配置了结束日期，则代码数据到达了这个日期的分片后，会重复从开始分片插入 sPartionDay 分区天数，默认值 10 ，从开始日期算起，每个10天一个分区 测试 配置完毕后，重新启动MyCat，然后在mycat的命令行中，执行如下SQL创建表、并插入数据，查看数据分布情况。\n创建表结构 1 2 3 4 create table tb_datepart( id bigint not null comment \u0026#39;ID\u0026#39; primary key, name varchar(100) null comment \u0026#39;姓名\u0026#39;, create_time date null ); 插入数据 1 2 3 4 5 6 7 insert into tb_datepart(id,name ,create_time) values(1,\u0026#39;Tom\u0026#39;,\u0026#39;2022-01-01\u0026#39;); insert into tb_datepart(id,name ,create_time) values(2,\u0026#39;Cat\u0026#39;,\u0026#39;2022-01-10\u0026#39;); insert into tb_datepart(id,name ,create_time) values(3,\u0026#39;Rose\u0026#39;,\u0026#39;2022-01-11\u0026#39;); insert into tb_datepart(id,name ,create_time) values(4,\u0026#39;Coco\u0026#39;,\u0026#39;2022-01-20\u0026#39;); insert into tb_datepart(id,name ,create_time) values(5,\u0026#39;Rose2\u0026#39;,\u0026#39;2022-01-21\u0026#39;); insert into tb_datepart(id,name ,create_time) values(6,\u0026#39;Coco2\u0026#39;,\u0026#39;2022-01-30\u0026#39;); insert into tb_datepart(id,name ,create_time) values(7,\u0026#39;Coco3\u0026#39;,\u0026#39;2022-01-31\u0026#39;); 1-10天，30-31天的数据在第一节点数据库。\n11-20天的数据在第二节点数据库。\n21-30天的数据在第三节点数据库。\n自然月分片 介绍 使用场景为按照月份来分片, 每个自然月为一个分片。\n配置 schema.xml中逻辑表配置: 1 2 \u0026lt;!-- 按自然月分片 --\u0026gt; \u0026lt;table name=\u0026#34;tb_monthpart\u0026#34; dataNode=\u0026#34;dn4,dn5,dn6\u0026#34; rule=\u0026#34;sharding-by-month\u0026#34; /\u0026gt; schema.xml 中数据节点配置: 1 2 3 \u0026lt;dataNode name=\u0026#34;dn4\u0026#34; dataHost=\u0026#34;dhost1\u0026#34; database=\u0026#34;itcast\u0026#34; /\u0026gt; \u0026lt;dataNode name=\u0026#34;dn5\u0026#34; dataHost=\u0026#34;dhost2\u0026#34; database=\u0026#34;itcast\u0026#34; /\u0026gt; \u0026lt;dataNode name=\u0026#34;dn6\u0026#34; dataHost=\u0026#34;dhost3\u0026#34; database=\u0026#34;itcast\u0026#34; /\u0026gt; rule.xml 中分片规则配置: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 \u0026lt;tableRule name=\u0026#34;sharding-by-month\u0026#34;\u0026gt; \u0026lt;rule\u0026gt; \u0026lt;columns\u0026gt;create_time\u0026lt;/columns\u0026gt; \u0026lt;algorithm\u0026gt;partbymonth\u0026lt;/algorithm\u0026gt; \u0026lt;/rule\u0026gt; \u0026lt;/tableRule\u0026gt; \u0026lt;function name=\u0026#34;partbymonth\u0026#34; class=\u0026#34;io.mycat.route.function.PartitionByMonth\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;dateFormat\u0026#34;\u0026gt;yyyy-MM-dd\u0026lt;/property\u0026gt; \u0026lt;property name=\u0026#34;sBeginDate\u0026#34;\u0026gt;2022-01-01\u0026lt;/property\u0026gt; \u0026lt;property name=\u0026#34;sEndDate\u0026#34;\u0026gt;2022-03-31\u0026lt;/property\u0026gt; \u0026lt;/function\u0026gt; \u0026lt;!-- 从开始时间开始，一个月为一个分片，到达结束时间之后，会重复开始分片插入配置表的 dataNode 的分片，必须和分片规则数量一致，例如 2022-01-01 到 2022-12-31 ，一 共需要12个分片。 --\u0026gt; 分片规则属性含义: 属性 描述 columns 标识将要分片的表字段 algorithm 指定分片函数与function的对应关系 class 指定该分片算法对应的类 dateFormat 日期格式 sBeginDate 开始日期 sEndDate 结束日期，如果配置了结束日期，则代码数据到达了这个日期的分片后，会重复从开始分片插入 测试 配置完毕后，重新启动MyCat，然后在mycat的命令行中，执行如下SQL创建表、并插入数据，查看数据分布情况。\n创建表结构 1 2 3 4 create table tb_monthpart( id bigint not null comment \u0026#39;ID\u0026#39; primary key, name varchar(100) null comment \u0026#39;姓名\u0026#39;, create_time date null ); 插入数据 1 2 3 4 5 6 7 8 9 insert into tb_monthpart(id,name ,create_time) values(1,\u0026#39;Tom\u0026#39;,\u0026#39;2022-01-01\u0026#39;); insert into tb_monthpart(id,name ,create_time) values(2,\u0026#39;Cat\u0026#39;,\u0026#39;2022-01-10\u0026#39;); insert into tb_monthpart(id,name ,create_time) values(3,\u0026#39;Rose\u0026#39;,\u0026#39;2022-01-31\u0026#39;); insert into tb_monthpart(id,name ,create_time) values(4,\u0026#39;Coco\u0026#39;,\u0026#39;2022-02-20\u0026#39;); insert into tb_monthpart(id,name ,create_time) values(5,\u0026#39;Rose2\u0026#39;,\u0026#39;2022-02-25\u0026#39;); insert into tb_monthpart(id,name ,create_time) values(6,\u0026#39;Coco2\u0026#39;,\u0026#39;2022-03-10\u0026#39;); insert into tb_monthpart(id,name ,create_time) values(7,\u0026#39;Coco3\u0026#39;,\u0026#39;2022-03-31\u0026#39;); insert into tb_monthpart(id,name ,create_time) values(8,\u0026#39;Coco4\u0026#39;,\u0026#39;2022-04-10\u0026#39;); insert into tb_monthpart(id,name ,create_time) values(9,\u0026#39;Coco5\u0026#39;,\u0026#39;2022-04-30\u0026#39;); 一月份和四月份的数据在第一节点数据库。\n二月份的数据在第二节点数据库。\n三月份的数据在第三点节数据库。\nMyCat管理及监控 MyCat原理 在MyCat中，当执行一条SQL语句时，MyCat需要进行SQL解析、分片分析、路由分析、读写分离分析 等操作，最终经过一系列的分析决定将当前的SQL语句到底路由到那几个(或哪一个)节点数据库，数据 库将数据执行完毕后，如果有返回的结果，则将结果返回给MyCat，最终还需要在MyCat中进行结果合 并、聚合处理、排序处理、分页处理等操作，最终再将结果返回给客户端。\n而在MyCat的使用过程中，MyCat官方也提供了一个管理监控平台MyCat-Web(MyCat-eye)。 Mycat-web 是 Mycat 可视化运维的管理和监控平台，弥补了 Mycat 在监控上的空白。帮 Mycat 分担统计任务和配置管理任务。Mycat-web 引入了 ZooKeeper 作为配置中心，可以管理多个节 点。Mycat-web 主要管理和监控 Mycat 的流量、连接、活动线程和内存等，具备 IP 白名单、邮 件告警等模块，还可以统计 SQL 并分析慢 SQL 和高频 SQL 等。为优化 SQL 提供依据。\nMyCat管理 Mycat默认开通2个端口，可以在server.xml中进行修改。\n8066 数据访问端口，即进行 DML 和 DDL 操作。 9066 数据库管理端口，即 mycat 服务管理控制功能，用于管理mycat的整个集群状态 连接MyCat的管理控制台: 1 mysql -h 172.16.140.111 -p 9066 -uroot -p123456 命令 含义 show @@help 查看Mycat管理工具帮助文档 show @@version 查看Mycat的版本 reload @@config 重新加载Mycat的配置文件 show @@datdsource 查看Mycat的数据源信息 show @@datanode 查看Mycat现有的分片节点信息 show @@threadpool 查看Mycat的线程池信息 show @@sql 查看执行的SQL show @@sql.sum 查看执行的SQL统计 示例 查看Mycat管理工具帮助文档 1 show @@help; 查看Mycat版本 1 show @@version 查看Mycat的数据源信息 1 show @@datasource; 查看Mycat现有的分片节点信息 1 show @@datanode; 查看Mycat的线程池信息 1 show @@threadpool; 查看执行的sql 1 show @@sql; 查看执行的SQL统计 1 show @@sql.sum; 重新加载Mycat配置文件 1). 修改配置文件\nschema.xml 逻辑表添加配置\n1 2 \u0026lt;!-- 测试 --\u0026gt; \u0026lt;table name=\u0026#34;tb_dbc\u0026#34; dataNode=\u0026#34;dn4,dn5,dn6\u0026#34; rule=\u0026#34;sharding-by-date\u0026#34; /\u0026gt; 2). 重载配置文件\n1 reload @@config; 3). 查询所有表\n1 show tables; MyCat-eye 介绍 Mycat-web(Mycat-eye)是对mycat-server提供监控服务，功能不局限于对mycat-server使 用。他通过JDBC连接对Mycat、Mysql监控，监控远程服务器(目前仅限于linux系统)的cpu、内 存、网络、磁盘。\nMycat-eye运行过程中需要依赖zookeeper，因此需要先安装zookeeper。\n安装 zookeeper安装 上传zookeeper安装包 1 scp zookeeper-3.4.6.tar.gz root@172.16.140.111:/opt 解压 1 tar -zxvf zookeeper-3.4.6.tar.gz -C /usr/local/ 创建数据存放目录 1 mkdir /usr/local/zookeeper-3.4.6/data 修改配置文件名称 1 2 cd /usr/local/zookeeper-3.4.6/conf mv zoo_sample.cfg zoo.cfg 编辑zoo.cfg文件 1 vim zoo.cfg 配置 1 2 # 配置数据存放目录 dataDir=/usr/local/zookeeper-3.4.6/data 启动Zookeeper 1 2 cd .. bin/zkServer.sh start 查看Zookeeper状态 1 bin/zkServer.sh status 看到这个表示Zookeeper已经启动完成\nMycat-web安装 上传Mycat-web安装包 1 scp Mycat-web.tar.gz root@172.16.140.111:/opt 解压 1 tar -zxvf Mycat-web.tar.gz -C /usr/local/ 目录介绍 1 2 3 4 5 6 etc ----\u0026gt; jetty配置文件 lib ----\u0026gt; 依赖jar包 mycat-web ----\u0026gt; mycat-web项目 readme.txt start.jar ----\u0026gt; 启动jar start.sh ----\u0026gt; linux启动脚本 启动 1 sh start.sh 挂起程序 按control-z挂起程序\n开放8082端口 1 2 firewall-cmd --zone=public --add-port=8082/tcp --permanent firewall-cmd --reload 将程序调回前端运行 1 fg 1 访问 1 http://172.16.140.111:8082/mycat 启动成功 如果Zookeeper与Mycat-web不在同一台服务器上 , 需要设置Zookeeper的地址 ; 在/usr/local/mycat-web/mycat-web/WEB-INF/classes/mycat.properties文件中配置 : zookeeper=localhost:2181\n访问 http://172.16.140.111:8082/mycat\n配置 开启MyCat的实时统计功能(server.xml) 1 \u0026lt;property name=\u0026#34;useSqlStat\u0026#34;\u0026gt;1\u0026lt;/property\u0026gt; \u0026lt;!-- 1为开启实时统计、0为关闭 --\u0026gt; 在Mycat监控界面配置服务地址 测试 配置好了之后，我们可以通过MyCat执行一系列的增删改查的测试，然后过一段时间之后，打开mycat-eye的管理界面，查看mycat-eye监控到的数据信息。\n性能监控 物理节点 \u0026mdash;\u0026ndash;由于以下的内容，没有数据显示，这里使用他人的截图\u0026mdash;\u0026ndash;\nSQL统计 SQL表分析 SQL监控 高频SQL ","date":"2025-11-27T20:00:28+08:00","permalink":"https://YLine-hub.github.io/p/mysqlmysql%E8%BF%90%E7%BB%B4-%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8mycat/","title":"[MySQL]MySQL运维-分库分表(MyCat)"},{"content":"MySQL运维-主从复制 概述 主从复制是指将主数据库的 DDL 和 DML 操作通过二进制日志传到从库服务器中，然后在从库上对这 些日志重新执行(也叫重做)，从而使得从库和主库的数据保持同步。\nMySQL支持一台主库同时向多台从库进行复制， 从库同时也可以作为其他从服务器的主库，实现链状复制。\nMySQL 复制的优点主要包含以下三个方面:\n主库出现问题，可以快速切换到从库提供服务。 实现读写分离，降低主库的访问压力。 可以在从库中执行备份，以避免备份期间影响主库服务。 原理 MySQL主从复制的核心就是二进制日志，具体的过程如下:\n从上图来看，复制分成三步:\nMaster 主库在事务提交时，会把数据变更记录在二进制日志文件 Binlog 中。 从库读取主库的二进制日志文件 Binlog ，写入到从库的中继日志 Relay Log 。 slave重做中继日志中的事件，将改变反映它自己的数据。 搭建 准备 准备好两台服务器之后，在上述的两台服务器中分别安装好MySQL，并完成基础的初始化准备(安装、 密码配置等操作)工作。 其中:\n172.16.140.101 作为主服务器master 172.16.140.102 作为从服务器slave 主库配置 修改配置文件 /etc/my.cnf 1 2 3 4 5 6 7 8 #mysql 服务ID，保证整个集群环境中唯一，取值范围:1 – 232-1，默认为1 server-id=1 #是否只读,1 代表只读, 0 代表读写 read-only=0 #忽略的数据, 指不需要同步的数据库 #binlog-ignore-db=mysql #指定同步的数据库 #binlog-do-db=db01 重启MySQL服务器 1 systemctl restart mysqld 登录mysql，创建远程连接的账号，并授予主从复制权限 创建itcast用户，并设置密码，该用户可在任意主机连接该MySQL服务 1 CREATE USER \u0026#39;itcast\u0026#39;@\u0026#39;%\u0026#39; IDENTIFIED WITH mysql_native_password BY \u0026#39;Root@123456\u0026#39; ; 为\u0026rsquo;itcast\u0026rsquo;@\u0026rsquo;%\u0026rsquo; 用户分配主从复制权限 1 GRANT REPLICATION SLAVE ON *.* TO \u0026#39;itcast\u0026#39;@\u0026#39;%\u0026#39;; 通过指令，查看二进制日志坐标 1 show master status; 字段含义说明:\nfile : 从哪个日志文件开始推送日志文件 position : 从哪个位置开始推送日志 binlog_ignore_db : 指定不需要同步的数据库 从库配置 修改配置文件 /etc/my.cnf 1 2 3 4 #mysql 服务ID，保证整个集群环境中唯一，取值范围:1 – 2^32-1，和主库不一样即可 server-id=2 #是否只读,1 代表只读, 0 代表读写 read-only=1 重新启动MySQL服务 1 systemctl restart mysqld 登录mysql，设置主库配置 1 CHANGE REPLICATION SOURCE TO SOURCE_HOST=\u0026#39;172.16.140.101\u0026#39;, SOURCE_USER=\u0026#39;itcast\u0026#39;, SOURCE_PASSWORD=\u0026#39;Root@123456\u0026#39;, SOURCE_LOG_FILE=\u0026#39;binlog.000019\u0026#39;, SOURCE_LOG_POS=656; 上述是8.0.23中的语法。如果mysql是 8.0.23 之前的版本，执行如下SQL:\n1 CHANGE MASTER TO MASTER_HOST=\u0026#39;172.16.140.101\u0026#39;, MASTER_USER=\u0026#39;itcast\u0026#39;, MASTER_PASSWORD=\u0026#39;Root@123456\u0026#39;, MASTER_LOG_FILE=\u0026#39;binlog.000019\u0026#39;, MASTER_LOG_POS=656; 参数 含义 8.0.23之前 SOURCE_HOST 主库IP地址 MASTER_HOST SOURCE_USER 连接主库的用户名 MASTER_USER SOURCE_PASSWORD 连接主库的密码 MASTER_PASSWORD SOURCE_LOG_FILE binlog日志文件名 MASTER_LOG_FILE SOURCE_LOG_POS binlog日志文件位置 MASTER_LOG_POS 开启同步操作 1 2 start replica ; #8.0.22之后 start slave ; #8.0.22之前 查看主从同步状态 1 2 show replica status\\G ; #8.0.22之后 show slave status\\G ; #8.0.22之前 只有当两个都为yes，才表示主从配置成功\n测试 在主库 172.16.140.101 上创建数据库、表，并插入数据 1 2 3 4 5 6 7 8 9 create database db02; use db02; create table tb_user( id int(11) primary key not null auto_increment, name varchar(50) not null, sex varchar(1) )engine=innodb default charset=utf8mb4; insert into tb_user(id,name,sex) values(null,\u0026#39;Tom\u0026#39;, \u0026#39;1\u0026#39;),(null,\u0026#39;Trigger\u0026#39;,\u0026#39;0\u0026#39;), (null,\u0026#39;Dawn\u0026#39;,\u0026#39;1\u0026#39;); 在从库 172.16.140.102 中查询数据，验证主从是否同步 可以看到主库创建的数据，从库同时能获取到。\n","date":"2025-11-27T14:48:17+08:00","permalink":"https://YLine-hub.github.io/p/mysqlmysql%E8%BF%90%E7%BB%B4-%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/","title":"[MySQL]MySQL运维-主从复制"},{"content":"MySQL运维-日志 错误日志 错误日志是 MySQL 中最重要的日志之一，它记录了当 mysqld 启动和停止时，以及服务器在运行过程中发生任何严重错误时的相关信息。当数据库出现任何故障导致无法正常使用时，建议首先查看此日志。\n该日志是默认开启的，默认存放目录 /var/log/，默认的日志文件名为 mysqld.log。查看日志位置:\n1 show variables like \u0026#39;%log_error%\u0026#39;; 可以看到log_error的配置信息为stderr，表示 MySQL 错误日志输出到标准错误流，而不是写入到具体的文件。\n启用log_error my.cnf\n1 2 3 [mysqld] ... log-error = /usr/local/mysql/log/mysqld.log 报错\n1 Job for mysqld.service failed because the control process exited with error code. See \u0026#34;systemctl status mysqld.service\u0026#34; and \u0026#34;journalctl -xe\u0026#34; for details. 原因：log目录没有权限\n解决方法：设置log目录所有者/组为mysql\n1 chown mysql:mysql /usr/local/mysql/log 查看mysqld.log文件 1 cat /usr/local/mysql/log/mysqld.log 查看日志文件位置 1 show variables like \u0026#39;%log_error%\u0026#39;; 二进制日志 介绍 二进制日志(BINLOG)记录了所有的 DDL(数据定义语言)语句和 DML(数据操纵语言)语句，但 不包括数据查询(SELECT、SHOW)语句。\n作用: 灾难时的数据恢复; MySQL的主从复制。 在MySQL8版本中，默认二进制日志是开启着 的，涉及到的参数如下:\n1 show variables like \u0026#39;%log_bin%\u0026#39;; 参数说明:\nlog_bin_basename:当前数据库服务器的binlog日志的基础名称(前缀)，具体的binlog文件名需要再该basename的基础上加上编号(编号从000001开始)。 log_bin_index:binlog的索引文件，里面记录了当前服务器关联的binlog文件有哪些。 格式 MySQL服务器中提供了多种格式来记录二进制日志，具体格式及特点如下：\n日志格式 含义 STATEMENT 基于SQL语句的日志记录，记录的是SQL语句，对数据进行修改的SQL都会记录在日志文件中。 ROW 基于行的日志记录，记录的是每一行的数据变更。(默认) MIXED 混合了STATEMENT和ROW两种格式，默认采用STATEMENT，在某些特殊情况下会自动切换为ROW进行记录。 查看二进制日志的格式 1 show variables like \u0026#39;%binlog_format%\u0026#39;; 如果我们需要配置二进制日志的格式，只需要在 /etc/my.cnf 中配置 binlog_format 参数即可。\n查看 由于日志是以二进制方式存储的，不能直接读取，需要通过二进制日志查询工具 mysqlbinlog 来查看，具体语法:\n1 mysqlbinlog [ 参数选项 ] logfilename 参数选项 -d 指定数据库名称，只列出指定的数据库相关操作。 -o 忽略掉日志中的前n行命令。 -v 将行事件(数据变更)重构为SQL语句 -vv 将行事件(数据变更)重构为SQL语句，并输出注释信息 删除 对于比较繁忙的业务系统，每天生成的binlog数据巨大，如果长时间不清除，将会占用大量磁盘空间。可以通过以下几种方式清理日志：\n指令 含义 reset master 删除全部 binlog 日志，删除之后，日志编号，将从binlog.000001重新开始 purge master logs to \u0026lsquo;binlog.*\u0026rsquo; 删除 * 编号之前的所有日志 purge master logs before \u0026lsquo;yyyy-mm-dd hh24:mi:ss\u0026rsquo; 删除日志为 \u0026ldquo;yyyy-mm-dd hh24:mi:ss\u0026rdquo; 之前产生的所有日志。 也可以在mysql的配置文件中配置二进制日志的过期时间，设置了之后，二进制日志过期会自动删除。\n查看binlog日志过期时间 1 show variables like \u0026#39;%binlog_expire_logs_seconds%\u0026#39;; 查询日志 查询日志中记录了客户端的所有操作语句，而二进制日志不包含查询数据的SQL语句。默认情况下， 查询日志是未开启的。\n1 show variables like \u0026#39;%general%\u0026#39;; 如果需要开启查询日志，可以修改MySQL的配置文件 /etc/my.cnf 文件，添加如下内容:\n1 2 3 4 #该选项用来开启查询日志 ， 可选值 : 0 或者 1 ; 0 代表关闭， 1 代表开启 general_log=1 #设置日志的文件名 ， 如果没有指定， 默认的文件名为 host_name.log general_log_file=mysql_query.log 开启了查询日志之后，在MySQL的数据存放目录，也就是 /usr/local/mysql/data 目录下就会出现 mysql_query.log 文件。之后所有的客户端的增删改查操作都会记录在该日志文件之中，长时间运行后，该日志文件将会非常大。\n慢查询日志 慢查询日志记录了所有执行时间超过参数 long_query_time 设置值并且扫描记录数不小于 min_examined_row_limit 的所有的SQL语句的日志，默认未开启。long_query_time 默认为 10 秒，最小为 0， 精度可以到微秒。\n如果需要开启慢查询日志，需要在MySQL的配置文件 /etc/my.cnf 中配置如下参数:\n1 2 3 4 #慢查询日志 slow_query_log=1 #执行时间参数 long_query_time=2 默认情况下，不会记录管理语句，也不会记录不使用索引进行查找的查询。可以使用 log_slow_admin_statements和 更改此行为 log_queries_not_using_indexes，如下所述。\n1 2 3 4 #记录执行较慢的管理语句 log_slow_admin_statements =1 #记录执行较慢的未使用索引的语句 log_queries_not_using_indexes = 1 上述所有的参数配置完成之后，都需要重新启动MySQL服务器才可以生效。\n","date":"2025-11-27T00:06:43+08:00","permalink":"https://YLine-hub.github.io/p/mysqlmysql%E8%BF%90%E7%BB%B4-%E6%97%A5%E5%BF%97/","title":"[MySQL]MySQL运维-日志"},{"content":"MySQL管理 系统数据库 Mysql数据库安装完成后，自带了一下四个数据库，具体作用如下:\n数据库 含义 mysql 存储MySQL服务器正常运行所需要的各种信息(时区、主从、用户、权限等) information_schema 提供了访问数据库元数据的各种表和视图，包含数据库、表、字段类型及访问权限等 performance_schema 为MySQL服务器运行时状态提供了一个底层监控功能，主要收集数据库服务器性能参数 sys 包含了一系列方便DBA和开发人员利用perforperformance_schema性能数据库进行性能调优和诊断的视图 常用工具 mysql 该mysql不是指mysql服务，而是指mysql的客户端工具。\n语法 1 mysql [options] [database] 参数 -u,\u0026ndash;user=name # 指定用户名 -p,\u0026ndash;password[=name] # 指定密码 -h,\u0026ndash;host=name # 指定服务器IP或域名 -p,\u0026ndash;port=port # 指定连接端口 -e,\u0026ndash;execute=name # 执行SQL语句并退出 -e选项可以在Mysql客户端执行SQL语句，而不用连接到MySQL数据库再执行，对于一些批处理脚本， 这种方式尤其方便。\n示例 1 mysql -uroot –p123456 db01 -e \u0026#34;select * from stu\u0026#34;; mysqladmin mysqladmin 是一个执行管理操作的客户端程序。可以用它来检查服务器的配置和当前状态、创建并 删除数据库等。\n通过帮助文档查看选项: 1 mysqladmin --help 语法 1 mysqladmin [options] command ... 选项 -u,\u0026ndash;user=name # 指定用户名 -p,\u0026ndash;password[=name] # 指定密码 -h,\u0026ndash;host=name # 指定服务器IP或域名 -p,\u0026ndash;port=port # 指定连接端口 示例 1 mysqladmin -uroot -p123456 version mysqlbinlog 由于服务器生成的二进制日志文件以二进制格式保存，所以如果想要检查这些文本的文本格式，就会使用到mysqlbinlog日志管理工具。\n语法 1 mysqlbinlog [options] log-files1 log-files2 ... 参数 -d, \u0026ndash;database=name -o, \u0026ndash;offset=# -r,\u0026ndash;result-file=name -s, \u0026ndash;short-form --start-datatime=date1 --stop-datetime=date2 指定日期间隔内的所有日志。 --start-position=pos1 --stop-position=pos2 指定位置间隔内的所有日志。 示例 查看binlog.000008这个二进制文件中的数据信息 1 mysqlbinlog binlog.000008 发生报错\n报错信息 1 mysqlbinlog: [ERROR] unknown variable \u0026#39;default-character-set=utf8mb4\u0026#39;. 原因 mysqlbinlog这个工具无法识别binlog中的配置中的default-character-set=utf8mb4这个指令。\n解决方法\n添加 --no-defaults 参数 1 mysqlbinlog --no-defaults binlog.000008 上述查看到的二进制日志文件数据信息量太多了，不方便查询。我们可以加上一个参数 -s 来显示简单格式。\n查看binlog.000008这个二进制文件中的数据信息(简化) 1 mysqlbinlog --no-defaults -s binlog.000008 mysqlshow mysqlshow客户端对象查找工具，用来很快地查找存在哪些数据库、数据库中的表、表中的列或者索引。\n语法 1 mysqlshow [options] [db_name [table_name [col_name]]] 选项 --count 显示数据库及表的统计信息(数据库，表 均可以不指定) -i 显示指定数据库或者指定表的状态信息 示例 查询每个数据库的表的数量及表中记录的数量 1 mysqlshow -uroot -p123456 --count 查询db01库中每个表中的字段数，及行数 1 mysqlshow -uroot -p123456 db01 --count 查询db01库中stu表的详细情况 1 mysqlshow -uroot -p123456 db01 stu --count 查询db01库中course表的信息 1 mysqlshow -uroot -p123456 db01 course --count 查询db01库中course表的id字段的信息 1 mysqlshow -uroot -p123456 db01 course id --count mysqldump mysqldump 客户端工具用来备份数据库或在不同数据库之间进行数据迁移。备份内容包含创建表，及插入表的SQL语句。\n语法 1 2 3 mysqldump [options] db_name [tables] mysqldump [options] --database/-B db1 [db2 db3...] mysqldump [options] --all-databases/-A 连接选项 -u, \u0026ndash;user=name # 指定用户名 -p, \u0026ndash;password[=name] # 指定密码 -h, \u0026ndash;host=name # 指定服务器IP或域名 -P, \u0026ndash;port=port # 指定连接端口 输出选项 --add-drop-database # 在每个数据库创建语句前加上 drop database 语句 --add-drop-table # 在每个表创建语句前加上 drop table 语句 , 默认开启 ; 不开启 (\u0026ndash;skip-add-drop-table) -n, \u0026ndash;no-create-db # 不包含数据库的创建语句 -t, \u0026ndash;no-create-info # 不包含数据表的创建语句 -d, \u0026ndash;no-data # 不包含数据 -T, \u0026ndash;tab=name # 自动生成两个文件:一个.sql文件，创建表结构的语句;一个.txt文件，数据文件 示例 备份db01数据库 1 mysqldump -uroot -p123456 db01 \u0026gt; /usr/backup/sql/db01.sql 打开db01.sql\n1 vim /usr/backup/sql/db01.sql 备份出来的数据包含:\n删除表的语句 创建表的语句 数据插入语句 如果我们在数据备份时，不需要创建表，或者不需要备份数据，只需要备份表结构，都可以通过对应的参数来实现。\n备份db01数据库中的表数据，不备份表结构(-t) 1 mysqldump -uroot -p123456 -t db01 \u0026gt; /usr/backup/sql/db02.sql 打开 db02.sql ，来查看备份的数据，只有insert语句，没有备份表结构。\n将db01数据库的表的表结构与数据分开备份(-T) 1 mysqldump -uroot -p123456 -T /usr/backup/sql db01 score 执行上述指令，会出错，数据不能完成备份，原因是因为我们所指定的数据存放目录/root，MySQL认 为是不安全的，需要存储在MySQL信任的目录下。那么，哪个目录才是MySQL信任的目录呢，可以查看 一下系统变量 secure_file_priv 。执行结果如下:\nmysql配置secure_file_priv my.cnf:\n1 2 3 [mysqld] ... secure_file_priv=/usr/backup/sql 重启mysql 1 systemctl restart mysqld 查看secure_file_priv 1 show variables like \u0026#39;%secure_file_priv%\u0026#39;; 将db01数据库的表的表结构与数据分开备份(-T) 1 mysqldump -uroot -p123456 -T /usr/backup/sql db01 score 报错\n1 mysqldump: Got error: 1: Can\u0026#39;t create/write to file \u0026#39;/usr/backup/sql/score.txt\u0026#39; (OS errno 13 - Permission denied) when executing \u0026#39;SELECT INTO OUTFILE\u0026#39; 原因：没有写入权限\n解决方法：添加权限\n1 chmod 777 /usr/backup/sql 将db01数据库的表的表结构与数据分开备份(-T) 1 mysqldump -uroot -p123456 -T /usr/backup/sql db01 score 上述的两个文件 score.sql 中记录的就是表结构文件，而 score.txt 就是表数据文件，但是需 要注意表数据文件，并不是记录一条条的insert语句，而是按照一定的格式记录表结构中的数据。如下:\nmysqlimport/source source 如果需要导入sql文件,可以使用mysql中的source 指令\n语法 1 source xxx.sql 示例 导入score表结构 mysqlimport mysqlimport 是客户端数据导入工具，用来导入mysqldump 加 -T 参数后导出的文本文件(txt)。\n语法 1 mysqlimport [options] db_name textfile1 [textfile2...] 示例 1 mysqlimport -uroot -p123456 test /usr/backup/sql/score.txt 生词 schema / ˈskiːmə / n、(计划或理论的)纲要，图解 execute / ˈeksɪkjuːt / v、执行，实施；处决；完成 ","date":"2025-11-26T20:53:28+08:00","permalink":"https://YLine-hub.github.io/p/mysqlmysql%E8%BF%9B%E9%98%B6-%E7%AE%A1%E7%90%86/","title":"[MySQL]MySQL进阶-管理"},{"content":"MySQL进阶-InnoDB引擎 逻辑存储结构 InnoDB的逻辑存储结构如下图所示:\n表空间 表空间是InnoDB存储引擎逻辑结构的最高层， 如果用户启用了参数innodb_file_per_table(在 8.0版本中默认开启) ，则每张表都会有一个表空间(xxx.ibd)，一个mysql实例可以对应多个表空 间，用于存储记录、索引等数据。\n段 段，分为数据段(Leaf node segment)、索引段(Non-leaf node segment)、回滚段 (Rollback segment)，InnoDB是索引组织表，数据段就是B+树的叶子节点， 索引段即为B+树的 非叶子节点。段用来管理多个Extent(区)。\n区 区，表空间的单元结构，每个区的大小为1M。 默认情况下， InnoDB存储引擎页大小为16K， 即一个区中一共有64个连续的页。\n页 页，是InnoDB 存储引擎磁盘管理的最小单元，每个页的大小默认为 16KB。为了保证页的连续性， InnoDB 存储引擎每次从磁盘申请 4-5 个区。\n行 行，InnoDB 存储引擎数据是按行进行存放的。 在行中，默认有两个隐藏字段:\nTrx_id:每次对某条记录进行改动时，都会把对应的事务id赋值给trx_id隐藏列。 Roll_pointer:每次对某条引记录进行改动时，都会把旧的版本写入到undo日志中，然后这个 隐藏列就相当于一个指针，可以通过它来找到该记录修改前的信息。 架构 概述 MySQL5.5 版本开始，默认使用InnoDB存储引擎，它擅长事务处理，具有崩溃恢复特性，在日常开发 中使用非常广泛。下面是InnoDB架构图，左侧为内存结构，右侧为磁盘结构。\n内存结构 在左侧的内存结构中，主要分为这么四大块儿: Buffer Pool、Change Buffer、Adaptive Hash Index、Log Buffer。 接下来介绍一下这四个部分。\nBuffer Pool InnoDB存储引擎基于磁盘文件存储，访问物理硬盘和在内存中进行访问，速度相差很大，为了尽可能 弥补这两者之间的I/O效率的差值，就需要把经常使用的数据加载到缓冲池中，避免每次访问都进行磁 盘I/O。\n在InnoDB的缓冲池中不仅缓存了索引页和数据页，还包含了undo页、插入缓存、自适应哈希索引以及 InnoDB的锁信息等等。\n缓冲池 Buffer Pool，是主内存中的一个区域，里面可以缓存磁盘上经常操作的真实数据，在执行增 删改查操作时，先操作缓冲池中的数据(若缓冲池没有数据，则从磁盘加载并缓存)，然后再以一定频 率刷新到磁盘，从而减少磁盘IO，加快处理速度。\n缓冲池以Page页为单位，底层采用链表数据结构管理Page。根据状态，将Page分为三种类型:\nfree page:空闲page，未被使用。 clean page:被使用page，数据没有被修改过。 dirty page:脏页，被使用page，数据被修改过，也中数据与磁盘的数据产生了不一致。 在专用服务器上，通常将多达80%的物理内存分配给缓冲池 。 参数设置:\n1 show variables like \u0026#39;innodb_buffer_pool_size\u0026#39;; Change Buffer Change Buffer，更改缓冲区(针对于非唯一二级索引页)，在执行DML语句时，如果这些数据Page 没有在Buffer Pool中，不会直接操作磁盘，而会将数据变更存在更改缓冲区 Change Buffer 中，在未来数据被读取时，再将数据合并恢复到Buffer Pool中，再将合并后的数据刷新到磁盘中。\nChange Buffer的意义是什么呢?\n先来看一幅图，这个是二级索引的结构图:\n与聚集索引不同，二级索引通常是非唯一的，并且以相对随机的顺序插入二级索引。同样，删除和更新 可能会影响索引树中不相邻的二级索引页，如果每一次都操作磁盘，会造成大量的磁盘IO。有了 ChangeBuffer之后，我们可以在缓冲池中进行合并处理，减少磁盘IO。\nAdaptive Hash Index 自适应hash索引，用于优化对Buffer Pool数据的查询。MySQL的innoDB引擎中虽然没有直接支持 hash索引，但是给我们提供了一个功能就是这个自适应hash索引。因为前面我们讲到过，hash索引在 进行等值匹配时，一般性能是要高于B+树的，因为hash索引一般只需要一次IO即可，而B+树，可能需 要几次匹配，所以hash索引的效率要高，但是hash索引又不适合做范围查询、模糊匹配等。\nInnoDB存储引擎会监控对表上各索引页的查询，如果观察到在特定的条件下hash索引可以提升速度， 则建立hash索引，称之为自适应hash索引。\n自适应哈希索引，无需人工干预，是系统根据情况自动完成。\n参数: adaptive_hash_index\nLog Buffer Log Buffer:日志缓冲区，用来保存要写入到磁盘中的log日志数据(redo log 、undo log)， 默认大小为 16MB，日志缓冲区的日志会定期刷新到磁盘中。如果需要更新、插入或删除许多行的事 务，增加日志缓冲区的大小可以节省磁盘 I/O。\n参数:\ninnodb_log_buffer_size:缓冲区大小 innodb_flush_log_at_trx_commit:日志刷新到磁盘时机，取值主要包含以下三个: 1：日志在每次事务提交时写入并刷新到磁盘，默认值。 2：每秒将日志写入并刷新到磁盘一次。 3：日志在每次事务提交后写入，并每秒刷新到磁盘一次。 磁盘结构 接下来，再来看看InnoDB体系结构的右边部分，也就是磁盘结构:\nSystem Tablespace 系统表空间是更改缓冲区的存储区域。如果表是在系统表空间而不是每个表文件或通用表空间中创建 的，它也可能包含表和索引数据。(在MySQL5.x版本中还包含InnoDB数据字典、undolog等)\n参数:innodb_data_file_path\n系统表空间，默认的文件名叫 ibdata1。\nFile-Per-Table Tablespaces 如果开启了innodb_file_per_table开关 ，则每个表的文件表空间包含单个InnoDB表的数据和索引 ，并存储在文件系统上的单个数据文件中。\n开关参数:innodb_file_per_table ，该参数默认开启。\n那也就是说，我们每创建一个表，都会产生一个表空间文件，如图:\nGeneral Tablespaces 通用表空间，需要通过 CREATE TABLESPACE 语法创建通用表空间，在创建表时，可以指定该表空间。\n创建表空间 1 CREATE TABLESPACE ts_name ADD DATAFILE \u0026#39;file_name\u0026#39; ENGINE = engine_name; 创建表时指定表空间 1 CREATE TABLE xxx ... TABLESPACE ts_name; 演示 创建表空间 1 create tablespace ts_yline ADD datafile \u0026#39;yline.ibd\u0026#39; ENGINE = innodb; 通用表空间文件会出现在 /usr/local/mysql/data 目录下\n创建表a时，指定表空间(需要指定数据库) 1 2 3 4 -- 使用数据库itfox use itfox; -- 创建表a，指定表空间 create table a(id int primary key auto_increment, name varchar(10)) engine=innodb tablespace ts_yline; Undo Tablespaces 撤销表空间，MySQL实例在初始化时会自动创建两个默认的undo表空间(初始大小16M)，用于存储undo log日志。\nTemporary Tablespaces InnoDB 使用会话临时表空间和全局临时表空间。存储用户创建的临时表等数据。\nDoublewrite Buffer Files 双写缓冲区，innoDB引擎将数据页从Buffer Pool刷新到磁盘前，先将数据页写入双写缓冲区文件 中，便于系统异常时恢复数据。\nRedo Log 重做日志，是用来实现事务的持久性。该日志文件由两部分组成:重做日志缓冲(redo log buffer)以及重做日志文件(redo log),前者是在内存中，后者在磁盘中。当事务提交之后会把所 有修改信息都会存到该日志中, 用于在刷新脏页到磁盘时,发生错误时, 进行数据恢复使用。\n以循环方式写入重做日志文件，涉及两个文件:\n注：MySQL8.0.30之后重做日志文件不同。\n查询显示活动重做日志文件的START_LSN和END_LSN值 1 SELECT FILE_NAME, START_LSN, END_LSN FROM performance_schema.innodb_redo_log_files; 前面我们介绍了InnoDB的内存结构，以及磁盘结构，那么内存中我们所更新的数据，又是如何到磁盘 中的呢? 此时，就涉及到一组后台线程，接下来，就来介绍一些InnoDB中涉及到的后台线程。\n后台线程 在InnoDB的后台线程中，分为4类，分别是:Master Thread 、IO Thread、Purge Thread、 Page Cleaner Thread。\nMaster Thread 核心后台线程，负责调度其他线程，还负责将缓冲池中的数据异步刷新到磁盘中, 保持数据的一致性，还包括脏页的刷新、合并插入缓存、undo页的回收 。\nIO Thread 在InnoDB存储引擎中大量使用了AIO来处理IO请求, 这样可以极大地提高数据库的性能，而IO Thread主要负责这些IO请求的回调。\n线程类型 默认个数 职责 Read thread 4 负责读操作 Write thread 4 负责写操作 Log thread 1 负责将日志缓冲区刷新到磁盘 Insert buffer thread 1 负责将缓冲区内容刷新到磁盘 我们可以通过以下的这条指令，查看到InnoDB的状态信息，其中就包含IO Thread信息。\n1 show engine innodb status \\G; Purge Thread 主要用于回收事务已经提交了的undo log，在事务提交之后，undo log可能不用了，就用它来回收。\nPage Cleaner Thread 协助 Master Thread 刷新脏页到磁盘的线程，它可以减轻 Master Thread 的工作压力，减少阻塞。\n事务原理 事务基础 事务 事务 是一组操作的集合，它是一个不可分割的工作单位，事务会把所有的操作作为一个整体一起向系 统提交或撤销操作请求，即这些操作要么同时成功，要么同时失败。\n特性 原子性(Atomicity):事务是不可分割的最小操作单元，要么全部成功，要么全部失败。 一致性(Consistency):事务完成时，必须使所有的数据都保持一致状态。 隔离性(Isolation):数据库系统提供的隔离机制，保证事务在不受外部并发操作影响的独立环 境下运行。 持久性(Durability):事务一旦提交或回滚，它对数据库中的数据的改变就是永久的。 那实际上，我们研究事务的原理，就是研究MySQL的InnoDB引擎是如何保证事务的这四大特性的。\n而对于这四大特性，实际上分为两个部分。 其中的原子性、一致性、持久化，实际上是由InnoDB中的 两份日志来保证的，一份是redo log日志，一份是undo log日志。 而持久性是通过数据库的锁， 加上MVCC来保证的。\n我们在讲解事务原理的时候，主要就是来研究一下redolog，undolog以及MVCC。\nredo log 重做日志，记录的是事务提交时数据页的物理修改，是用来实现事务的持久性。\n该日志文件由两部分组成:重做日志缓冲(redo log buffer)以及重做日志文件(redo log file),前者是在内存中，后者在磁盘中。当事务提交之后会把所有修改信息都存到该日志文件中, 用 于在刷新脏页到磁盘,发生错误时, 进行数据恢复使用。\n如果没有redo log，可能会存在什么问题的? 我们一起来分析一下。\n我们知道，在InnoDB引擎中的内存结构中，主要的内存区域就是缓冲池，在缓冲池中缓存了很多的数据页。 当我们在一个事务中，执行多个增删改的操作时，InnoDB引擎会先操作缓冲池中的数据，如果 缓冲区没有对应的数据，会通过后台线程将磁盘中的数据加载出来，存放在缓冲区中，然后将缓冲池中 的数据修改，修改后的数据页我们称为脏页。 而脏页则会在一定的时机，通过后台线程刷新到磁盘 中，从而保证缓冲区与磁盘的数据一致。 而缓冲区的脏页数据并不是实时刷新的，而是一段时间之后 将缓冲区的数据刷新到磁盘中，假如刷新到磁盘的过程出错了，而提示给用户事务提交成功，而数据却 没有持久化下来，这就出现问题了，没有保证事务的持久性。\n那么，如何解决上述的问题呢? 在InnoDB中提供了一份日志 redo log，接下来我们再来分析一下，通过redolog如何解决这个问题。\n有了redo log之后，当对缓冲区的数据进行增删改之后，会首先将操作的数据页的变化，记录在redo log buffer中。在事务提交时，会将redo log buffer中的数据刷新到redo log磁盘文件中。 过一段时间之后，如果刷新缓冲区的脏页到磁盘时，发生错误，此时就可以借助于redo log进行数据 恢复，这样就保证了事务的持久性。 而如果脏页成功刷新到磁盘 或 或者涉及到的数据已经落盘，此 时redolog就没有作用了，就可以删除了，所以存在的两个redolog文件是循环写的。\n那为什么每一次提交事务，要刷新redo log到磁盘中呢，而不是直接将buffer pool中的脏页刷新到磁盘呢 ?\n因为在业务操作中，我们操作数据一般都是随机读写磁盘的，而不是顺序读写磁盘。 而redo log在 往磁盘文件中写入数据，由于是日志文件，所以都是顺序写的。顺序写的效率，要远大于随机写。 这 种先写日志的方式，称之为 WAL(Write-Ahead Logging)。\nundo log 回滚日志，用于记录数据被修改前的信息 , 作用包含两个 : 提供回滚(保证事务的原子性) 和 MVCC(多版本并发控制) 。\nundo log和redo log记录物理日志不一样，它是逻辑日志。可以认为当delete一条记录时，undo log中会记录一条对应的insert记录，反之亦然，当update一条记录时，它记录一条对应相反的 update记录。当执行rollback时，就可以从undo log中的逻辑记录读取到相应的内容并进行回滚。\nUndo log销毁:undo log在事务执行时产生，事务提交时，并不会立即删除undo log，因为这些 日志可能还用于MVCC。\nUndo log存储:undo log采用段的方式进行管理和记录，存放在前面介绍的 rollback segment 回滚段中，内部包含1024个undo log segment。\nMVCC 基本概念 当前读 读取的是记录的最新版本，读取时还要保证其他并发事务不能修改当前记录，会对读取的记录进行加 锁。对于我们日常的操作，如:select \u0026hellip; lock in share mode(共享锁)，select \u0026hellip; for update、update、insert、delete(排他锁)都是一种当前读。\n测试 在测试中我们可以看到，即使是在默认的RR隔离级别下，事务A中依然可以读取到事务B最新提交的内 容，因为在查询语句后面加上了 lock in share mode 共享锁，此时是当前读操作。当然，当我们 加排他锁的时候，也是当前读操作。\n快照读 简单的select(不加锁)就是快照读，快照读，读取的是记录数据的可见版本，有可能是历史数据， 不加锁，是非阻塞读。\nRead Committed:每次select，都生成一个快照读。 Repeatable Read:开启事务后第一个select语句才是快照读的地方。 Serializable:快照读会退化为当前读。 测试 在测试中,我们看到即使事务B提交了数据,事务A中也查询不到。 原因就是因为普通的select是快照 读，而在当前默认的RR隔离级别下，开启事务后第一个select语句才是快照读的地方，后面执行相同 的select语句都是从快照中获取数据，可能不是当前的最新数据，这样也就保证了可重复读。\nMVCC 全称 Multi-Version Concurrency Control，多版本并发控制。指维护一个数据的多个版本， 使得读写操作没有冲突，快照读为MySQL实现MVCC提供了一个非阻塞读功能。MVCC的具体实现，还需 要依赖于数据库记录中的三个隐式字段、undo log日志、readView。\n接下来，我们再来介绍一下InnoDB引擎的表中涉及到的隐藏字段 、undolog 以及 readview，从 而来介绍一下MVCC的原理。\n隐藏字段 介绍 当我们创建了上面的这张表，我们在查看表结构的时候，就可以显式的看到这三个字段。 实际上除了 这三个字段以外，InnoDB还会自动的给我们添加三个隐藏字段及其含义分别是:\n隐藏字段 含义 DB_TRX_ID 最近修改事务ID，记录插入这条记录或最后一次修改该记录的事务ID DB_ROLL_PTR 回滚指针，指向这条记录的上一个版本，用于配合undo log，指向上一个版本。 DB_ROW_ID 隐藏主键，如果表结构没有指定主键，将会生成该隐藏字段 而上述的前两个字段是肯定会添加的， 是否添加最后一个字段DB_ROW_ID，得看当前表有没有主键，如果有主键，则不会添加该隐藏字段。\n测试 查看有主键的表stu 进入服务器中的 /usr/local/mysql/data/db01/ ，查看stu的表结构信息，通过如下指令：\n1 ibd2sdi stu.ibd 查看到的表结构信息中，有一栏 columns，在其中我们会看到处理我们建表时指定的字段以外，还有 额外的两个字段 分别是:DB_TRX_ID 、 DB_ROLL_PTR ，因为该表有主键，所以没有DB_ROW_ID 隐藏字段。\n若没有ibdsdi命令\n设置ibdsdi的软链接 1 ln -fs /usr/local/mysql/bin/ibdsdi /usr/bin 查看是否设置成功 1 find /usr/bin -name \u0026#39;ibd2sdi\u0026#39; 查看stu表结构信息 1 ibd2sdi stu.ibd 查看没有主键的表employee 建表语句 1 create table employee (id int , name varchar(10)); 查看表结构及其其中的字段信息 1 ibd2sdi employee.ibd 查看到的表结构信息中，有一栏 columns，在其中我们会看到处理我们建表时指定的字段以外，还有 额外的三个字段 分别是:DB_TRX_ID 、 DB_ROLL_PTR 、DB_ROW_ID，因为employee表是没有指定主键的。\nundo log 介绍 回滚日志，在insert、update、delete的时候产生的便于数据回滚的日志。 当insert的时候，产生的undo log日志只在回滚时需要，在事务提交后，可被立即删除。 而update、delete的时候，产生的undo log日志不仅在回滚时需要，在快照读时也需要，不会立即被删除。\n版本链 有一张表原始数据为:\nDB_TRX_ID : 代表最近修改事务ID，记录插入这条记录或最后一次修改该记录的事务ID，是自增的。\nDB_ROLL_PTR : 由于这条数据是才插入的，没有被更新过，所以该字段值为null。\n然后，有四个并发事务同时在访问这张表。\n第一步 当事务2执行第一条修改语句时，会记录undo log日志，记录数据变更之前的样子; 然后更新记录， 并且记录本次操作的事务ID，回滚指针，回滚指针用来指定如果发生回滚，回滚到哪一个版本。\n第二步 当事务3执行第一条修改语句时，也会记录undo log日志，记录数据变更之前的样子; 然后更新记 录，并且记录本次操作的事务ID，回滚指针，回滚指针用来指定如果发生回滚，回滚到哪一个版本。\n第三步 当事务4执行第一条修改语句时，也会记录undo log日志，记录数据变更之前的样子; 然后更新记录， 并且记录本次操作的事务 ID，回滚指针， 回滚指针用来指定如果发生回滚，回滚到哪一个版本 。\n最终我们发现，不同事务或相同事务对同一条记录进行修改，会导致该记录的undolog生成一条 记录版本链表，链表的头部是最新的旧记录，链表尾部是最早的旧记录。\nreadview ReadView(读视图)是 快照读 SQL执行时MVCC提取数据的依据，记录并维护系统当前活跃的事务 (未提交的)id。\nReadView中包含了四个核心字段:\n字段 含义 m_ids 当前活跃的事务ID集合 min_trx_id 最小活跃事务ID max_trx_id 预分配事务ID，当前最大事务ID+1(因为事务ID是自增的) creator_trx_id ReadView创建者的事务ID 而在readview中就规定了版本链数据的访问规则: trx_id 代表当前undolog版本链对应事务ID。\n条件 是否可以访问 说明 trx_id == creator_trx_id 可以访问该版本 成立，说明数据是当前这个事务更改的。 trx_id \u0026lt; min_trx_id 可以访问该版本 成立，说明数据已经提交了。 trx_id \u0026gt; max_trx_id 不可以访问该版本 成立，说明事务是在ReadView生成后才开启的。 min_trx_id \u0026lt;= trx_id \u0026lt;= max_trx_id 如果trx_id不在m_ids中，是可以访问该版本的 成立，说明数据已经提交 不同的隔离级别，生成ReadView的时机不同:\nREAD COMMITTED :在事务中每一次执行快照读时生成ReadView。 REPEATABLE READ:仅在事务中第一次执行快照读时生成ReadView，后续复用该ReadView。 原理分析 RC隔离级别 RC隔离级别下，在事务中每一次执行快照读时生成ReadView。\n我们就来分析事务5中，两次快照读读取数据，是如何获取数据的?\n在事务5中，查询了两次id为30的记录，由于隔离级别为Read Committed，所以每一次进行快照读都会生成一个ReadView，那么两次生成的ReadView如下。\n那么这两次快照读在获取数据时，就需要根据所生成的ReadView以及ReadView的版本链访问规则，到undolog版本链中匹配数据，最终决定此次快照读返回的数据。\nA. 先来看第一次快照读具体的读取过程：\n在进行匹配时，会从undo log的版本链，从上到下进行挨个匹配:\n先匹配 这条记录，这条记录对应的trx_id为4，也就是将4带入右侧的匹配规则中。 ①不满足 ②不满足 ③不满足 ④也不满足 ， 都不满足，则继续匹配undo log版本链的下一条。\n再匹配第二条 ，这条 记录对应的trx_id为3，也就是将3带入右侧的匹配规则中。①不满足 ②不满足 ③不满足 ④也不满足 ，都不满足，则继续匹配undo log版本链的下一条。\n再匹配第三条 ，这条记录对应的trx_id为2，也就是将2带入右侧的匹配规则中。①不满足 ②满足终止匹配，此次快照读，返回的数据就是版本链中记录的这条数据。\nB. 再来看第二次快照读具体的读取过程:\n在进行匹配时，会从undo log的版本链，从上到下进行挨个匹配:\n先匹配 这条记录，这条记录对应的trx_id为4，也就是将4带入右侧的匹配规则中。 ①不满足 ②不满足 ③不满足 ④也不满足 ， 都不满足，则继续匹配undo log版本链的下一条。\n再匹配第二条 ，这条记录对应的trx_id为3，也就是将3带入右侧的匹配规则中。①不满足 ②满足 。终止匹配，此次快照读，返回的数据就是版本链中记录的这条数据。\nRR隔离级别 RR隔离级别下，仅在事务中第一次执行快照读时生成ReadView，后续复用该ReadView。 而RR 是可重复读，在一个事务中，执行两次相同的select语句，查询到的结果是一样的。\n那MySQL是如何做到可重复读的呢? 我们简单分析一下就知道了\n我们看到，在RR隔离级别下，只是在事务中第一次快照读时生成ReadView，后续都是复用该 ReadView，那么既然ReadView都一样， ReadView的版本链匹配规则也一样， 那么最终快照读返 回的结果也是一样的。\n所以呢，MVCC的实现原理就是通过 InnoDB表的隐藏字段、UndoLog 版本链、ReadView来实现的。 而MVCC + 锁，则实现了事务的隔离性。而一致性则是由redolog 与 undolog保证。\n","date":"2025-11-25T17:08:38+08:00","permalink":"https://YLine-hub.github.io/p/mysqlmysql%E8%BF%9B%E9%98%B6-innodb%E5%BC%95%E6%93%8E/","title":"[MySQL]MySQL进阶-InnoDB引擎"},{"content":"MySQL进阶-锁 概述 锁是计算机协调多个进程或线程并发访问某一资源的机制。在数据库中，除传统的计算资源(CPU、 RAM、I/O)的争用以外，数据也是一种供许多用户共享的资源。如何保证数据并发访问的一致性、有 效性是所有数据库必须解决的一个问题，锁冲突也是影响数据库并发访问性能的一个重要因素。从这个 角度来说，锁对数据库而言显得尤其重要，也更加复杂。\nMySQL中的锁，按照锁的粒度分，分为以下三类: 全局锁:锁定数据库中的所有表。 表级锁:每次操作锁住整张表。 行级锁:每次操作锁住对应的行数据。 全局锁 介绍 全局锁就是对整个数据库实例加锁，加锁后整个实例就处于只读状态，后续的DML的写语句，DDL语 句，已经更新操作的事务提交语句都将被阻塞。\n其典型的使用场景是做全库的逻辑备份，对所有的表进行锁定，从而获取一致性视图，保证数据的完整性。\n为什么全库逻辑备份，就需要加全就锁呢?\nA. 我们一起先来分析一下不加全局锁，可能存在的问题。\n假设在数据库中存在这样三张表: tb_stock 库存表，tb_order 订单表，tb_orderlog 订单日志表。\n在进行数据备份时，先备份tb_stock库存表。 然后接下来，在业务系统中，执行了下单操作，扣减库存，生成订单(更新tb_stock表，插入tb_order表)。 然后再执行备份tb_order表的逻辑。 业务中执行插入订单日志操作。 最后，又备份tb_orderlog表。 此时备份出来的数据，是存在问题的。因为备份出来的数据，tb_stock表与tb_order表的数据不一 致(有最新操作的订单信息,但是库存数没减)。\n那如何来规避这种问题呢? 此时就可以借助于MySQL的全局锁来解决。\nB.再来分析一下加了全局锁后的情况。\n对数据库进行进行逻辑备份之前，先对整个数据库加上全局锁，一旦加了全局锁之后，其他的DDL、 DML全部都处于阻塞状态，但是可以执行DQL语句，也就是处于只读状态，而数据备份就是查询操作。 那么数据在进行逻辑备份的过程中，数据库中的数据就是不会发生变化的，这样就保证了数据的一致性 和完整性。\n语法 全局锁 1 flush tables with read lock; 数据备份 1 mysqldump -uroot -p123456 itcast \u0026gt; itcast.sql 数据备份的相关指令，在后面MySQL管理章节，还会详细讲解。\n释放锁 1 unlock tables; 特点 数据库中加全局锁，是一个比较重的操作，存在以下问题:\n如果在主库上备份，那么在备份期间都不能执行更新，业务基本上就得停摆。 如果在从库上备份，那么在备份期间从库不能执行主库同步过来的二进制日志(binlog)，会导 致主从延迟。 在InnoDB引擎中，我们可以在备份时加上参数 \u0026ndash;single-transaction 参数来完成不加锁的一致 性数据备份。\n1 mysqldump --single-transaction -uroot -p123456 itcast \u0026gt; itcast.sql 示例 数据准备\n环境 两个终端连接数据库：A、B\n创建数据库 1 create database db01; 创建表 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 create table student( id int auto_increment primary key comment \u0026#39;主键ID\u0026#39;, name varchar(10) comment \u0026#39;姓名\u0026#39;, no varchar(10) comment \u0026#39;学号\u0026#39; ) comment \u0026#39;学生表\u0026#39;; insert into student values(null,\u0026#39;黛绮丝\u0026#39;,\u0026#39;2000100101\u0026#39;),(null,\u0026#39;谢逊\u0026#39;,\u0026#39;2000100102\u0026#39;),(null,\u0026#39;殷天正\u0026#39;,\u0026#39;2000100103\u0026#39;),(null,\u0026#39;韦一笑\u0026#39;,\u0026#39;2000100104\u0026#39;); create table course( id int auto_increment primary key comment \u0026#39;主键ID\u0026#39;, name varchar(10) comment \u0026#39;课程名称\u0026#39; ) comment \u0026#39;课程表\u0026#39;; insert into course values(null,\u0026#39;Java\u0026#39;),(null,\u0026#39;PHP\u0026#39;),(null,\u0026#39;MySQL\u0026#39;),(null,\u0026#39;Hadoop\u0026#39;); create table student_course( id int auto_increment comment \u0026#39;主键\u0026#39; primary key, studentid int not null comment \u0026#39;学生ID\u0026#39;, courseid int not null comment \u0026#39;课程ID\u0026#39;, constraint fk_courseid foreign key (courseid) references course(id), constraint fk_studentid foreign key (studentid) references student(id) ) comment \u0026#39;学生课程中间表\u0026#39;; insert into student_course values(null,1,1),(null,1,2),(null,1,3),(null,2,2),(null,2,3),(null,3,4); 终端A：设置全局锁 1 2 3 4 -- 使用db01库 use db01; -- 设置全局锁 flush tables with read lock; 终端B：查询/修改学生表 1 2 3 4 5 6 -- 使用db01 use db01; -- 查询学生表 select * from student; -- 修改学生表 update student set name = \u0026#39;A\u0026#39; where id = 2; 此时光标状态处于阻塞。\n终端C：备份数据库(不连接mysql) 1 mysqldump -uroot -p123456 db01 \u0026gt; /root/sql/db01.sql 报错\n原因 未设置mysqldump软链接\n解决方法 1 2 3 4 5 6 # 查找mysql的安装路径 find / -name mysql -print # 找到bin目录的 /usr/local/mysql/bin/ # 设置软链接 ln -fs /usr/local/mysql/bin/mysqldump /usr/bin ln -fs /usr/local/mysql/bin/mysql /usr/bin 再次备份\n1 mysqldump -uroot -p123456 db01 \u0026gt; /root/sql/db01.sql 查看文件是否存在 1 find /root/sql -type f -name \u0026#39;db01.sql\u0026#39; 查看文件内容 1 vim /root/sql/db01.sql 终端A：解锁 1 unlock tables; 生词 interface / ˈɪntərfeɪs / n、(人机)界面；(计算机设备之间的)连接，接口； v、连接 insecure / ˌɪnsɪˈkjʊr / adj、缺乏信心的；不安全的 表级锁 介绍 表级锁，每次操作锁住整张表。锁定粒度大，发生锁冲突的概率最高，并发度最低。应用在MyISAM、 InnoDB、BDB等存储引擎中。 对于表级锁，主要分为以下三类:\n表锁 元数据锁(meta data lock，MDL) 意向锁 表锁 对于表锁，分为两类:\n表共享读锁(read lock) 表独占写锁(write lock) 语法 加锁 1 lock tables 表名... read/write 释放锁 1 unlock tables / 客户端断开连接 特点 A.读锁\n左侧为客户端一，对指定表加了读锁，不会影响右侧客户端二的读，但是会阻塞右侧客户端的写。\n测试 B.写锁\n左侧为客户端一，对指定表加了写锁，会阻塞右侧客户端的读和写。\n测试: 结论: 读锁不会阻塞其他客户端的读，但是会阻塞写。写锁既会阻塞其他客户端的读，又会阻塞 其他客户端的写。\n元数据锁 meta data lock , 元数据锁，简写MDL。 MDL加锁过程是系统自动控制，无需显式使用，在访问一张表的时候会自动加上。MDL锁主要作用是维 护表元数据的数据一致性，在表上有活动事务的时候，不可以对元数据进行写入操作。 为了避免DML与 DDL冲突，保证读写的正确性。\n这里的元数据，大家可以简单理解为就是一张表的表结构。也就是说，某一张表涉及到未提交的事务时，是不能够修改这张表的表结构的。 在MySQL5.5中引入了MDL，当对一张表进行增删改查的时候，加MDL读锁(共享);当对表结构进行变 更操作的时候，加MDL写锁(排他)。 常见的SQL操作时，锁添加的元数据锁：\n对应SQL 锁类型 说明 lock tables xxx read / write SHARED_READ_ONLY / SHARED_NO_READ_WRITE select、select \u0026hellip; lock in share mode SHARED_READ 与SAHRED_READ、SHARED_WRITE兼容，与EXCLUSIVE互斥 insert、update、delete、select\u0026hellip; SHARED_WRITE 与SHARED_READ、SHARED_WRITE兼容，与EXCLUSIVE互斥 alter table \u0026hellip; EXCLUSIVE 与其他的MDL都互斥 演示 当执行SELECT、INSERT、UPDATE、DELETE等语句时，添加的是元数据共享锁(SHARED_READ / SHARED_WRITE)，之间是兼容的。 当执行SELECT语句时，添加的是元数据共享锁(SHARED_READ)，会阻塞元数据排他锁 (EXCLUSIVE)，之间是互斥的。 我们可以通过下面的SQL，来查看数据库中的元数据锁的情况:\n1 select object_type,object_schema,object_name,lock_type,lock_duration from performance_schema.metadata_locks; 我们在操作过程中，可以通过上述的SQL语句，来查看元数据锁的加锁情况。\n意向锁 介绍 为了避免DML在执行时，加的行锁与表锁的冲突，在InnoDB中引入了意向锁，使得表锁不用检查每行 数据是否加锁，使用意向锁来减少表锁的检查。\n假如没有意向锁，客户端一对表加了行锁后，客户端二如何给表加表锁呢，来通过示意图简单分析一下:\n首先客户端一，开启一个事务，然后执行DML操作，在执行DML语句时，会对涉及到的行加行锁。 当客户端二，想对这张表加表锁时，会检查当前表是否有对应的行锁，如果没有，则添加表锁，此时就会从第一行数据，检查到最后一行数据，效率较低。 有了意向锁之后 :\n客户端一，在执行DML操作时，会对涉及的行加行锁，同时也会对该表加上意向锁。 而其他客户端，在对这张表加表锁的时候，会根据该表上所加的意向锁来判定是否可以成功加表锁，而不用逐行判断行锁情况了。 分类 意向共享锁(IS): 由语句select ... lock in share mode添加 。 与表锁共享锁 (read)兼容，与表锁排他锁(write)互斥。 意向排他锁(IX): 由insert、update、delete、select...for update添加 。与表锁共 享锁(read)及排他锁(write)都互斥，意向锁之间不会互斥。 一旦事务提交了，意向共享锁、意向排他锁，都会自动释放。\n可以通过以下SQL，查看意向锁及行锁的加锁情况:\n1 select object_schema,object_name,index_name,lock_type,lock_mode,lock_data from performance_schema.data_locks; 演示 A、意向共享锁与表读锁是兼容的\nB. 意向排他锁与表读锁、写锁都是互斥的\n行级锁 介绍 行级锁，每次操作锁住对应的行数据。锁定粒度最小，发生锁冲突的概率最低，并发度最高。应用在 InnoDB存储引擎中。\nInnoDB的数据是基于索引组织的，行锁是通过对索引上的索引项加锁来实现的，而不是对记录加的 锁。对于行级锁，主要分为以下三类:\n行锁(Record Lock):锁定单个行记录的锁，防止其他事务对此行进行update和delete。在 RC、RR隔离级别下都支持。 间隙锁(Gap Lock):锁定索引记录间隙(不含该记录)，确保索引记录间隙不变，防止其他事 务在这个间隙进行insert，产生幻读。在RR隔离级别下都支持。 临键锁(Next-Key Lock):行锁和间隙锁组合，同时锁住数据，并锁住数据前面的间隙Gap。 在RR隔离级别下支持。 行锁 介绍 InnoDB实现了以下两种类型的行锁:\n共享锁(S):允许一个事务去读一行，阻止其他事务获得相同数据集的排它锁。 排他锁(X):允许获取排他锁的事务更新数据，阻止其他事务获得相同数据集的共享锁和排他锁。 两种行锁的兼容情况如下:\n常见的SQL语句，在执行时，所加的行锁如下:\nSQL 行锁类型 说明 INSERT \u0026hellip; 排他锁 自动加锁 UPDATE \u0026hellip; 排他锁 自动加锁 DELETE \u0026hellip; 排他锁 自动加锁 SELECT(正常) 不加任何锁 SELECT \u0026hellip; LOCK IN SHARED MODE 共享锁 需要手动在SELECT之后加LOCK IN SHARED MODE SELECT \u0026hellip; FOR UPDATE 排他锁 需要手动在SELECT之后加FOR UPDATE 演示 默认情况下，InnoDB在 REPEATABLE READ事务隔离级别运行，InnoDB使用 next-key 锁进行搜 索和索引扫描，以防止幻读。\n针对唯一索引进行检索时，对已存在的记录进行等值匹配时，将会自动优化为行锁。 InnoDB的行锁是针对于索引加的锁，不通过索引条件检索数据，那么InnoDB将对表中的所有记 录加锁，此时 就会升级为表锁。 可以通过以下SQL，查看意向锁及行锁的加锁情况:\n1 select object_schema,object_name,index_name,lock_type,lock_mode,lock_data from performance_schema.data_locks; 示例演示 数据准备 1 2 3 4 5 6 7 8 9 10 11 CREATE TABLE `stu` ( `id` int NOT NULL PRIMARY KEY AUTO_INCREMENT, `name` varchar(255) DEFAULT NULL, `age` int NOT NULL ) ENGINE = InnoDB CHARACTER SET = utf8mb4; INSERT INTO `stu` VALUES (1, \u0026#39;tom\u0026#39;, 1); INSERT INTO `stu` VALUES (3, \u0026#39;cat\u0026#39;, 3); INSERT INTO `stu` VALUES (8, \u0026#39;rose\u0026#39;, 8); INSERT INTO `stu` VALUES (11, \u0026#39;jetty\u0026#39;, 11); INSERT INTO `stu` VALUES (19, \u0026#39;lily\u0026#39;, 19); INSERT INTO `stu` VALUES (25, \u0026#39;luci\u0026#39;, 25); 演示行锁的时候，我们就通过上面这张表来演示一下。\nA. 普通的select语句，执行时，不会加锁。\nB. select...lock in share mode，加共享锁，共享锁与共享锁之间兼容。\n共享锁与排他锁之间互斥。\n客户端一获取的是id为1这行的共享锁，客户端二是可以获取id为3这行的排它锁的，因为不是同一行 数据。 而如果客户端二想获取id为1这行的排他锁，会处于阻塞状态，因为共享锁与排他锁之间互斥。\nC. 排他锁与排他锁之间互斥\n当客户端一，执行update语句，会为id为1的记录加排他锁; 客户端二，如果也执行update语句更 新id为1的数据，也要为id为1的数据加排他锁，但是客户端二会处于阻塞状态，因为排他锁之间是互 斥的。 直到客户端一，把事务提交了，才会把这一行的行锁释放，此时客户端二，解除阻塞。\nD. 无索引行锁升级为表锁\nstu表中数据如下:\n我们在两个客户端中执行如下操作:\n在客户端一中，开启事务，并执行update语句，更新name为Lily的数据，也就是id为19的记录 。 然后在客户端二中更新id为3的记录，却不能直接执行，会处于阻塞状态，为什么呢?\n原因就是因为此时，客户端一，根据name字段进行更新时，name字段是没有索引的，如果没有索引， 此时行锁会升级为表锁(因为行锁是对索引项加的锁，而name没有索引)。\n接下来，我们再针对name字段建立索引，索引建立之后，再次做一个测试:\n此时我们可以看到，客户端一，开启事务，然后依然是根据name进行更新。而客户端二，在更新id为3 的数据时，更新成功，并未进入阻塞状态。 这样就说明，我们根据索引字段进行更新操作，就可以避免行锁升级为表锁的情况。\n间隙锁\u0026amp;临键锁 默认情况下，InnoDB在 REPEATABLE READ事务隔离级别运行，InnoDB使用 next-key 锁进行搜索和索引扫描，以防止幻读。\n索引上的等值查询(唯一索引)，给不存在的记录加锁时, 优化为间隙锁。 索引上的等值查询(非唯一普通索引)，向右遍历时最后一个值不满足查询需求时，next-key lock 退化为间隙锁。 索引上的范围查询(唯一索引)\u0026ndash;会访问到不满足条件的第一个值为止。 注意:间隙锁唯一目的是防止其他事务插入间隙。间隙锁可以共存，一个事务采用的间隙锁不会 阻止另一个事务在同一间隙上采用间隙锁。\n示例演示 A. 索引上的等值查询(唯一索引)，给不存在的记录加锁时, 优化为间隙锁 。\nB. 索引上的等值查询(非唯一普通索引)，向右遍历时最后一个值不满足查询需求时，next-key lock 退化为间隙锁。\n介绍分析一下: 我们知道InnoDB的B+树索引，叶子节点是有序的双向链表。 假如，我们要根据这个二级索引查询值 为18的数据，并加上共享锁，我们是只锁定18这一行就可以了吗? 并不是，因为是非唯一索引，这个 结构中可能有多个18的存在，所以，在加锁时会继续往后找，找到一个不满足条件的值(当前案例中也 就是29)。此时会对18加临键锁，并对29之前的间隙加锁。\nC. 索引上的范围查询(唯一索引)\u0026ndash;会访问到不满足条件的第一个值为止。\n查询的条件为id\u0026gt;=19，并添加共享锁。此时我们可以根据数据库表中现有的数据，将数据分为三个部分: [19] (19,25] (25,+∞] 所以数据库数据在加锁是，就是将19加了行锁，25的临键锁(包含25及25之前的间隙)，正无穷的临键锁(正无穷及之前的间隙)。\n","date":"2025-11-24T00:18:53+08:00","permalink":"https://YLine-hub.github.io/p/mysqlmysql%E8%BF%9B%E9%98%B6-%E9%94%81/","title":"[MySQL]MySQL进阶-锁"},{"content":" 这些缩写通常代表软件开发和测试过程中的不同环境，其全称和含义如下：\nENV - Environment(环境)\nPROD - Production（生产环境）：生产环境是部署实际用户使用的版本的地方，通常是最终版本，用户可以直接访问和使用。\nSIT - System Integration Testing（系统集成测试环境）：系统集成测试环境用于对系统不同模块之间的集成和交互进行测试。\nUAT - User Acceptance Testing（用户验收测试环境）：用户验收测试环境是在软件开发完成后，由最终用户进行的测试，以确认软件是否满足其需求和预期。\nTEST - Testing（测试环境）：测试环境是用于进行各种测试，包括单元测试、功能测试、性能测试等。\nPRE - Pre-production（预生产环境）：预生产环境是用于进行最终测试和准备生产环境的环境。\nDEV - Development（开发环境）：开发环境是程序员用来进行软件开发和调试的地方。\nFAT - Factory Acceptance Testing（工厂验收测试环境）：工厂验收测试环境是在软件交付给客户之前在开发商的环境中进行的测试。\nStaging - Staging Environment（预上线环境）：预上线环境是在生产环境之前的一个环境，用于测试和准备上线前的最后调整和检查。\n这些环境通常在软件开发和测试周期中使用，以确保软件在不同阶段的质量和稳定性。\n","date":"2025-11-23T21:21:02+08:00","permalink":"https://YLine-hub.github.io/p/ops%E5%90%84%E7%8E%AF%E5%A2%83%E7%BC%A9%E5%86%99%E5%90%AB%E4%B9%89%E4%BB%8B%E7%BB%8D/","title":"[OPS]各环境缩写含义介绍"},{"content":"Mac终端命令 下载文件 1 curl -O https://xxxxx.xxx (链接) 打开文件 1 open /文件路径 ","date":"2025-11-23T17:46:51+08:00","permalink":"https://YLine-hub.github.io/p/mac%E7%BB%88%E7%AB%AF%E5%91%BD%E4%BB%A4/","title":"[Mac]终端命令"},{"content":"Jmeter的安装 前置环境 jdk 8 下载jmeter jmeter下载地址：jmeter-download 在/opt目录下，下载jmeter 1 curl -O https://archive.apache.org/dist/jmeter/binaries/apache-jmeter-5.6.3.tgz 解压jmeter 1 tar -zxvf apache-jmeter-5.6.3.tgz 移动apache-jmeter-5.6.3到/usr/local目录下 1 sudo mv apache-jmeter-5.6.3 /usr/local/ 配置环境变量 验证文件完整性 1 2 find /usr/local/apache-jmeter-5.6.3/lib -type f -name \u0026#39;ApacheJMeter_core.jar\u0026#39; find /usr/local/apache-jmeter-5.6.3/lib -type f -name \u0026#39;jorphan.jar\u0026#39; 打开~/.bash_profile\n配置\n1 2 3 export JMETER_HOME=/usr/local/apache-jmeter-5.6.3 #注意这个需要换成自己的安装地址 export PATH=$JAVA_HOME/bin:$JMETER_HOME/bin:$PATH export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$JMETER_HOME/lib/ext/ApacheJMeter_core.jar:$JMETER_HOME/lib/jorphan.jar 重新加载配置文件 1 source ~/.bash_profile 运行 1 jmeter 报错问题 报错 1 2 3 Error: VM option \u0026#39;UseG1GC\u0026#39; is experimental and must be enabled via -XX:+UnlockExperimentalVMOptions. Error: Could not create the Java Virtual Machine. Error: A fatal exception has occurred. Program will exit. 解决 进入jmeter的bin目录 1 cd /usr/local/apache-jmeter-5.6.3/bin/ 编辑jmeter文件 1 vim jmeter 找到-XX:+UseG1GC 1 /-XX:+UseG1GC 将其注释 1 #: \u0026#34;${GC_ALGO:=\u0026#34;-XX:+UseG1GC -XX:MaxGCPauseMillis=100 -XX:G1ReservePercent=20\u0026#34;}\u0026#34; 保存并退出\n按esc，然后输入:wq\n再次运行 1 jmeter ","date":"2025-11-23T16:59:16+08:00","permalink":"https://YLine-hub.github.io/p/macjmeter%E5%AE%89%E8%A3%85%E4%BD%BF%E7%94%A8/","title":"[Mac]Jmeter安装使用"},{"content":"MySQL进阶-触发器 介绍 触发器是与表有关的数据库对象，指在insert/update/delete之前(BEFORE)或之后(AFTER)，触发并执行触发器中定义的SQL语句集合。触发器的这种特性可以协助应用在数据库端确保数据的完整性，日志记录，数据校验等操作。\n使用别名OLD和NEW来引用触发器中发生变化的记录内容，这与其他的数据库是相似的。现在触发器还只支持行级触发，不支持语句级触发。\n触发器类型 NEW和OLD INSERT 型触发器 NEW 表示将要或者已经新增的数据 UPDATE 型触发器 OLD 表示修改之前的数据，NEW 表示将要或已经修改后的数据 DELETE 型触发器 OLD 表示将要或者已经删除的数据 语法 创建 1 2 3 4 5 CREATE TRIGGER trigger_name BEFORE/AFTER INSERT/UPDATE/DELETE ON table_name FOR EACH ROW -- 行级触发器 BEGIN trigger_stmt; END; 查看 1 SHOW TRIGGERS; 删除 1 2 -- 如果没有指定 schema_name.默认为当前数据库 DROP TRIGGER [schema_name.]trigger_name; 生词 trigger / ˈtrɪɡər / v、引发；触发；引爆；n、（枪械的）扳机；（引发不良反应或发展的）起因；（炸弹的）引爆器；触发器 案例 通过触发器记录 tb_user 表的数据变更日志，将变更日志插入到日志表user_logs中, 包含增加, 修改 , 删除 ;\n表结构准备 1 2 3 4 5 6 7 8 9 -- 准备工作：日志表 user_logs create table user_logs( id int(11) not null auto_increment, operation varchar(20) not null comment \u0026#39;操作类型，insert/update/delete\u0026#39;, operate_time datetime not null comment \u0026#39;操作时间\u0026#39;, operate_id int(11) not null comment \u0026#39;操作id\u0026#39;, operate_params varchar(500) comment \u0026#39;操作参数\u0026#39;, primary key(`id`) )engine=innodb default charset=utf8; 插入数据触发器 1 2 3 4 5 6 create trigger tb_user_insert_trigger after insert on tb_user for each row begin insert into user_logs(id, operation, operate_time, operate_id, operate_params) values (null, \u0026#39;insert\u0026#39;, now(), new.id, concat(\u0026#39;插入的数据内容为：id=\u0026#39;, new.id,\u0026#39;,name=\u0026#39;, new.name, \u0026#39;, phone=\u0026#39;, new.phone, \u0026#39;, email=\u0026#39;, new.email, \u0026#39;, profession=\u0026#39;, new.profession)); end; 测试 1 2 3 4 5 6 7 8 -- 查看 show triggers; -- 删除 drop trigger tb_user_insert_trigger; -- 插入数据到tb_user insert into tb_user(id, name, phone, email, profession, age, gender, status, createtime) values (26,\u0026#39;三皇子\u0026#39;, \u0026#39;18809091212\u0026#39;, \u0026#39;erhuangzi@163.com\u0026#39;,\u0026#39;软件工程\u0026#39;, 23, \u0026#39;1\u0026#39;, \u0026#39;1\u0026#39;, now()); 查看 删除 插入数据 测试完毕之后，检查日志表中的数据是否可以正常插入，以及插入数据的正确性。\n修改数据触发器 1 2 3 4 5 6 create trigger tb_user_update_trigger after update on tb_user for each row begin insert into user_logs(id, operation, operate_time, operate_id, operate_params) values (null,\u0026#39;update\u0026#39;,now(), new.id, concat(\u0026#39;更新之前的数据：id=\u0026#39;,old.id,\u0026#39;, name=\u0026#39;,old.name,\u0026#39;, phone=\u0026#39;,old.phone,\u0026#39;, email=\u0026#39;,old.email,\u0026#39;, profession=\u0026#39;,old.profession,\u0026#39; | 更新之后的数据：id=\u0026#39;,new.id,\u0026#39;, name=\u0026#39;,new.name,\u0026#39;, phone=\u0026#39;,new.phone,\u0026#39;, email=\u0026#39;,new.email,\u0026#39;, profession=\u0026#39;,new.profession)); end; 测试 1 2 3 4 5 6 -- 查看 show triggers; -- 更新 update tb_user set profession = \u0026#39;会计\u0026#39; where id = 23; update tb_user set profession = \u0026#39;会计\u0026#39; where id \u0026lt; 5; 测试完毕之后，检查日志表中的数据是否可以正常插入，以及插入数据的正确性。\n删除数据触发器 1 2 3 4 5 6 create trigger tb_user_delete_trigger after delete on tb_user for each row begin insert into user_logs(id, operation, operate_time, operate_id, operate_params) values (null, \u0026#39;delete\u0026#39;, now(), old.id, concat(\u0026#39;删除之前的数据：id=\u0026#39;,old.id,\u0026#39;, name=\u0026#39;,old.name,\u0026#39;, phone=\u0026#39;,old.phone,\u0026#39;, email=\u0026#39;,old.email,\u0026#39;, profession=\u0026#39;,old.profession)); end; 测试 1 2 3 4 5 -- 查看 show triggers; -- 删除 delete from tb_user where id = 26; 测试完毕之后，检查日志表中的数据是否可以正常插入，以及插入数据的正确性。\n","date":"2025-11-23T15:54:37+08:00","permalink":"https://YLine-hub.github.io/p/mysql%E8%BF%9B%E9%98%B6-%E8%A7%A6%E5%8F%91%E5%99%A8/","title":"[MySQL]进阶-触发器"},{"content":"MySQL进阶-存储过程 介绍 存储过程是事先经过编译并存储在数据库中的一段SQL语句的集合，调用存储过程可以简化应用开发人员的很多工作，减少数据在数据库和应用服务器之间的传输，对于提高数据处理的效率是有好处的。存储过程思想上很简单，就是数据库SQL语言层面的的代码封装与重用。\n特点 封装，复用\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;\u0026gt; 可以把某一业务SQL封装在存储过程中，需要用到 的时候直接调用即可。 可以接收参数，也可以返回数据\u0026mdash;\u0026mdash;\u0026ndash;\u0026gt; 在存储过程中，可以传递参数，也可以接收返回 值。 减少网络交互，效率提升\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-\u0026gt; 如果涉及到多条SQL，每执行一次都是一次网络传 输。 而如果封装在存储过程中，我们只需要网络交互一次可能就可以了。 语法 创建 1 2 3 4 CREATE PROCEDURE 存储过程名称([参数列表]) BEGIN -- SQL语句 END; 示例 创建存储过程 1 2 3 4 create procedure p1() begin select count(*) from student; end; MySQL命令行写法 1 2 3 4 5 6 delimiter // create procedure p1() begin select count(*) from student; end// delimiter ; 创建第一个存储过程；事先用DELIMITER关键字申明当前段分隔符，这样MySQL才会将\u0026quot;;\u0026ldquo;当做存储过程中的代码；\n调用 1 CALL 名称([参数]); 示例 调用p1函数 1 call p1(); 查看 查询指定数据库的存储过程及状态信息 1 SELECT * FROM INFORMATION_SCHEMA.ROUTINES WHERE ROUTINES_SCHEMA=\u0026#39;xxx\u0026#39;; 查询某个存储过程的定义 1 SHOW CREATE PROCEDURE 存储过程名称; 示例 查询itcast数据库的存储过程及状态信息 1 select * from information_schema.ROUTINES where ROUTINE_SCHEMA=\u0026#39;itcast\u0026#39;; 查询p1存储过程的定义 1 show create procedure p1; 删除 1 DROP PROCEDURE [IF EXISTS] 存储过程名称; 示例 删除p1存储过程 1 drop procedure if exists p1; 变量 在MySQL中变量分为三种类型：系统变量、用户定义变量、局部变量。 系统变量 系统变量是MySQL服务器提供，不是用户定义的，属于服务器层面。分为全局变量(GLOBAL)、会话变量(SESSION)。 基本语法 查看系统变量 查看所有系统变量 1 SHOW [SESSION|GLOBAL] VARIABLES; 可以通过LIKE模糊匹配方式查找变量 1 SHOW [SESSION|GLOBAL] VARIABLES LIKE \u0026#39;......\u0026#39;; 查看指定变量的值 1 SELECT @@[SESSION|GLOBAL] 系统变量值; 设置系统变量 第一种 1 SET [SESSION|GLOBAL] 系统变量名 = 值; 第二种 1 SET @@[SESSION|GLOBAL] 系统变量名 = 值; 注意：\n1.如果没有指定SESSION/GLOBAL，默认是SESSION，会话变量\n2.mysql服务重新启动之后，所设置的全局参数会失效，要想不失效，可以在/etc/my.cnf中配置\n用户定义变量 用户定义变量是用户根据需要自己定义的变量，用户变量不用提前声明，在用的时候直接用\u0026rdquo;@变量名\u0026quot;使用就可以。其作用域为当前连接。 基本语法 赋值 SET方式赋值 1 2 3 4 # 第一种 SET @var_name=expr [,@var_name=expr]...; # 第二种 SET @var_name:=expr [,@var_name:=expr]...; SELECT方式赋值 1 2 3 4 # 第一种 SELECT @var_name:=expr [,@var_name:=expr]...; # 第二种(表中查询出来的数据赋值给变量) SELECT 字段名 INTO @var_name FROM 表名; 推荐使用:=，因为在MySQL中比较运算符也是=，所以为了和比较运算符做区分，推荐使用:=\n注意：用户定义的变量无需对其进行声明或初始化，只不过获取到的值为NULL。\n使用 1 SELECT @var_name; 局部变量 局部变量是根据需要定义的在局部生效的变量，访问之前，需要DECLARE声明。可用做存储过程内的局部变量和输入参数，局部变量的范围是在其内声明的BEGIN \u0026hellip; END块。 基本语法 声明 1 DECLARE 变量名 变量类型 [DEFAULT ... ]; 变量类型就是数据库字段类型：INT、BIGINT、CHAR、VARCHAR、DATE、TIME等。\n赋值 1 2 3 SET 变量名=值; SET 变量名:=值; SELECT 字段名 INTO 变量名 FROM 表名; 示例 系统变量 查询所有系统变量(默认session) 1 show variables; 查询auto开头的系统变量(session) 1 show session variables like \u0026#39;auto%\u0026#39;; 查询auto开头的系统变量(global) 1 show global variables like \u0026#39;auto%\u0026#39;; 查询autocommit系统变量(session) 1 select @@autocommit; 查询autocommit系统变量(global) 1 select @@global.autocommit; 关闭系统变量autocommit(session) 1 set session autocommit = 0; 关闭系统变量autocommit(global) 新开一个窗口，查询系统变量\n全局级别的系统变量，当修改完以后，除了当前会话其他都会修改，但是当重启mysql以后将会重置。\n用户定义变量 给myname变量赋值itcast 1 set @myname = \u0026#39;itcast\u0026#39;; 给myage变量赋值10 1 set @myage = 10; 给mygender赋值男，给myhobby变量赋值java 1 set @mygender := \u0026#39;男\u0026#39; ,@myhobby := \u0026#39;java\u0026#39;; 给mycolor赋值red 1 select @mycolor := \u0026#39;red\u0026#39;; 查询tb_user的数据数量赋值给mycount 1 select count(*) into @mycount from tb_user; 查看变量myname，myage，mygender，myhobby 1 select @myname,@myage,@mygender,@myhobby; 查看变量mycolor，mycount的值 1 select @mycolor ,@mycount; 查看abc的值 1 select @abc; 局部变量 声明局部变量 - declare\n赋值(datagrip)\n1 2 3 4 5 6 7 8 create procedure p2() begin declare stu_count int default 0; select count(*) into stu_count from student; select stu_count; end; call p2(); 赋值(命令行) 1 2 3 4 5 6 7 8 9 10 delimiter // create procedure p2() begin declare stu_count int default 0; select count(*) into stu_count from student; select stu_count; end// delimiter ; call p2(); if 介绍 if用于做条件判断，具体的语法结构为：\n1 2 3 4 5 6 7 IF 条件1 THEN ..... ELSEIF 条件2 THEN -- 可选 ..... ELSE -- 可选 ..... END IF; 在if条件判断的结构中，ELSE IF结构可以有多个，也可以没有。ELSE结构可以有，也可以没有。\n案例 根据定义的分数score变量，判定当前分数对应的分数等级。\nscore \u0026gt;= 85分，等级为优秀。 score \u0026gt;= 60分 且 score \u0026lt; 85分，等级为及格。 score \u0026lt; 60分，等级为不及格 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 create procedure p3() begin declare score int default 58; declare result varchar(10); if score \u0026gt;= 85 then set result := \u0026#39;优秀\u0026#39;; elseif score \u0026gt;= 60 then set result := \u0026#39;及格\u0026#39;; else set result := \u0026#39;不及格\u0026#39;; end if; select result; end; call p3(); 上述的需求我们虽然已经实现了，但是也存在一些问题，比如：score 分数我们是在存储过程中定义死的，而且最终计算出来的分数等级，我们也仅仅是最终查询展示出来而已。\n那么我们能不能，把score分数动态的传递进来，计算出来的分数是否可以作为返回值返回呢？答案是肯定的，我们可以通过接下来所讲解的 参数 来解决上述问题。\n参数 介绍 参数的类型，主要分为以下三种：IN、OUT、INOUT。具体的含义如下：\n类型 含义 备注 IN 该类参数作为输入，也就是需要调用时传入值 默认 OUT 该类参数作为输出，也就是该参数可以作为返回值 INOUT 既可以作为输入参数，也可以作为输出参数 用法 1 2 3 4 CREATE PROCEDURE 存储过程名称([IN/OUT/INOUT 参数名 参数类型]) BEGIN -- SQL语句 END ; 示例 案例一 根据传入参数score，判定当前分数对应的分数等级，并返回。\nscore \u0026gt;= 85分，等级为优秀。 score \u0026gt;= 60分 且 score \u0026lt; 85分，等级为及格。 score \u0026lt; 60 分，等级为不合格。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 create procedure p4(in score int ,out result varchar(10)) begin if score \u0026gt;= 85 then set result := \u0026#39;优秀\u0026#39;; elseif score \u0026gt;= 60 then set result := \u0026#39;及格\u0026#39;; else set result := \u0026#39;不及格\u0026#39;; end if; end; -- 定义用户变量@result来接收返回的数据，用户变量可以不用声明 call p4(18,@result); select @result; 案例二 将传入的200分制的分数，进行换算，换算成百分制，然后返回。\n1 2 3 4 5 6 7 8 9 create procedure p5(inout score double) begin set score := score * 0.5; end; set @score = 198; call p5(@score); select @score; case 介绍 case结构及作用，和我们在基础篇中所讲解的流程控制函数很类似。有两种语法格式：\n语法1 1 2 3 4 5 6 7 -- 含义：当case_value的值为when_value1时，执行statement_list1，当值为when_value2时，执行statement_list2，否则执行statement_list CASE case_value WHEN when_value THEN statement_list1 [WHEN when_value2 THEN statement_list2] ... [ELSE statement_list] END CASE; 语法2 1 2 3 4 5 6 -- 含义：当条件search_condition1成立时，执行statement_list1，当条件search_condition2成立时，执行statement_list2，否则就执行statement_list CASE WHEN search_condition1 THEN statement_list1 [WHEN search_condition2 THEN staement_list2]... [ELSE statement_list] END CASE; 案例 根据传入的月份，判定月份所属的季节(要求采用case结构)。\n1-3月份，为第一季度 4-6月份，为第二季度 7-9月份，为第三季度 10-12月份，为第四季度 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 create procedure p6(in month int) begin declare result varchar(10); case when month \u0026gt;= 1 and month \u0026lt;= 3 then set result := \u0026#39;第一季度\u0026#39;; when month \u0026gt;= 4 and month \u0026lt;= 6 then set result := \u0026#39;第二季度\u0026#39;; when month \u0026gt;= 7 and month \u0026lt;= 9 then set result := \u0026#39;第三季度\u0026#39;; when month \u0026gt;= 10 and month \u0026lt;= 12 then set result := \u0026#39;第四季度\u0026#39;; else set result := \u0026#39;非法参数\u0026#39;; end case; select concat(\u0026#39;您输入的月份为：\u0026#39;,month,\u0026#39;，所属的季度为：\u0026#39;, result); end; call p6(16); 注意：如果判定条件有多个，多个条件之间，可以使用 and 或 or 进行连接。\nwhile 介绍 while 循环是有条件的循环控制语句。满足条件后，再执行循环体中的SQL语句。\n语法 1 2 3 4 5 -- 先判定条件，如果条件为true，则执行逻辑，否则，不执行逻辑。 WHILE 条件 DO SQL逻辑... END WHILE; 案例 计算从1累加到n的值，n为传入的参数值。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 -- A.定义局部变量，记录累加之后的值； -- B.每循环一次，就会对n进行减1，如果n减到0，则退出循环 create procedure p7(in n int) begin declare total int default 0; while n\u0026gt;0 do set total := total + n; set n := n - 1; end while; select total; end; call p7(100); repeat 介绍 repeat 是有条件的循环控制语句，当满足until声明的条件的时候，则退出循环。\n语法 1 2 3 4 5 6 -- 先执行一次逻辑，然后判定UNTIL条件是否满足，如果满足，则退出。如果不满足，则继续下一次循环 REPEAT SQL逻辑... UNTIL 条件 END REPEAT; 案例 计算从1累加到n的值，n为传入的参数值。(使用repeat实现) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 -- A.定义局部变量，记录累加之后的值； -- B.每循环一次，就会对 create procedure p8(in n int) begin declare total int default 0; repeat set total := total + n; set n := n - 1; until n \u0026lt;= 0 end repeat; select total; end; call p8(10); call p8(100); loop 介绍 LOOP 实现简单的循环，如果不在SQL逻辑中增加退出循环的条件，可以用其来实现简单的死循环。 LOOP 可以配合以下两个语句来使用：\nLEAVE：配合循环使用，退出循环。 ITERATE：必须用在循环中，作用是跳过当前循环剩下的语句，直接进入下一次循环。 语法 LOOP 1 2 3 [begin_label:] LOOP SQL 逻辑... END LOOP [end_label]; 退出 1 2 LEAVE label; -- 退出指定标记的循环体 ITERATE label; -- 直接进入下一次循环 上述语法中出现的begin_label，end_label，label 指的都是我们所自定义的标记。\n案例 案例一 计算从1累加到n的值，n为传入的参数值。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 -- A.定义局部变量，记录累加之后的值； -- B.每循环一次，就会对n进行-1，如果n见到0，则退出循环 ----\u0026gt; leave xxx create procedure p9(in n int) begin declare total int default 0; sum:loop if n \u0026lt;= 0 then leave sum; end if; set total := total + n; set n := n - 1; end loop sum; select total; end; call p9(100); 案例二 计算从1到n之间的偶数累加的值，n为传入的参数。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 -- A.定义局部变量，记录累加之后的值； -- B.每循环一次，就会对n进行-1，如果n减到0，则退出循环 ----\u0026gt; leave xx -- C.如果当次累加的数据是奇数，则直接进入下一次循环 ----\u0026gt; iterate xx create procedure p10(in n int) begin declare total int default 0; sum:loop if n \u0026lt;= 0 then leave sum; end if; if n % 2 = 1 then set n := n - 1; iterate sum; end if; set total := total + n; set n := n - 1; end loop sum; select total; end; call p10(100); 生词 iterate / ˈɪtəreɪt / v、迭代；重复；重做 游标 介绍 游标(CURSOR)是用来存储查询结果集的数据类型，在存储过程和函数中可以使用游标对结果集进行循环的处理。游标的使用包括游标的声明、OPEN、FETCH和CLOSE，其语法分别如下。\n语法 声明游标 1 DECLARE 游标名称 CURSOR FOR 查询语句; 打开游标 1 OPEN 游标名称; 获取游标记录 1 FETCH 游标名称 INTO 变量 [,变量]; 关闭游标 1 CLOSE 游标名称; 案例 根据传入的参数uage，来查询用户表tb_user中，所有的用户年龄小于等于uage的用户姓名(name)和专业(profession)，并将用户的姓名和专业插入到所创建的一张新表(id,name,profession)中。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 -- 逻辑： -- A.声明游标，存储查询结果集 -- B.准备：创建表结构 -- C.开启游标 -- D.获取游标中的记录 -- E.插入数据到新表中 -- F.关闭游标 create procedure p11(in uage int) begin declare uname varchar(100); declare upro varchar(100); -- 声明游标(注意：声明游标要在声明普通变量之后) declare u_cursor cursor for select name,profession from tb_user where age \u0026lt;= uage; drop table if exists tb_user_pro; create table if not exists tb_user_pro ( id int primary key auto_increment, name varchar(100), profession varchar(100) ); -- 打开游标 open u_cursor; while true do -- 获取一行游标的的数据，存入变量中 fetch u_cursor into uname,upro; -- 将变量插入表中 insert into tb_user_pro values(null,uname,upro); end while; -- 关闭游标 close u_cursor; end; call p11(40); 上述的存储过程，最终我们在调用的过程中，会报错，之所以报错是因为上面的while循环中，并没有 退出条件。当游标的数据集获取完毕之后，再次获取数据，就会报错，从而终止了程序的执行。\n但是此时，tb_user_pro表结构及其数据都已经插入成功了，我们可以直接刷新表结构，检查表结构 中的数据。\n上述的功能，虽然我们实现了，但是逻辑并不完善，而且程序执行完毕，获取不到数据，数据库还报 错。 接下来，我们就需要来完成这个存储过程，并且解决这个问题。 要想解决这个问题，就需要通过MySQL中提供的 条件处理程序 Handler 来解决。\n生词 cursor / ˈkɜːrsər / n、光标；(计算尺的)[计]游标，指标 cursorily / ˈkɜːrsərəli / adv、疏忽地；马虎地；粗糙地 条件处理程序 介绍 条件处理程序(Handler)可以用来定义在流程控制结构中遇到问题时相应的处理步骤。 语法 1 DECLARE handler_action HANDLER FOR condition_value [, condition_value]... statement; handler 的取值：\nCONTINUE：继续执行当前程序 EXIT：终止执行当前程序 condition_value 的取值：\nSQLSTATE sqlstate_value：状态码，如02000\nSQLWARING：所有以01开头的SQLSTATE代码的简写\nNOT FOUND：所有以02开头的SQLSTATE代码的简写\nSQLEXCEPTION：所有没有被 SQLWARING 或 NOT FOUND 捕获的SQLSTATE代码的简写\n案例 我们继续上一小节提出的这个需求，并解决其中的问题。\n根据传入的参数uage，来查询用户表tb_user中，所有的用户年龄小于等于uage的用户姓名 (name)和专业(profession)，并将用户的姓名和专业插入到所创建的一张新表 (id,name,profession)中。\n通过SQLSTATE指定具体的状态码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 -- 删除原先的p11存储过程 drop procedure if exists p11; -- 逻辑： -- A.声明游标，存储查询结果集 -- B.准备：创建表结构 -- C.开启游标 -- D.获取游标中的记录 -- E.插入数据到新表中 -- F.关闭游标 create procedure p11(in uage int) begin declare uname varchar(100); declare upro varchar(100); declare u_cursor cursor for select name, profession from tb_user where age \u0026lt;= uage; -- 声明条件处理程序：当SQL语句执行抛出的状态为02000时，将关闭游标u_cursor，并退出。 declare exit handler for SQLSTATE \u0026#39;02000\u0026#39; close u_cursor; drop table if exists tb_user_pro; create table if not exists tb_user_pro ( id int primary key auto_increment, name varchar(100), profession varchar(100) ); open u_cursor; while true do fetch u_cursor into uname,upro; insert into tb_user_pro values (null, uname, upro); end while; close u_cursor; end; call p11(40); 通过SQLSTATE的代码方式简写 02开头的状态码，代码简写为 NOT FOUND\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 create procedure p12(in uage int) begin declare uname varchar(100); declare upro varchar(100); declare u_cursor cursor for select name, profession from tb_user where age \u0026lt;= uage; -- 声明条件处理程序：当SQL语句执行抛出的状态码为02开头时，将关闭游标u_cursor，并退出 declare exit handler for not found close u_cursor; drop table if exists tb_user_pro; create table if not exists tb_user_pro ( id int primary key auto_increment, name varchar(100), profession varchar(100) ); open u_cursor; while true do fetch u_cursor into uname, upro; insert into tb_user_pro values (null, uname, upro); end while; close u_cursor; end; call p12(40); 错误状态码 具体错误状态码，可以参考官方文档： declare-handler server-error-reference 存储函数 介绍 存储函数是有返回值的存储过程，存储函数的参数只能是IN类型的。 语法 1 2 3 4 5 6 CREATE FUNCTION 存储函数名称([参数列表]) RETURNS type [characteristic ...] BEGIN -- SQL语句 RETURN ...; END characteristic说明： DETERMINISTIC：相同的输入参数总是产生相同的结果 NO SQL：不包含SQL语句 READS SQL DATA：包含读取数据的语句，但不包含写入数据的语句。 案例 计算从1累加到n的值，n为传入的参数值。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 create function fun1(n int) returns int begin declare total int default 0; while n \u0026gt; 0 do set total := total + n; set n := n - 1; end while; return total; end; select fun1(50); 在mysql8.0版本中binlog默认是开启的，一旦开启了，mysql就要求在定义存储过程时，需要指定 characteristic特性，否则就会报如下错误:\n","date":"2025-11-20T15:47:04+08:00","permalink":"https://YLine-hub.github.io/p/mysqlmysql%E8%BF%9B%E9%98%B6-%E5%AD%98%E5%82%A8%E8%BF%87%E7%A8%8B/","title":"[MySQL]MySQL进阶-存储过程"},{"content":"视图 介绍 视图(View)是一种虚拟存在的表。视图中的数据并不在数据库中实际存在，行和列数据来自定义视图的查询中使用的表，并且是在使用视图时动态生成的。\n通俗的讲，视图只保存了查询的SQL逻辑，不保存查询结果。所以我们在创建视图的时候，主要工作就落在这条SQL查询语句上。\n语法 创建 1 CREATE [OR REPLACE] VIEW 视图名称[(列表名称)] AS SELECT语句 [WITH [CASCADED|LOCAL] CHECK OPTION] 查询 查看创建视图语句 1 SHOW CREATE VIEW 视图名称; 查看视图数据 1 SELECT * FROM 视图名称......; 修改 方式一 1 CREATE [OR REPLACE] VIEW 视图名称[(列表名称)] AS SELECT语句 [WITH [CASCADED|LOCAL] CHECK OPTION] 方式二 1 ALTER VIEW 视图名称[(列表名称)] AS SELECT语句 [WITH [CASCADED|LOCAL] CHECK OPTION] 删除 1 DROP VIEW [IF EXISTS] 视图名称 [,视图名称] ... 演示 创建视图 封装从student表中查询id，name条件为id小于等于10的视图 1 create or replace view stu_v_1 as select id, name from student where id \u0026lt;= 10; 可以看到datagrip中出现了视图stu_v_1，并且列为id，name。\n查询视图 查询创建stu_v_1视图语句 1 show create view stu_v_1; 查询stu_v_1视图数据 1 select * from stu_v_1; 查询stu_v_1视图数据，条件id小于3 1 select * from stu_v_1 where id \u0026lt; 3; 修改视图 修改视图stu_v_1内容为从student表中查询id，name，no，条件为id小于等于10 1 create or replace view stu_v_1 as select id, name, no from student where id \u0026lt;= 10; 修改视图stu_v_1为从student表中查询id，name，条件为id小于等于10 1 alter view stu_v_1 as select id, name from student where id \u0026lt;= 10; 删除视图 删除视图stu_v_1 1 drop view if exists stu_v_1; 通过视图插入数据 创建视图从student表中查询id，name条件为id小于等于10 1 create or replace view stu_v_1 as select id, name from student where id \u0026lt;= 10; 查询stu_v_1视图数据 1 select * from stu_v_1; 插入id为6的数据 1 insert into stu_v_1 values(6,\u0026#39;Tom\u0026#39;); 插入id为17的数据 1 insert into stu_v_1 values(17,\u0026#39;Tom22\u0026#39;); 执行上诉SQL，发现，id为6和17的数据都是可以插入的，但是执行查询，查出来的数据，却没有id为17的记录。\n因为在创建视图的时候，指定条件为id\u0026lt;=10，id为17的数据，是不符合条件的，所以没有查询出来，但是这条数据确实是已经成功的插入到了基表中。\n如果我们定义视图时，如果指定了条件，然后我们在插入、修改、删除数据时，是否可以做到必须满足条件才能操作，否则不能够操作呢？答案是可以的，这就需要借助视图的检查选项了。\n检查选项 当使用WITH CHECK OPTION子句创建视图时，MySQL会通过视图检查正在更正的每个行，例如 插入，更新，删除，以使其符合视图的定义。MySQL允许基于另一个视图创建视图，它还会检查依赖视图中的规则以保持一致性。为了确定检查的范围，mysql提供了两个选项：CASCADED 和 LOCAL，默认值为CASCADED。\n演示 A、数据准备\n删除stu_v_1视图，id为6和id为17的数据 1 2 delete from stu_v_1 where id = 6; delete from stu_v_1 where id = 17; B、操作\n修改stu_v_1视图，增加检查选项功能 1 create or replace view stu_v_1 as select id, name from student where id \u0026lt;= 10 with cascaded check option; 插入id为6的数据 1 insert into stu_v_1 values(6,\u0026#39;Tom\u0026#39;); 插入id为17的数据 1 insert into stu_v_1 values(17,\u0026#39;Tom22\u0026#39;); 能够看到当id\u0026gt;10的时候，插入报错。\nCASCADED(级联) 比如，v2视图是基于v1视图的，如果在v2视图创建的时候指定了检查选项为cascaded，但是v1视图未指定检查选项。则在检查时，不仅会检查v2，还会联级检查v2的关联视图v1。 演示 修改视图stu_v_1为从student表中查询id，name，条件为id\u0026lt;=20 1 create or replace view stu_v_1 as select id, name from student where id \u0026lt;= 20; 插入id为5的数据 1 insert into stu_v_1 values(5,\u0026#39;Tom5\u0026#39;); 插入id为25的数据 1 insert into stu_v_1 values(25,\u0026#39;Tom25\u0026#39;); 创建视图stu_v_2，封装从视图stu_v_1中查询id，name，条件为id大于等于10，并且指定检查选项为cascaded 1 create or replace view stu_v_2 as select id, name from stu_v_1 where id \u0026gt;= 10 with cascaded check option; 插入id为7的数据到视图stu_v_2中 1 insert into stu_v_2 values(7,\u0026#39;Tom7\u0026#39;); 此时显示不符合，因为stu_v_2添加了检查选项，id要求大于等于10\n插入id为26的数据到视图stu_v_2中 1 insert into stu_v_2 values(26,\u0026#39;Tom26\u0026#39;); 当插入id为26的数据时，也显示不符合。因为当前加的是cascaded检查选项，它会去检查当前视图所依赖的底层所有视图，并且会查询底层视图的条件，此时检查到stu_v_1的id不满足条件从而报错。\n插入id为15的数据到视图stu_v_2中 1 insert into stu_v_2 values(15,\u0026#39;Tom15\u0026#39;); 创建stu_v_3视图，封装从视图stu_v_2中查询id，name，条件为id小于等于15 1 create or replace view stu_v_3 as select id, name from stu_v_2 where id \u0026lt;= 15; 插入id为11的数据 1 insert into stu_v_3 values(11,\u0026#39;Tom11\u0026#39;); 插入id为18的数据 1 insert into stu_v_3 values(18,\u0026#39;Tom18\u0026#39;); 插入成功，因为stu_v_3视图没有设置检查选项，并且满足底层视图stu_v_2的需求，以及因为stu_v_2视图的cascaded检查选项需要满足，且实际上满足stu_v_1的条件，可以正常插入。\n插入id为28的数据 1 insert into stu_v_3 values(28,\u0026#39;Tom28\u0026#39;); 由于stu_v_3视图没有加检查选项，所以不会去检查是否满足stu_v_3的条件。而stu_v_3视图依赖于stu_v_2(stu_v_2视图加了cascaded)，所以需要满足stu_v_2的条件，这里28大于10满足条件。由于加了with cascaded check option，紧接着回去检查底层依赖的stu_v_1视图，此时发现不满足stu_v_1的需求，就返回错误信息。\nLOCAL(本地) 比如，v2视图是基于v1视图的，如果v2视图创建的时候指定了检查选项为local，但是v1视图创建未指定检查选项。则在执行检查时，只会检查v2，不会检查v2的关联视图v1。 演示 封装从student表中查询id，name到视图stu_v_4中，条件为id小于等于15 1 create or replace view stu_v_4 as select id, name from student where id \u0026lt;= 15; 插入id为5的数据到v4视图 1 insert into stu_v_4 values(7,\u0026#39;Tom7\u0026#39;); 插入id为16的数据到v4视图 1 insert into stu_v_4 values(16,\u0026#39;Tom16\u0026#39;); 封装从v4视图中查询id，name，条件为id大于等于10的语句到v5视图中，并且指定local检查选项 1 create or replace view stu_v_5 as select id, name from stu_v_4 where id \u0026gt;=10 with local check option; 插入id为13的数据到v5视图中 1 insert into stu_v_5 values(13,\u0026#39;Tom13\u0026#39;); 插入id为19的数据到v5视图中 1 insert into stu_v_5 values(19,\u0026#39;Tom19\u0026#39;); 封装从视图v5中查询id，name，条件为id小于20的语句到视图v6中 1 create or replace view stu_v_6 as select id, name from stu_v_5 where id \u0026lt; 20; 插入id为14的数据到视图v6中 1 insert into stu_v_6 values(14,\u0026#39;Tom14\u0026#39;); 修改v4视图，添加本地检查选项 1 create or replace view stu_v_4 as select id, name from student where id \u0026lt;= 15 with local check option; 从student表删除id为19的数据 1 delete from student where id = 19; 插入id为19的数据到stu_v_5 1 insert into stu_v_5 values(19,\u0026#39;Tom19\u0026#39;); 对于local视图检查选项，当我们在操作视图的时候，它会去递归的查找当前视图所依赖的视图，如果说当前视图，以及依赖的视图，后面定义的有检查选项，它会去判定我们插入的数是否会满足它的条件，如果递归的时候，某个视图没有定义检查选项，此时我们操作的时候，不会去判断它的条件。\n更新及作用 视图的更新 要使视图更新，视图的行与基础表中的行必须存在一对一的关系。如果视图包含以下任何一项，则该视图不可更新： 聚合函数或窗口函数(SUM()、MIN()、MAX()、COUNT()等) DISTINCT GROUP BY HAVING UNION 或者 UNION ALL 演示 创建视图，使用聚合函数 1 create view stu_v_count as select count(*) from student; 此时视图的数据和表中的数据并不是一一对应的关系。\n插入数据10 1 insert into stu_v_count values(10); 不能进行插入，当然也不能进行更新\n视图的作用 简单 视图不仅可以简化用户对数据的理解，也可以简化他们的操作。那些经常使用的查询可以被定义为视图，从而使得用户不必为以后的操作每次指定全部的条件。 安全 数据库可以授权，但不能授权到数据库特定行和特定的列上。通过视图用户只能查询和修改他们所能见到的数据。 数据独立 视图可以帮助用户屏蔽真实表结构带来的影响。 案例 根据如下需求，定义视图：\n案例一 为了保证数据库表的安全性，开发人员在操作tb_user表时，只能看到用户的基本字段，屏蔽手机号和邮箱两个字段。\n1 create view tb_user_view as select id, name, profession, age, gender, status, createtime from tb_user; 查询数据 1 select * from tb_user_view; 案例二 查询每个学生所选修的课程(三张表联查)，这个功能在很多的业务中都有使用到，为了简化操作，定义一个视图。\n1 create view tb_stu_course_view as select s.name, s.no, c.name from student s,student_course sc, course c where s.id = sc.studentid and c.id = sc.courseid; 显示重复字段name，给字段起别名 1 create view tb_stu_course_view as select s.name student_name, s.no student_no, c.name course_name from student s,student_course sc, course c where s.id = sc.studentid and c.id = sc.courseid; 查询数据 1 select * from tb_stu_course_view; ","date":"2025-11-18T15:48:42+08:00","permalink":"https://YLine-hub.github.io/p/mysqlmysql%E8%BF%9B%E9%98%B6-%E8%A7%86%E5%9B%BE/","title":"[MySQL]MySQL进阶-视图"},{"content":"SQL优化 插入数据 insert优化 批量插入 1 insert into tb_test values(1,\u0026#39;Tom\u0026#39;),(2,\u0026#39;Cat\u0026#39;),(3,\u0026#39;jerry\u0026#39;); 不建议一条一条数据插入\n手动提交事务 1 2 3 4 5 start transation; insert into tb_test values(1,\u0026#39;Tom\u0026#39;),(2,\u0026#39;Cat\u0026#39;),(3,\u0026#39;jerry\u0026#39;); insert into tb_test values(4,\u0026#39;Tom\u0026#39;),(5,\u0026#39;Cat\u0026#39;),(6,\u0026#39;jerry\u0026#39;); insert into tb_test values(7,\u0026#39;Tom\u0026#39;),(8,\u0026#39;Cat\u0026#39;),(9,\u0026#39;jerry\u0026#39;); commit; MySQL默认自动提交事务，当插入一条语句之前，他会开启事务，插入语句之后，会提交事务。所以当插入多条语句时，会频繁提交事务。所以建议手动提交事务。\n主键顺序插入 1 2 主键乱序插入：8 1 9 21 88 2 4 15 89 5 7 3 主键顺序插入：1 2 3 4 5 7 8 9 15 21 88 89 主键顺序插入的性能，要高于乱序插入。\n大批量插入数据 如果一次性需要插入大量数据，使用insert语句插入性能较低，此时可以使用MySQL提供的load指令进行插入。操作如下： 1 2 3 4 5 6 # 客户端连接服务器时，加上参数 --local-infile mysql --local-infile -uroot -p # 设置全局参数local_infile为1，开启从本地加载文件导入数据的开关 set global local_infile=1 # 执行local指令将准备好的数据，加载到表结构中 local data local infile \u0026#39;/root/sql1.log\u0026#39; into table `tb_user` fileds terminated by \u0026#39;,\u0026#39; lines terminated by \u0026#39;\\n\u0026#39;; 演示 数据准备 1 2 3 4 5 6 7 8 9 10 CREATE TABLE `tb_user` ( `id` INT(11) NOT NULL AUTO_INCREMENT, `username` VARCHAR(50) NOT NULL, `password` VARCHAR(50) NOT NULL, `name` VARCHAR(20) NOT NULL, `birthday` DATE DEFAULT NULL, `sex` CHAR(1) DEFAULT NULL, PRIMARY KEY (`id`), UNIQUE KEY `unique_user_username` (`username`) ) ENGINE=INNODB DEFAULT CHARSET=utf8 ; 客户端连接服务端时，加上参数 -–local-infile 1 mysql –-local-infile -uroot -p 查看系统变量local_infile 1 select @@local_infile; 设置全局参数local_infile为1，开启从本地加载文件导入数据的开关 1 set global local_infile = 1; 查看文件行数 1 wc -l load_user_100w_sort.sql [Mac]上传sql文件到服务器/root/sql目录下 1 scp load_user_100w_sort.sql root@172.16.140.101:/root/sql load加载数据 1 load data local infile \u0026#39;/root/sql/load_user_100w_sort.sql\u0026#39; into table tb_user fields terminated by \u0026#39;,\u0026#39; lines terminated by \u0026#39;\\n\u0026#39;; 我们看到，插入100w的记录，6.75s就完成了，性能很好。\n在load时，主键顺序插入性能高于乱序插入。\n主键优化 数据组织方式 在InnoDB存储引擎中，表数据都是根据主键顺序组织存放的，这种存储方式的表称为索引组织表(index organized table 简称IOT) 行数据，都是存储在聚集索引的叶子结点上的。InnoDB的逻辑存储结构： 页分裂 页可以为空，也可以填充一半，也可以填充100%。每个页包含了2-N行数据(如果一行数据大，会行溢出)，根据主键排列。 A. 主键顺序插入效果\n从磁盘中申请页， 主键顺序插入 第一个页没有满，继续往第一页插入 当第一个也写满之后，再写入第二个页，页与页之间会通过指针连接 当第二页写满了，再往第三页写入 B. 主键乱序插入效果\n加入1#,2#页都已经写满了，存放了如图所示的数据 此时再插入id为50的记录，我们来看看会发生什么现象\n会再次开启一个页，写入新的页中吗? 不会。因为，索引结构的叶子节点是有顺序的。按照顺序，应该存储在47之后。\n但是47所在的1#页，已经写满了，存储不了50对应的数据了。 那么此时会开辟一个新的页 3#。\n但是并不会直接将50存入3#页，而是会将1#页后一半的数据，移动到3#页，然后在3#页，插入50。\n移动数据，并插入id为50的数据之后，那么此时，这三个页之间的数据顺序是有问题的。 1#的下一个 页，应该是3#， 3#的下一个页是2#。 所以，此时，需要重新设置链表指针。\n上述的这种现象，称之为 \u0026ldquo;页分裂\u0026rdquo;，是比较耗费性能的操作。\n页合并 目前表中已有数据的索引结构(叶子节点)如下:\n当我们对已有数据进行删除时，具体的效果如下:\n当删除一行记录时，实际上记录并没有被物理删除，只是记录被标记(flaged)为删除并且它的空间变得允许被其他记录声明使用。\n当我们继续删除2#的数据记录\n当页中删除的记录达到 MERGE_THRESHOLD(默认为页的50%)，InnoDB会开始寻找最靠近的页(前 或后)看看是否可以将两个页合并以优化空间使用。\n删除数据，并将页合并之后，再次插入新的数据21，则直接插入3#页\n这个里面所发生的合并页的这个现象，就称之为 \u0026ldquo;页合并\u0026rdquo;。\n知识小贴士: MERGE_THRESHOLD:合并页的阈值，可以自己设置，在创建表或者创建索引时指定。\n主键设计原则 满足业务需求的情况下，尽量降低主键的长度。 插入数据时，尽量选择顺序插入，选择使用AUTO_INCREMENT自增主键。 尽量不要使用UUID做主键或者是其他自然主键，如身份证号。 业务操作时，避免对主键的修改。 order by优化 MySQL的排序，有两种方式:\nUsing filesort : 通过表的索引或全表扫描，读取满足条件的数据行，然后在排序缓冲区sort buffer中完成排序操作，所有不是通过索引直接返回排序结果的排序都叫 FileSort 排序。 Using index : 通过有序索引顺序扫描直接返回有序数据，这种情况即为 using index，不需要 额外排序，操作效率高。 对于以上的两种排序方式，Using index的性能高，而Using filesort的性能低，我们在优化排序 操作时，尽量要优化为 Using index。\n接下来做个测试：\n数据准备 把之前测试时，为tb_user表所建立的部分索引直接删除掉\n1 2 3 drop index idx_user_phone on tb_user; drop index index_user_name on tb_user; drop index idx_user_age on tb_user; 查询tb_user表的id，age，phone根据age升序排序(执行计划) 1 explain select id, age, phone from tb_user order by age; 查询tb_user表的id，age，phone根据age升序排序，若age相同则按照phone升序排序(执行计划) 1 explain select id, age, phone from tb_user order by age, phone; 由于 age, phone 都没有索引，所以此时再排序时，出现Using filesort， 排序性能较低。\n创建索引 1 create index idx_user_age_phone_aa on tb_user(age, phone); 查询tb_user表的id，age，phone根据age升序排序(执行计划) 1 explain select id, age, phone from tb_user order by age; 查询tb_user表的id，age，phone根据age升序排序，若age相同则按照phone升序排序(执行计划) 1 explain select id, age, phone from tb_user order by age, phone; 建立索引之后，再次进行排序查询，就由原来的Using filesort， 变为了 Using index，性能 就是比较高的了。\n查询tb_user表的id，age，phone根据age，phone进行降序排序。 也出现 Using index， 但是此时Extra中出现了 Backward index scan，这个代表反向扫描索 引，因为在MySQL中我们创建的索引，默认索引的叶子节点是从小到大排序的，而此时我们查询排序 时，是从大到小，所以，在扫描时，就是反向扫描，就会出现 Backward index scan。 在 MySQL8版本中，支持降序索引，我们也可以创建降序索引。\n查询tb_user表的id，age，phone根据phone，age进行升序排序。 1 explain select id, age, phone from tb_user order by phone, age; 排序时,也需要满足最左前缀法则,否则也会出现 filesort。因为在创建索引的时候， age是第一个 字段，phone是第二个字段，所以排序时，也就该按照这个顺序来，否则就会出现 Using filesort。\n查询tb_user表的id，age，phone根据age升序，phone降序排序。 1 explain select id, age, phone from tb_user order by age asc, phone desc; 因为创建索引时，如果未指定顺序，默认都是按照升序排序的，而查询时，一个升序，一个降序，此时 就会出现Using filesort。\n为了解决上述的问题，我们可以创建一个索引，这个联合索引中 age 升序排序，phone 倒序排序。\n创建联合索引(age 升序排序，phone 降序排序) 1 create index idx_user_age_phone_ad on tb_user(age asc, phone desc); 查询tb_user表的id，age，phone根据age升序，phone降序排序。 1 explain select id, age, phone from tb_user order by age asc, phone desc; 升序/降序联合索引结构图示:\n由上述的测试,我们得出order by优化原则:\n根据排序字段建立合适的索引，多字段排序时，也遵循最左前缀法则。 尽量使用覆盖索引。 多字段排序, 一个升序一个降序，此时需要注意联合索引在创建时的规则(ASC/DESC)。 如果不可避免的出现filesort，大数据量排序时，可以适当增大排序缓冲区大小 sort_buffer_size(默认256k)。 group by优化 删除所有的索引 1 2 3 4 drop index idx_user_pro_age_sta on tb_user; drop index idx_email_5 on tb_user; drop index idx_user_age_phone_aa on tb_user; drop index idx_user_age_phone_ad on tb_user; 查询tb_user的专业，数量，根据专业分组排序(执行计划) 1 explain select profession, count(*) from tb_user group by profession; 可以看到是全表扫描，以及使用了临时表，性能较低。\n使用profession , age , status创建联合索引idx_user_pro_age_sta 1 create index idx_user_pro_age_sta on tb_user(profession , age, status); 查询tb_user的专业，数量，根据专业分组排序(执行计划) 1 explain select profession, count(*) from tb_user group by profession; 查询tb_user的专业，数量，根据专业和年龄分组排序(执行计划) 1 explain select profession, count(*) from tb_user group by profession, age; 查询tb_user的专业，数量，根据年龄分组排序(执行计划) 1 explain select age, count(*) from tb_user group by age; 我们发现，如果仅仅根据age分组，就会出现 Using temporary ;而如果是 根据 profession,age两个字段同时分组，则不会出现 Using temporary。原因是因为对于分组操作， 在联合索引中，也是符合最左前缀法则的。\n所以，在分组操作中，我们需要通过以下两点进行优化，以提升性能:\n在分组操作时，可以通过索引来提高效率。 分组操作时，索引的使用也是满足最左前缀法则的 limit优化 在数据量比较大时，如果进行limit分页查询，在查询时，越往后，分页查询效率越低。\n执行limit分页查询耗时对比:\n数据准备(tb_sku表)\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 CREATE TABLE `tb_sku` ( `id` int(11) NOT NULL AUTO_INCREMENT COMMENT \u0026#39;商品id\u0026#39;, `sn` varchar(100) NOT NULL COMMENT \u0026#39;商品条码\u0026#39;, `name` varchar(200) NOT NULL COMMENT \u0026#39;SKU名称\u0026#39;, `price` int(20) NOT NULL COMMENT \u0026#39;价格（分）\u0026#39;, `num` int(10) NOT NULL COMMENT \u0026#39;库存数量\u0026#39;, `alert_num` int(11) DEFAULT NULL COMMENT \u0026#39;库存预警数量\u0026#39;, `image` varchar(200) DEFAULT NULL COMMENT \u0026#39;商品图片\u0026#39;, `images` varchar(2000) DEFAULT NULL COMMENT \u0026#39;商品图片列表\u0026#39;, `weight` int(11) DEFAULT NULL COMMENT \u0026#39;重量（克）\u0026#39;, `create_time` datetime DEFAULT NULL COMMENT \u0026#39;创建时间\u0026#39;, `update_time` datetime DEFAULT NULL COMMENT \u0026#39;更新时间\u0026#39;, `category_name` varchar(200) DEFAULT NULL COMMENT \u0026#39;类目名称\u0026#39;, `brand_name` varchar(100) DEFAULT NULL COMMENT \u0026#39;品牌名称\u0026#39;, `spec` varchar(200) DEFAULT NULL COMMENT \u0026#39;规格\u0026#39;, `sale_num` int(11) DEFAULT \u0026#39;0\u0026#39; COMMENT \u0026#39;销量\u0026#39;, `comment_num` int(11) DEFAULT \u0026#39;0\u0026#39; COMMENT \u0026#39;评论数\u0026#39;, `status` char(1) DEFAULT \u0026#39;1\u0026#39; COMMENT \u0026#39;商品状态 1-正常，2-下架，3-删除\u0026#39;, PRIMARY KEY (`id`) USING BTREE ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT=\u0026#39;商品表\u0026#39;; 上传数据文件到服务器 1 2 3 4 5 scp tb_sku1.sql root@172.16.140.101:/root/sql scp tb_sku2.sql root@172.16.140.101:/root/sql scp tb_sku3.sql root@172.16.140.101:/root/sql scp tb_sku4.sql root@172.16.140.101:/root/sql scp tb_sku5.sql root@172.16.140.101:/root/sql 加载数据到tb_sku表中 1 2 3 4 5 load data local infile \u0026#39;/root/sql/tb_sku1.sql\u0026#39; into table `tb_sku` fields terminated by \u0026#39;,\u0026#39; lines terminated by \u0026#39;\\n\u0026#39;; load data local infile \u0026#39;/root/sql/tb_sku2.sql\u0026#39; into table `tb_sku` fields terminated by \u0026#39;,\u0026#39; lines terminated by \u0026#39;\\n\u0026#39;; load data local infile \u0026#39;/root/sql/tb_sku3.sql\u0026#39; into table `tb_sku` fields terminated by \u0026#39;,\u0026#39; lines terminated by \u0026#39;\\n\u0026#39;; load data local infile \u0026#39;/root/sql/tb_sku4.sql\u0026#39; into table `tb_sku` fields terminated by \u0026#39;,\u0026#39; lines terminated by \u0026#39;\\n\u0026#39;; load data local infile \u0026#39;/root/sql/tb_sku5.sql\u0026#39; into table `tb_sku` fields terminated by \u0026#39;,\u0026#39; lines terminated by \u0026#39;\\n\u0026#39;; 查询tb_sku表第1条开始的10条数据 1 select * from tb_sku limit 0,10; 查询tb_sku表从1000001开始的10条数据 1 select * from tb_sku limit 1000000,10; 查询tb_sku表从第5000001开始的10条数据 1 select * from tb_sku limit 5000000,10; 查询tb_sku表从第9000001开始的10条数据 1 select * from tb_sku limit 9000000,10; 通过测试我们会看到，越往后，分页查询效率越低，这就是分页查询的问题所在。 因为，当在进行分页查询时，如果执行limit 9000000,10，此时需要MySQL排序前9000010记录，仅仅返回9000001-9000010的记录，其他记录丢弃，查询排序的代价非常大。\n优化思路：一般分页查询时，通过创建 覆盖索引 能够比较好地提高性能，可以通过覆盖索引加子查询形式进行优化。\n查询9000001-9000010的id，顺序排序。 1 select id from tb_sku order by id limit 9000000,10; 对tb_sku与查询出来的id进行联表查询，查询相同9000001-9000010的数据信息 1 select s.* from tb_sku s, (select id from tb_sku order by id limit 9000000,10) a where s.id = a.id; 对tb_sku与查询出来的id进行联表查询，查询相同9000001-9000010的数据信息(执行计划) 1 explain select s.* from tb_sku s , (select id from tb_sku order by id limit 9000000,10) a where s.id = a.id; 查询tb_sku表从第9000001开始的10条数据(执行计划) 1 explain select * from tb_sku limit 9000000,10; count优化 概述 1 select count(*) from tb_sku; 在之前的测试中，我们发现，如果数据量很大，在执行count操作时，时非常耗时的。\nMyISAM引擎把一个表的总行数存在了磁盘上，因此执行count(*)的时候会直接返回这个数，效率很高；但是如果时带条件的count，MyISAM也慢。 InnoDB引擎就麻烦了，它执行count(*)的时候，需要数据一行一行地从引擎里面读出来，然后累积计数。 如果说要大幅度提升InnoDB表的count效率，主要的优化思路：自己计数(可以借助于redis这样的数据库进行，但是如果是带条件的count又比较麻烦了)。\nInnoDB的行锁是针对索引加的锁，不是针对记录加的锁，并且该索引不能失效，否则会从行锁升级为表锁。\ncount用法 count()是一个聚合函数，对于返回的结果集，一行行地判断，如果count函数不是NULL，累计值就加1，否则就不加，最后返回累计值。\n用法：count(*)、count(主键)、count(字段)、count(数字)\ncount用法 含义 count(主键) InnoDB引擎会遍历整张表，把每一行的主键id值都取出来，返回给服务层。服务层拿到主键后，直接按行进行累加(主键不可能为null) count(字段) 没有not null约束：InnoDB引擎会遍历整张表把每一行的字段值都取出来，返回给服务层，服务层判断是否为null，不为null，计数累加。\n有not null约束：InnoDB引擎会遍历整张表把每一行的字段都取出来，返回给服务层，直接按行进行累加。 count(数字) InnoDB引擎遍历整张表，但不取值。服务层对于返回的每一行，放一个数字“1”进去，直接按行进行累加。 count(*) InnoDB引擎并不会把全部字段取出来，而是专门做了优化，不取值，服务层直接按行进行累加。 按照效率排序的话，count(字段) \u0026lt; count(主键 id) \u0026lt; count(1) ≈ count(*)，所以尽量使用count(*)。\n演示 count(*) 1 select count(*) from tb_user; count(id) 1 select count(id) from tb_user; count(字段) 1 2 3 # 设置id为24的用户，profession为null update tb_user set profession = null where id = 24; select count(profession) from tb_user; 字段为null的话将不会被计数。\ncount(null) 1 select count(null) from tb_user; count(1)，数字随意输入，比如 -1，0 1 select count(1) from tb_user; update优化 使用数据 1 select * from course; 演示 测试行锁：\n\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;A电脑\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-\n开启事务 1 begin; \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;B电脑\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-\n开启事务 1 begin; \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;A电脑\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-\n修改数据 1 update course set name = \u0026#39;javaEE\u0026#39; where id = 1; 此时MySQL会给该表添加id为1的行锁，将id为1这行数据锁起来。只要事务未提交，该行锁将不会解锁。\n\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;B电脑\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-\n修改数据 1 update course set name = \u0026#39;Kafka\u0026#39; where id = 4; 因为加的是行锁，电脑A给id为1的数据添加了行锁，所以B电脑能够正常执行。\n\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;A电脑\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-\n提交事务 1 commit; \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;B电脑\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-\n提交事务 1 commit; 测试表锁：\n\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;A电脑\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-\n开启事务 1 begin; 修改数据 1 update course set name = \u0026#39;SpringBoot\u0026#39; where name = \u0026#39;PHP\u0026#39;; \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;B电脑\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-\n开启事务 1 begin; 修改数据 1 update course set name = \u0026#39;redis\u0026#39; where id = 4; 此时MySQL在此处卡住，因为A电脑在执行update语句的时候，name字段没有索引，MySQL加的为表锁，而不是行锁\n\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;A电脑\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-\n提交事务 1 commit 提交成功后，B电脑继续向下运行。\n\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;B电脑\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-\n提交事务 1 commit name字段添加索引后再次修改：\n\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;A电脑\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-\n创建索引 1 create index idx_course_name on course(name); 开启事务 1 begin; \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;B电脑\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-\n开启事务 1 begin; \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;A电脑\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-\n修改数据 1 update course set name = \u0026#39;Spring\u0026#39; where name = \u0026#39;SpringBoot\u0026#39;; \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;B电脑\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-\n修改数据 1 update course set name = \u0026#39;Cloud\u0026#39; where id = 4; 提交事务 1 commit; \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;A电脑\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-\n提交事务 1 commit; ","date":"2025-11-17T17:05:01+08:00","permalink":"https://YLine-hub.github.io/p/mysqlmysql%E8%BF%9B%E9%98%B6-sql%E4%BC%98%E5%8C%96/","title":"[MySQL]MySQL进阶-SQL优化"},{"content":"[MySQL]问题 问题一：全局配置文件被忽略 原因 MySQL配置文件\u0026rsquo;/etc/my.cnf\u0026rsquo;的权限设置过于开放(world-writable)，因此被MySQL忽略了。 解决方法 修改MySQL配置文件\u0026rsquo;/etc/my.cnf\u0026rsquo;的权限 1 chmod 644 /etc/my.cnf 问题二：加载本地数据到数据库失败 原因 未启用local_infile系统变量\n查询local_infile变量\n1 show global variables like \u0026#39;local_infile\u0026#39;; 解决方法 修改配置文件/etc/my.cnf，在[client]、[mysql]、[mysqld]部分添加以下行： 1 local_infile=ON 重启mysql 1 systemctl restart mysqld 查询local_file变量 1 show global variables like \u0026#39;local_infile\u0026#39;; 此时，若是爆以下错误，就退出mysql，重新进入 1 ERROR 2068 (HY000): LOAD DATA LOCAL INFILE file request rejected due to restrictions on access. ","date":"2025-11-14T23:39:44+08:00","permalink":"https://YLine-hub.github.io/p/mysql%E9%97%AE%E9%A2%98/","title":"[MySQL]问题"},{"content":"快捷指令 command + option + m + h : 捷键返回桌面\ncommand + option + esc : 强制关闭软件窗口\ncommand + 空格　: Spotlight搜索\n浏览器指令 command + r : 刷新浏览器\ncommand + shift + r : 强制刷新浏览器，并清除缓存\niTerm指令 command + k : 清空页面 control + u : 清除当前行\n","date":"2025-11-12T20:13:00+08:00","permalink":"https://YLine-hub.github.io/p/mac%E5%BF%AB%E6%8D%B7%E6%8C%87%E4%BB%A4/","title":"[Mac]快捷指令"},{"content":"[Mac]zsh通配符问题 报错信息 原因 这个错误是因为 zsh 将方括号 [] 解释为通配符（模式匹配），而不是普通的字符。在 zsh 中，方括号用于字符集匹配。\n解决方法 禁用 zsh 的通配符功能\n打开~/.zshrc文件 1 vim ~/.zshrc 在文件内底部添加如下内容 1 setopt no_nomatch 更新zsh 1 source ~/.zshrc ","date":"2025-11-12T20:07:41+08:00","permalink":"https://YLine-hub.github.io/p/maczsh%E9%80%9A%E9%85%8D%E7%AC%A6%E9%97%AE%E9%A2%98/","title":"[Mac]zsh通配符问题"},{"content":"mac安装hugo(二进制方式) 打开hugo下载页面 hugo: hugo 找到自己要下载的hugo版本 点击下载hugo 下载完成后进入Downloads文件夹 1 cd /Users/line/Downloads 将下载的文件移动到自己的目录下(可选) 1 mv hugo_extended_withdeploy_0.152.1_darwin-universal.tar.gz /Users/line/opt/hugo 进入移动后的目录 1 cd /User/line/opt/hugo 解压hugo压缩包 1 tar -zxvf hugo_extended_withdeploy_0.152.1_darwin-universal.tar.gz 将压缩出来的hugo文件放到bin目录下 1 sudo mv hugo /usr/local/bin 输入管理员密码 检验 1 hugo version 添加验证 弹出hugo无法验证开发者后点击取消 打开设置 点击プライバシーとセキュリティ 找到セキュリティ，点击このまま許可 点击パスワードを使用(或者直接使用指纹) 输入密码后，点击設定を変更 再次验证 1 hugo version 此时如果有弹出弹窗，点击開く即可\n生词 プライバシー：privacy　隐私；私密 セキュリティ：security　安全 許可(きょか) ","date":"2025-11-12T19:58:47+08:00","permalink":"https://YLine-hub.github.io/p/mac%E5%AE%89%E8%A3%85hugo%E4%BA%8C%E8%BF%9B%E5%88%B6/","title":"[Mac]安装hugo(二进制)"},{"content":"安装htpasswd工具 centos\n1 yum -y install httpd-tools ubuntu\n1 apt-get -y install apache2-utils 生成密码文件 1 2 3 4 htpasswd -c /usr/local/nginx/passwd admin New password: Re-type new password: Adding password for user admin 查看密码文件 1 cat /usr/local/nginx/passwd 修改nginx配置文件 1 2 3 4 5 6 7 8 9 server { listen 80; server_name localhost; ....... #设置密码 auth_basic \u0026#34;请输入账号密码\u0026#34;; #这里是验证时的提示信息 auth_basic_user_file /usr/local/nginx/passwd; } 重启nginx 修改用户密码 删除用户admin的密码 1 htpasswd -D /usr/local/nginx/passwd admin 添加用户admin密码为admin123456 1 htpasswd -b /usr/local/nginx/passwd admin admin123456 ","date":"2025-11-10T20:38:25+08:00","permalink":"https://YLine-hub.github.io/p/nginx%E4%BD%BF%E7%94%A8nginx%E8%AE%BE%E7%BD%AE%E7%99%BB%E9%99%86%E8%AE%BF%E9%97%AE/","title":"[nginx]使用nginx设置登陆访问"},{"content":"git基础 概述 开发中的实际场景 场景一：备份 小明负责的模块就要完成了，就在即将Release之前的一瞬间，电脑突然蓝屏，硬盘光荣牺牲！几个月来的努力付之东流\n场景二：代码还原 这个项目中需要一个很复杂的功能，老王摸索了一个星期终于有眉目了，可是这被改得面目全非的 代码已经回不到从前了。什么地方能买到哆啦A梦的时光机啊？\n场景三：协同开发 小刚和小强先后从文件服务器上下载了同一个文件：Analysis.java。小刚在Analysis.java 文件中的第30行声明了一个方法，叫count()，先保存到了文件服务器上；小强在Analysis.java文件中的 第50行声明了一个方法，叫sum()，也随后保存到了文件服务器上，于是，count()方法就只存在于小刚的记 忆中了\n场景四：追溯问题代码的编写人和编写时间 老王是另一位项目经理，每次因为项目进度挨骂之后，他都不知道该扣哪个程序员的工资！就拿这次来说吧，有个Bug调试了30多个小时才知道是因为相关属性没有在应用初始化时赋值！可是二胖、王东、刘流和正经牛都不承认是自己干的!\n版本控制器的方式 a、集中式版本控制工具 集中式版本控制工具，版本库是集中存放在中央服务器的，team里每个人work时从中央服务器下载代码，是必须联网才能工作，局域网或互联网。个人修改后然后提交到中央版本库。\n举例：SVN和CVS b、分布式版本控制工具 分布式版本控制系统没有“中央服务器”，每个人的电脑上都是一个完整的版本库，这样工作的时候，无需要联网了，因为版本库就在你自己的电脑上。多人协作只需要各自的修改推送给对方，就能互相看到对方的修改了。\n举例：Git SVN(过时) Git 介绍 Git是分布式的,Git不需要有中心服务器，我们每台电脑拥有的东西都是一样的。我们使用Git并且有个中心服务器，仅仅是为了方便交换大家的修改，但是这个服务器的地位和我们每个人的PC是一样的。我们可以把它当做一个开发者的pc就可以就是为了大家代码容易交流不关机用的。没有它大家一样可以工作，只不过“交换”修改不方便而已。\ngit是一个开源的分布式版本控制系统，可以有效、高速地处理从很小到非常大的项目版本管理。Git是Linus Torvalds 为了帮助管理 Linux 内核开发而开发的一个开放源码的版本控制软件。\n特点 速度快 简单的设计 对非线性开发模式的强力支持(允许成千上万个并行开发的分支) 完全分布式 有能力高效管理类似Linux内核一样的超大规模项目(速度和数据量) Git工作流程图 命令\nclone（克隆）: 从远程仓库中克隆代码到本地仓库 checkout （检出）:从本地仓库中检出一个仓库分支然后进行修订 add（添加）: 在提交前先将代码提交到暂存区 commit（提交）: 提交到本地仓库。本地仓库中保存修改的各个历史版本 fetch (抓取) ： 从远程库，抓取到本地仓库，不进行任何的合并动作，一般操作比较少。 pull (拉取) ： 从远程库拉到本地库，自动进行合并(merge)，然后放到到工作区，相当于 fetch+merge push（推送） : 修改完成后，需要和团队成员共享代码时，将代码推送到远程仓库 Git安装与常用命令 Git环境配置 windows 基本配置 打开Git Bash(内置linux环境)\n设置用户信息(自己随意设置)\n1 2 git config --global user.name \u0026#34;yline\u0026#34; git config --global user.email \u0026#34;yline@yline.cn\u0026#34; 查看配置信息 1 2 git config --global user.name git config --global user.email 查看所有配置信息 1 git config --global -l 为常用指令配置别名(可选) 有些常用的指令参数非常多，每次都要输入好多参数，我们可以使用别名。\n打开用户目录，创建.bashrc文件 windwos 用户目录：\n部分windows系统不允许用户创建点开头的文件，可以打开Git Bash，执行touch ~/.bashrc\n1 touch ~/.bashrc 在.bashrc文件中输入以下内容 1 2 3 4 #用于输出git提交日志 alias git-log=\u0026#39;git log --pretty=oneline --all --graph --abbrev-commit\u0026#39; #用于输出当前目录所有文件及基本信息 alias ll=\u0026#39;ls -al\u0026#39; 打开Git Bash，执行source ~/.bashrc 解决Git Bash中文乱码问题 打开Git Bash执行下面命令 1 git config --global core.quotepath false ${git_home}/etc/bash.bashrc文件最后加入下面两行 1 2 export LANG=\u0026#34;zh_CN.UTF-8\u0026#34; export LC_ALL=\u0026#34;zh_CN.UTF-8\u0026#34; 获取本地仓库 要使用Git对我们的代码进行版本控制，首先需要获得本地仓库\n在电脑的任意位置创建一个空目录(例如test)作为我们的本地Git仓库 进入这个目录中，点击右键打开Git Bash窗口 执行命令git init 1 git init 如果创建成功后可在文件夹下看到隐藏的.git目录 基础操作指令 Git工作目录下对于文件的修改(增加、删除、更新)会存在几个状态，这些修改的状态会随我们执行Git的命令而发生变化。\n本章节主要讲解如何使用命令来控制这些状态之间的转换：\n工作区 -\u0026gt; 暂存区 1 git add 暂存区 -\u0026gt; 本地仓库 1 git commit *查看修改的状态(status) 作用：查看的修改的状态(暂存区、工作区) 命令形式： 1 git status *添加工作区到暂存区(add) 作用：添加工作区一个或多个文件的修改到暂存区 命令形式： 1 git add 单个文件名|通配符 将所有修改添加到暂存区 1 git add . *提交暂存区到本地仓库(commit) 作用：提交暂存区内容到本地仓库的当前分支 命令形式： 1 git commit -m \u0026#39;注释内容\u0026#39; *查看提交日志(log) 在“为常用指令配置别名”中配置的别名git-log就包含了这些参数，所以后续可以直接使用指令git-log\n作用：查看提交记录 命令形式： 1 git log [option] options --all 显示所有分支 --pretty=oneline 将提交信息显示为一行 --abbrev-commit 使得输出的commitId更简短 --graph 以图的形式显示 版本回退 作用：版本切换 命令形式： 1 git reset --hard commitID commitID 可以使用git-log或git log指令查看 如何查看已经删除的记录 git reflog 这个指令可以看到已经删除的提交记录 添加文件至忽略列表 一般我们总会有些文件无需纳入Git 的管理，也不希望它们总出现在未跟踪文件列表。 通常都是些自动生成的文件，比如日志文件，或者编译过程中创建的临时文件等。 在这种情况下，我们可以在工作目录中创建一个名为 .gitignore 的文件（文件名称固定），列出要忽略的文件模式。下面是一个示例：\n1 2 3 4 5 6 7 8 9 10 11 12 # no .a files *.a # but do track lib.a, even though you\u0026#39;re ignoring .a files above !lib.a # only ignore the TODO file in the current directory, not subdir/TODO /TODO # ignore all files in the build/ directory build/ # ignore doc/notes.txt, but not doc/server/arch.txt doc/*.txt # ignore all .pdf files in the doc/ directory doc/**/*.pdf 练习 创建一个文件 1 touch file01.txt 查看文件状态 1 git status 可以看到该文件处于Untracked(未跟踪)状态\n添加file01.txt 到暂存区 1 2 3 4 5 6 # 添加file01.txt文件到暂存区 git add file01.txt # 添加所有文件到暂存区(常用) git add . # 查看文件状态 git status 提交文件 1 2 # -m 表示注释 git commit -m \u0026#34;add file01\u0026#34; 查看提交日志 1 git log 编辑文件(修改file01.txt) 1 vi file01.txt 查看状态 1 git status 添加文件到暂存区 1 git add . 提交文件 1 git commit -m \u0026#34;update file01.txt\u0026#34; 查看提交日志 1 git log 查看提交日志，并且展示为一行 1 git log --pretty=oneline 展示的数据此时变成了两行\n查看提交日志，展示为一行，并且简化内容 1 git log --pretty=oneline --abbrev-commit 查看提交的日志，简化ID展示为一行，并且以图的形式展示提交的分支 1 git log --pretty=oneline --abbrev-commit --graph 查看提交的日志，简化ID展示为一行，并且以图的形式展示提交的分支(mac) 1 git log --pretty=oneline --abbrev-commit --graph --decorate 回退版本\n查看修改前的版本ID 1 2 git-log # ID为2d9eaee 回退到id为2d9eaee的版本 1 git reset --hard 2d9eaee 此时可以看到修改文件的版本没有了，只剩提交文件的版本 原先文件中输入的update count=1也没了\n重新回到修改文件的版本 1 git reset --hard 14da90b 查看git操作记录\n1 git reflog 添加.a结尾文件至git忽略列表 创建file02.a 1 touch file02.a 查看提交状态 1 git status 创建.gitignore文件 1 touch .gitignore 编辑并添加.a结尾的文件至git忽略列表 1 vi .gitignore .gitignore 1 *.a 查看git状态 1 git status 其中结尾为.a的文件被忽略 分支 几乎所有的版本控制系统都以某种形式支持分支。使用分支意味着你可以把你的工作从开发主线上分离开来进行重大的Bug修改、开发新的功能，以面影响开发主线\n查看本地分支 命令 1 git branch 创建本地分支 命令 1 git branch 分支名 *切换分支(checkout) 命令 1 git checkout 分支名 我们还可以直接切换到一个不存在的分支(创建并切换)\n命令 1 git checkout -b 分支名 *合并分支(merge) 一个分支上的提交可以合并到另一个分支\n命令 1 git merge 分支名称 删除分支 不能删除当前分支，只能删除其他分支\n命令 1 2 3 4 # 删除分支时，需要做各种检查 git branch -d 分支名 # 不做任何检查，强制删除 git branch -D 分支名 解决冲突 当两个分支上对文件的修改可能会存在冲突，例如同时修改了同一个文件的同一行，这时就需要手动解 决冲突，解决冲突步骤如下：\n处理文件中冲突的地方 将解决完冲突的文件加入暂存区(add) 提交到仓库(commit) 冲突部分的内容处理如下所示： 开发中分支使用原则与流程 几乎所有的版本控制系统都以某种形式支持分支。 使用分支意味着你可以把你的工作从开发主线上分离开来进行重大的Bug修改、开发新的功能，以免影响开发主线。\n在开发中，一般有如下分支使用原则与流程：\nmaster （生产） 分支 线上分支，主分支，中小规模项目作为线上运行的应用对应的分支； develop（开发）分支 是从master创建的分支，一般作为开发部门的主要开发分支，如果没有其他并行开发不同期上线 要求，都可以在此版本进行开发，阶段开发完成后，需要是合并到master分支,准备上线。 feature/xxxx分支 从develop创建的分支，一般是同期并行开发，但不同期上线时创建的分支，分支上的研发任务完 成后合并到develop分支。 hotfix/xxxx分支， 从master派生的分支，一般作为线上bug修复使用，修复完成后需要合并到master、test、 develop分支。 还有一些其他分支，在此不再详述，例如test分支（用于代码测试）、pre分支（预上线分支）等 等。 练习：分支操作 查看分支 1 git branch 创建分支dev01 1 git branch dev01 查看当前分支详情 1 git-log 在当前分支提交.gitignore(未提交) 1 2 3 4 git status git add . git commit -m \u0026#34;add ignore file\u0026#34; git-log 此时可以看到当前的分支提交了.gitignore文件，而dev01分支此时处于提交file01时\n切换到dev01分支 1 git checkout dev01 可以看到，HEAD指向了dev01，表示此时处于dev01分支，而原先提交的.gitignore文件也消失了\n切换回master分支 1 git checkout master 创建并切换到dev02分支 1 git checkout -b dev02 在dev01分支上创建file02.txt文件并提交 1 2 3 4 5 git checkout dev01 touch file02.txt git add . git commit -m \u0026#39;add file02.txt\u0026#39; git-log 查看master分支 1 2 git checkout master git-log 此时dev01分支上有file02.txt文件，但是没有.gitignore文件。 master分支上有.gitignore，但是没有file02文件。\n将dev01分支上的文件合并到master(需要在master下) 1 git merge dev01 弹出一个提示，需要我们对这个合并做出解释，可以不说明。用:wq保存退出。\n查看日志 1 git-log 删除dev02分支 1 git branch -d dev02 删除dev01分支 1 git branch -d dev01 解决冲突 创建并切换到dev分支 1 git checkout -b dev 修改file01.txt 1 vi file01.txt file01.txt 1 update count=2 提交，并查看 1 2 3 git add . git commit -m \u0026#39;update file01 count=2\u0026#39; git-log 切换到master分支，并改成3 1 2 git checkout master vi file01.txt file01.txt 1 update count=3 提交，并查看 1 2 3 git add . git commit -m \u0026#39;update file01 count=3\u0026#39; git-log 在master上合并dev 1 git merge dev 表示自动合并file01.txt时，发现在file01.txt文件内存在冲突，自动合并失败。 要求修改冲突并且提交结果\n打开file01.txt文件 1 vi file01.txt file01.txt 其中表示HEAD为update count=3，dev为update count=2\n最终修改file01.txt\n1 update count=5 提交 1 2 git add . git commit 由于此次我没有写注释，git自动给我生成了\n表示合并了分支dev\n查看日志 1 git-log 此时最终的master里的file01.txt 删除dev分支 1 git branch -d dev 创建dev02分支 1 git checkout -b dev02 创建文件file03.txt并提交 1 2 3 4 5 touch file03.txt git status git add . git commit -m \u0026#39;abced\u0026#39; git-log 切换到master分支，并删除dev分支 1 2 git checkout master git branch -d dev02 显示错误：分支dev02没完全合并。他认为我们可能是误操作，没有将dev02合并到master。\n强制删除 1 2 git branch -D dev02 git-log 生词 conflict / ˈkɑːnflɪkt / n、冲突，分歧；v、冲突 Git远程仓库 常用的托管服务[远程仓库] github: https://github.com gitee: https://gitee.com gitlab: https://about.gitlab.com 注册码云(gitee) 创建远程仓库 点击右上角的+号，然后点击新建仓库 填写仓库信息，并创建 创建成功 配置SSH公钥 生成SSH公钥 1 ssh-keygen -t rsa 然后一直回车即可 如果公钥已经存在，则自动覆盖\n查看公钥 1 cat ~/.ssh/id_rsa.pub 复制红框内的内容\n点击头上-\u0026gt;选择设置 点击安全设置下的SSH公钥 填入标题和公钥，然后点击确定 填入账号的密码，然后点击验证 验证公钥 1 ssh -T git@gitee.com 操作远程仓库 复制仓库地址 1 git@gitee.com:yline-hub/git_test.git 添加远程仓库 命令 1 git remote add \u0026lt;远端名称\u0026gt; \u0026lt;仓库路径\u0026gt; 注意 \u0026lt;远端名称\u0026gt;，默认是origin，取决于远端服务器设置 \u0026lt;仓库路径\u0026gt;，从远端服务器获取此URL 查看远程仓库 命令 1 git remote 查看远程分支，并显示url 1 git remote -v 推送到远程仓库 命令 1 git push [-f] [--set-upstream] [远端名称 [本地分支名][:远端分支名] ] 注意 如果远程分支名和本地分支名称相同，则可以只写本地分支 1 2 3 4 # 原本 git push origin master:master # 省略 git push origin master -f(force) 表示强制覆盖 --set-upstream 推送到远端的同时并且建立起和远端分支的关联关系。 1 git push --set-upstream origin master 如果当前分支已经和远端分支关联，则可以省略分支名和远端名。 1 2 # 将master分支推送到已关联的远端分支。 git push 本地分支与远程分支的关联关系 查看关联关系 1 git branch -vv 从远程仓库克隆 如果已经有一个远端仓库，我们可以直接clone到本地。 1 git clone \u0026lt;仓库路径\u0026gt; [本地仓库目录] 注意 本地目录可以省略，会自动生成一个目录 从远程仓库中抓取和拉取 远程分支和本地的分支一样，我们可以进行merge操作，只是需要先把远端仓库里的更新都下载到本地，再进行操作。\n抓取命令\n1 git fetch [remote name] [branch name] 注意\n抓取指令就是将仓库里的更新都抓取到本地，不会进行合并 如果不指定远端名称和分支名，则抓取所有分支。 拉取命令\n1 git pull [remote name] [branch name] 注意 拉取指令就是将远端仓库的修改拉到本地并自动进行合并，等同于fetch+merge 如果不指定远端名称和分支名，则抓取所有并更新当前分支。 解决合并冲突 在一段时间，A、B用户修改了同一个文件，且修改了同一行位置的代码，此时会发生合并冲突。 A用户在本地修改代码后优先推送到远程仓库，此时B用户在本地修订代码，提交到本地仓库后，也需要推送到远程仓库，此时B用户晚于A用户，故需要先拉取远程仓库的提交，经过合并后才能推送到远端分支,如下图所示\n在B用户拉取代码时，因为A、B用户同一段时间修改了同一个文件的相同位置代码，故会发生合并冲突。\n练习：远程仓库操作 添加远程仓库 1 git remote add origin git@gitee.com:yline-hub/git_test.git 查看远程仓库 1 git remote 查看远程仓库及其url 1 git remote -v 将当前的分支推送到origin的远程仓库 1 git push origin master 查看远程仓库 省略分支名和远端名推送 1 git push 表示当前分支master没有上游(关联)的分支\n查看本地分支和远程分支的关联关系 1 git branch -vv 将本地master推送到远程仓库的master，并绑定关系 1 git push --set-upstream origin master:master 绑定成功\n查看本地分支和远程分支的关联关系 1 git branch -vv 可以看到现在多了一个[origin/master]，表示本地的master与远程的[origin/master]关联\n提交 1 git push 现在不会再报错了\n克隆仓库\n新建空目录(ylineClone) 在当前目录下右键打开Git Bash 使用刚刚创建的远程仓库链接克隆一个仓库下来(默认文件名为仓库名) 1 git clone git@gitee.com:yline-hub/git_test.git 进入克隆仓库 1 cd git_test 克隆仓库 1 git-log 本地仓库 1 git-log 克隆仓库：fetch抓取文件 原仓库：上传文件\n创建file04.txt 1 touch file04.txt 添加到暂存区 1 git add . 提交到仓库 1 git commit -m \u0026#39;add file03.txt\u0026#39; 查看日志 1 git-log 推送到远程仓库 1 git push 查看日志 1 git-log 克隆仓库：拉取远程仓库\n拉取远程仓库 1 git fetch 查看日志 1 git-log 合并到本地 1 git merge origin/master 查看日志 1 git-log 克隆仓库：pull拉取文件 原仓库：上传文件\n1 2 3 4 touch file05.txt git add . git commit -m \u0026#39;file05.txt\u0026#39; git push 克隆仓库：拉取文件\n1 2 git pull git-log 解决冲突 原仓库：查看日志 1 git-log 克隆仓库：查看日志 1 git-log 原仓库：修改并提交文件\n修改file01.txt 1 vi file01.txt file01.txt 1 update count=6 提交 1 2 git add . git commit -m \u0026#39;update file01 count=6\u0026#39; 查看日志 1 git-log 推送到远程仓库 1 git push 查看日志 1 git-log 克隆仓库：修改并提交文件\n修改file01.txt 1 vi file01.txt file01.txt 1 update count=7 提交 1 2 3 git add . git commit -m \u0026#39;update file01 count=7\u0026#39; git-log 抓取已经被修改的仓库 1 git fetch 查看日志 1 git-log 此时可以看出，由于克隆仓库和远程仓库都在6e0da05版本做出了不同的修改，导致之后的版本出现了冲突\n尝试直接拉取文件 1 git pull 显示自动合并时，在文件file01.txt产生冲突，要求我们修改冲突并提交结果\n查看文件file01.txt 1 cat file01.txt 可以看到，本地仓库的内容为update count=7，远程仓库ab56cf7版本的内容为update count=6\n最终结果file01.txt 1 update count=7 提交 1 2 git add . git commit 查看日志 1 git-log 推送到远程仓库 1 git push 查看日志 1 git-log 原仓库：拉取新版\n拉取文件 1 git pull 查看日志 1 git-log 生词 remote / rɪˈmoʊt / adj、偏远的；远程的 origin / ˈɔːrɪdʒɪn / n、起源；出身；神经(或血管)起端 force / fɔːrs / n、暴力；力量；v、强迫；用力推；使发生； upstream / ˌʌpˈstriːm / adv、向(在)上游地；逆流地；adj、向(在)上游的；逆流的 在IDEA中使用Git 在IDEA中配置Git File -\u0026gt; Settings\u0026hellip; Version Control -\u0026gt; Git -\u0026gt; Path to Git executable 如果电脑里已经安装了Git，IDEA会默认帮你配置好\n在IDEA中操作Git 场景：本地已经有一个项目，但是并不是Git项目，我们需要将这个放到码云的仓库里，和其他开发人员继续一起协作开发。\n创建项目远程仓库 点击右上角的+号，然后点击新建仓库 填写信息，并创建 创建成功，复制SSH的提交链接 初始化本地仓库 点击VCS，选择Create Git Repository\u0026hellip; 选择当前项目的目录 提交到本地仓库 点击Commit，然后全选文件(已经有.gitignore排除不需要的文件)，输入注释，然后点击提交 然后idea右下角显示文件已经被提交 查看提交记录 点击左下角的git按钮 可以查询到提交的所有内容 设置远程仓库 点击Git，选择push 点击Define remote 输入信息，然后点击OK 推送到远程仓库 设置完成后，点击push即可推送 右下角显示已经被推送 查看远程仓库 修改内容并推送 修改文件内容后，commit会自动出现修改的文件 点击Commit and push 可以直接将文件提交，并推送到远程仓库\n弹出推送窗口，点击push 可以看到提交的日志信息 点击右边的文件，可以查看修改的内容 克隆远程仓库到本地 复制仓库链接\n点击克隆/下载 选择SSH，复制链接 点击Git-\u0026gt;Clone 输入SSH链接，然后点击Clone 打开新窗口 信任项目 克隆项目 解决冲突 原项目：在用户控制类编写注销用户功能 克隆项目：在用户控制类编写查询用户功能 原项目：推送到远程仓库 原项目：然后点击Commit Anyway and push 原项目：点击push 克隆项目：提交查询功能 克隆项目：提交成功 克隆项目：点击Git-\u0026gt;Update Project 克隆项目：点击OK 克隆项目：发生冲突，可以点击Close 克隆项目：查看冲突 克隆项目：将其都留下，直接修改文件内容即可 克隆项目：添加文件到暂存区 克隆项目：推送到远程仓库 原项目：拉取最新仓库 查看分支 创建分支 点击+号 输入分支名，点击创建 此时本地仓库，创建并切换到分支dev 快速创建分支\n在git日志里右键想要创建分支的版本，点击New Branch 输入分支名，并点击创建 HEAD表示为当前的git版本\n切换分支及其他分支相关操作 附：铁令 切换分支前要先提交本地的修改 代码及时提交，提交过了就不会丢 附：IDEA集成GitBash作为Terminal git常用指令 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # 基本操作类 git init 初始化仓库 git-log 查看日志(重要) git add \u0026lt;文件名\u0026gt; 添加到暂存区 git commit -m \u0026#39;注释\u0026#39; 提交到仓库 git merge \u0026lt;分支名\u0026gt; 合并指定分支到当前活跃分支 # 分支切换类 git checkout \u0026lt;分支名\u0026gt; 切换到某个分支 git checkout -b \u0026lt;分支名\u0026gt; 创建并切换到某个分支(分支原来不存在) # 远程操作类 git clone \u0026lt;远程地址\u0026gt; [本地文件夹] clone远程仓库到本地 git pull 拉取远程仓库的修改并合并 git push [--set-upstream] origin \u0026lt;分支名\u0026gt; 推送本地修改到远程分支 --set-upstream 表示和远程分支绑定关联关系，只有第一次推送时才需要此参数 ","date":"2025-11-07T23:24:38+08:00","permalink":"https://YLine-hub.github.io/p/gitgit%E5%9F%BA%E7%A1%80/","title":"[Git]Git基础"},{"content":"问题 问题一：pip安装时连接失败 报错详情 1 There was a problem confirming the ssl certificate: HTTPSConnectionPool(host=\u0026#39;pypi.org\u0026#39;, port=443) 原因 使用了代理 解决方法 关闭代理 问题二：pip安装速度慢 原因 网速问题 解决方法 使用国内镜像源 1 2 3 4 清华大学：https://pypi.tuna.tsinghua.edu.cn/simple 阿里云：https://mirrors.aliyun.com/pypi/simple/ 豆瓣(douban)：https://pypi.douban.com/simple/ 中国科学技术大学：https://pypi.mirrors.ustc.edu.cn/simple/ 以清华大学镜像为例 1 2 3 4 5 # 临时使用 pip install PySpice -i https://pypi.tuna.tsinghua.edu.cn/simple # 永久配置 pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple ","date":"2025-11-07T08:35:01+08:00","permalink":"https://YLine-hub.github.io/p/pip%E9%97%AE%E9%A2%98/","title":"[pip]问题"},{"content":"Git常见问题 问题一：无法连接github远程仓库 报错详情 1 fatal: unable to access \u0026#39;https://github.com/xxx/xxx.git/\u0026#39;: Recv failure: Connection was reset 1 fatal: unable to access \u0026#39;https://github.com/xxx/xxx.git/\u0026#39;: Failed to connect to github.com port 443 after 21084 ms: Could not connect to server 原因 没有给git设置代理\n查询全局配置\n1 git config --global -l 发现其中没有代理配置 解决方法 设置git代理 1 2 git config --global http.proxy http://127.0.0.1:7890 git config --global https.proxy http://127.0.0.1:7890 再次查看全局配置 1 git config --global -l 此时可以看到已经配置了代理\n再次抓取代码 1 git fetch --all ","date":"2025-11-07T07:54:40+08:00","permalink":"https://YLine-hub.github.io/p/git%E9%97%AE%E9%A2%98/","title":"[Git]问题"},{"content":"git实现跨设备代码同步 A电脑：上传代码 将代码添加到暂存区 1 git add . 提交代码 1 git commit -m \u0026#34;update\u0026#34; 推送代码到远程仓库 1 git push B电脑：克隆代码 1 git clone https://XXXX.git B电脑：上传代码 将代码添加到暂存区 1 git add . 提交代码 1 git commit -m \u0026#34;update\u0026#34; 在本机第一次上传，配置用户名和邮箱 1 2 git config --global user.name \u0026#34;yourname\u0026#34; git config --global user.email \u0026#34;youremail\u0026#34; 推送代码 1 git push 查看全局配置 1 git config --global -l A电脑：拉取最新代码 更新远程仓库代码为最新的 1 git fetch --all 让本地代码与origin/main完全相同 1 git reset --hard origin/main 拉取远程代码 1 git pull origin main 将暂存区代码更新到本地工作区 1 git merge main ","date":"2025-11-06T22:13:07+08:00","permalink":"https://YLine-hub.github.io/p/gitgit%E5%AE%9E%E7%8E%B0%E8%B7%A8%E8%AE%BE%E5%A4%87%E4%BB%A3%E7%A0%81%E5%90%8C%E6%AD%A5/","title":"[Git]git实现跨设备代码同步"},{"content":"MySQL进阶-索引 索引概述 介绍 索引(index)是帮助MySQL高效获取数据的数据结构(有序)。在数据之外，数据库系统还维护着满足特定查找算法的数据结构，这些数据结构以某种方式引用(指向)数据，这样就可以在这些数据结构上实现高级查找算法，这种数据结构就是索引。 演示 备注：上述二叉树索引结构的只是一个示意图，并不是真是的索引结构。\n优缺点 优势 劣势 提高数据检索的效率，降低数据库的IO成本 索引列也是要占空间的。 通过索引列对数据进行排序，降低数据排序的成本，降低CPU的消耗。 索引大大提高了查询效率，同时却也降低更新表的速度，如对表进行INSERT、UPDATE、DELETE时，效率降低。 索引结构 类型 MySQL的索引是在存储引擎层实现的，不同的存储引擎有不同的结构，主要包含以下几种： 索引结构 描述 B+Tree索引 最常见的索引类型，大部分引擎都支持B+树索引 Hash索引 底层数据结构是用哈希表实现的，只有精确匹配索引列的查询才有效，不支持范围查询 R-tree(空间索引) 空间索引是MyISAM引擎的一个特殊索引类型，主要用于地理空间数据类型，通常使用较少 Full-text(全文索引) 是一种通过建立倒排索引，快速匹配文档的方式。类似与Lucene,Solr,ES 支持情况 索引 InnoDB MyISAM Memory B+tree索引 支持 支持 支持 Hash索引 不支持 不支持 支持 R-tree索引 不支持 支持 不支持 Full-text索引 5.6版本之后支持 支持 不支持 我们平常所说的索引，如果没有特别指明，都是指B+树结构\n二叉树和红黑树 二叉树 如果主键是顺序插入的，则会形成一个单向链表，结构如下：\n二叉树缺点：1、(不平衡问题)顺序插入时，会形成一个链表，查询性能大大降低。而且每一层只有两个节点，在大数据情况下，层级较深，检索速度慢。\n解决二叉树的平衡问题（红黑树） 红黑树：大数据量情况下，层级较深，检索速度慢。\nB-Tree(多路平衡查找树) 介绍 以一颗最大度数(max-degree)为5(5阶)的b-tree为例(每个节点最多存储4个key，5个指针)： 知识小贴士：树的度数指的是一个节点的子节点个数。\n演示 数据结构可视化网站: Data Structure Visualizations 选择B Trees 使用说明 插入数据 1 插入 100 65 169 368 900 556 780 35 215 1200 234 888 158 90 1000 88 120 268 250 数据为例。 特点： 5阶的B树，每一个节点最多存储4个key，对应5个指针。 一旦节点存储的key数量到达5，就会裂变，中间元素向上分裂。 在B树中，非叶子节点和叶子节点都会存放数据。 B+Tree 以一颗最大度数(max-degree)为3(3阶)的b+tree为例： 我们可以看到两部分：\n绿色框框起来的部分，是索引部分，仅仅起到索引数据的作用，不存储数据。 红色框框起来的部分，是数据存储部分，在其叶子节点中要存储具体的数据。 演示 使用数据结构可视化网站进行演示，选择B+ Trees 插入一组数据进行观察(最大度数为5) 1 100 65 169 368 900 556 780 35 215 1200 234 888 158 90 1000 88 120 268 250 最终可以看到，B+Tree与B-Tree相比，主要有以下三点区别 所有的数据都会出现在叶子节点。 叶子节点形成一个单向链表。 非叶子节点仅仅起到索引数据作用，具体的数据都是在叶子节点存放的 MySQL的B+Tree MySQL索引数据结构对经典的B+Tree进行了优化。在原B+Tree的基础上，增加一个指向相邻叶子节点的链表指针，就形成了带有顺序指针的B+Tree，提高区间访问的性能，利于排序。\nHash MySQL中除了支持B+Tree索引，还支持一种索引类型\u0026ndash;Hash索引 结构 哈希索引就是采用一定的hash算法，将键值换算成新的hash值，映射到对应的槽位上，然后存储在 hash表中。\n如果两个(或多个)键值，映射到一个相同的槽位上，他们就产生了hash冲突（也称为hash碰撞），可以通过链表来解决。\n特点 Hash索引只能用于对等比较(=，in)，不支持范围查询（between，\u0026gt;，\u0026lt; ，\u0026hellip;） 无法利用索引完成排序操作 查询效率高，通常(不存在hash冲突的情况)只需要一次检索就可以了，效率通常要高于B+tree索引 3.存储引擎支持\n在MySQL中，支持hash索引的是Memory存储引擎。 而InnoDB中具有自适应hash功能，hash索引是InnoDB存储引擎根据B+Tree索引在指定条件下自动构建的。\n思考题 为什么InnoDB存储引擎选择使用B+Tree索引结构\n相对于二叉树，层级更少，搜索效率高； 对于B-tree，无论是叶子节点还是非叶子节点，都会保存数据，这样导致一页中存储的键值减少，指针跟着减少，要同样保存大量数据，只能增加树的高度，导致性能降低； 相对Hash索引，B+tree支持范围匹配及排序操作； 索引分类 索引分类 在MySQL数据库，将会索引的具体类型主要分为以下几类：主键索引、唯一索引、常规索引、全文索引。\n分类 含义 特点 关键字 主键索引 针对于表中主键创建的索引 默认自动创建，只能有一个 PRIMARY 唯一索引 避免同一个表中某数据列中的值重复 可以有多个 UNIQUE 常规索引 快速定位特定数据 可以有多个 全文索引 全文索引查找的时文本中的关键词，而不是比较索引中的值 可以有多个 FULLTEXT 聚集索引\u0026amp;二级索引 而在InnoDB存储引擎中，根据索引的存储形式，又可以分为以下两种： 分类 含义 特点 聚集索引(Clustered Index) 将数据存储与索引放到了一块，索引结构的叶子节点保存了行数据 必须有，而且只有一个 二级索引(Secondary Index) 将数据与索引分开存储，索引结构的叶子节点关联的是对应的主键 可以存在多个 聚集索引选取规则：\n如果存在主键，主键索引就是聚集索引。如果不存在主键，将使用第一个唯一(UNIQUE)索引作为聚集索引 如果表没有主键，或没有合适的唯一索引，则InnoDB会自动生成一个rowid作为隐藏的聚集索引 聚集索引和二级索引的具体结构如下：\n聚集索引的叶子节点下挂的是这一行的数据。 二级索引的叶子节点下挂的是该字段值对应的主键值。 执行SQL语句的查找过程 如下SQL语句 1 select * from user where name = \u0026#39;Arm\u0026#39;; 具体过程如下：\n由于是根据name字段进行查询，所以先根据name=\u0026lsquo;Arm\u0026rsquo;到name字段的二级索引中进行匹配查找。但是在二级索引中只能查找到 Arm 对应的主键值 10。 由于查询返回的数据是*，所以此时，还需要根据主键值10，到聚集索引中查找10对应的记录，最终找到10对应的行row。 最终拿到这一行的数据，直接返回即可。 回表查询：这种先到二级索引中查找数据，找到主键值，然后再到聚集索引中根据主键值，获取数据的方式，就称之为回表查询。\n思考题 以下两条SQL语句，哪个执行效率高？为什么？ select * from user where id = 10; select * from user where name = \u0026lsquo;Arm\u0026rsquo;; 备注：id为主键，name字段创建的有索引。\n解答：1语句的执行性能要高于2语句。\n因为1语句直接走聚集索引，直接返回数据。而2语句需要先查询name字段的二级索引，然后再查询聚集索引，也就是需要进行回表查询。\nInnoDB主键索引的B+tree高度为多高呢？ 假设：\n一行数据大小为1k，一页中可以存储16行这样的数据，InnoDB的指针占用6个字节的空间，主键即使为bigint，占用字节数位8。\n高度为2：\nn * 8 + (n + 1) * 6 = 16 * 1024，算出n约为1170\n1171 * 16 = 18736\n也就是说，如果树的高度为2，则可以存储18000多条记录。\n高度为3：\n1171 * 1171 * 16 = 21939856\n也就是说，如果树的高度为3，则可以存储2200w左右的数据。\n解析： A、高度为2的情况： B、高度为3的情况： 索引语法 基础语法 创建索引 命令 1 CREATE [UNIQUE|FULLTEXT] INDEX index_name ON table_name (index_col_name,...); 查看索引 命令 1 SHOW INDEX FROM table_name; 查看tb_user表的索引(列表示) 1 show index from tb_user; 查看tb_user表的索引(行表示) 1 show index from tb_user\\G; 删除索引 命令 1 DROP INDEX index_name ON table_name; 删除tb_user表的email字段的索引 1 drop index idx_user_email on tb_user; 案例 基础数据准备 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 create table tb_user( id int primary key auto_increment comment \u0026#39;主键\u0026#39;, name varchar(50) not null comment \u0026#39;用户名\u0026#39;, phone varchar(11) not null comment \u0026#39;手机号\u0026#39;, email varchar(100) comment \u0026#39;邮箱\u0026#39;, profession varchar(11) comment \u0026#39;专业\u0026#39;, age tinyint unsigned comment \u0026#39;年龄\u0026#39;, gender char(1) comment \u0026#39;性别 , 1: 男, 2: 女\u0026#39;, status char(1) comment \u0026#39;状态\u0026#39;, createtime datetime comment \u0026#39;创建时间\u0026#39; ) comment \u0026#39;系统用户表\u0026#39;; INSERT INTO itcast.tb_user (name, phone, email, profession, age, gender, status, createtime) VALUES (\u0026#39;吕布\u0026#39;, \u0026#39;17799990000\u0026#39;, \u0026#39;lvbu666@163.com\u0026#39;, \u0026#39;软件工程\u0026#39;, 23, \u0026#39;1\u0026#39;, \u0026#39;6\u0026#39;, \u0026#39;2001-02-02 00:00:00\u0026#39;); INSERT INTO itcast.tb_user (name, phone, email, profession, age, gender, status, createtime) VALUES (\u0026#39;曹操\u0026#39;, \u0026#39;17799990001\u0026#39;, \u0026#39;caocao666@qq.com\u0026#39;, \u0026#39;通讯工程\u0026#39;, 33, \u0026#39;1\u0026#39;, \u0026#39;0\u0026#39;, \u0026#39;2001-03-05 00:00:00\u0026#39;); INSERT INTO itcast.tb_user (name, phone, email, profession, age, gender, status, createtime) VALUES (\u0026#39;赵云\u0026#39;, \u0026#39;17799990002\u0026#39;, \u0026#39;17799990@139.com\u0026#39;, \u0026#39;英语\u0026#39;, 34, \u0026#39;1\u0026#39;, \u0026#39;2\u0026#39;, \u0026#39;2002-03-02 00:00:00\u0026#39;); INSERT INTO itcast.tb_user (name, phone, email, profession, age, gender, status, createtime) VALUES (\u0026#39;孙悟空\u0026#39;, \u0026#39;17799990003\u0026#39;, \u0026#39;17799990@sina.com\u0026#39;, \u0026#39;工程造价\u0026#39;, 54, \u0026#39;1\u0026#39;, \u0026#39;0\u0026#39;, \u0026#39;2001-07-02 00:00:00\u0026#39;); INSERT INTO itcast.tb_user (name, phone, email, profession, age, gender, status, createtime) VALUES (\u0026#39;花木兰\u0026#39;, \u0026#39;17799990004\u0026#39;, \u0026#39;19980729@sina.com\u0026#39;, \u0026#39;软件工程\u0026#39;, 23, \u0026#39;2\u0026#39;, \u0026#39;1\u0026#39;, \u0026#39;2001-04-22 00:00:00\u0026#39;); INSERT INTO itcast.tb_user (name, phone, email, profession, age, gender, status, createtime) VALUES (\u0026#39;大乔\u0026#39;, \u0026#39;17799990005\u0026#39;, \u0026#39;daqiao666@sina.com\u0026#39;, \u0026#39;舞蹈\u0026#39;, 22, \u0026#39;2\u0026#39;, \u0026#39;0\u0026#39;, \u0026#39;2001-02-07 00:00:00\u0026#39;); INSERT INTO itcast.tb_user (name, phone, email, profession, age, gender, status, createtime) VALUES (\u0026#39;露娜\u0026#39;, \u0026#39;17799990006\u0026#39;, \u0026#39;luna_love@sina.com\u0026#39;, \u0026#39;应用数学\u0026#39;, 24, \u0026#39;2\u0026#39;, \u0026#39;0\u0026#39;, \u0026#39;2001-02-08 00:00:00\u0026#39;); INSERT INTO itcast.tb_user (name, phone, email, profession, age, gender, status, createtime) VALUES (\u0026#39;程咬金\u0026#39;, \u0026#39;17799990007\u0026#39;, \u0026#39;chengyaojin@163.com\u0026#39;, \u0026#39;化工\u0026#39;, 38, \u0026#39;1\u0026#39;, \u0026#39;5\u0026#39;, \u0026#39;2001-05-23 00:00:00\u0026#39;); INSERT INTO itcast.tb_user (name, phone, email, profession, age, gender, status, createtime) VALUES (\u0026#39;项羽\u0026#39;, \u0026#39;17799990008\u0026#39;, \u0026#39;xiaoyu666@qq.com\u0026#39;, \u0026#39;金属材料\u0026#39;, 43, \u0026#39;1\u0026#39;, \u0026#39;0\u0026#39;, \u0026#39;2001-09-18 00:00:00\u0026#39;); INSERT INTO itcast.tb_user (name, phone, email, profession, age, gender, status, createtime) VALUES (\u0026#39;白起\u0026#39;, \u0026#39;17799990009\u0026#39;, \u0026#39;baiqi666@sina.com\u0026#39;, \u0026#39;机械工程及其自动化\u0026#39;, 27, \u0026#39;1\u0026#39;, \u0026#39;2\u0026#39;, \u0026#39;2001-08-16 00:00:00\u0026#39;); INSERT INTO itcast.tb_user (name, phone, email, profession, age, gender, status, createtime) VALUES (\u0026#39;韩信\u0026#39;, \u0026#39;17799990010\u0026#39;, \u0026#39;hanxin520@163.com\u0026#39;, \u0026#39;无机非金属材料工程\u0026#39;, 27, \u0026#39;1\u0026#39;, \u0026#39;0\u0026#39;, \u0026#39;2001-06-12 00:00:00\u0026#39;); INSERT INTO itcast.tb_user (name, phone, email, profession, age, gender, status, createtime) VALUES (\u0026#39;荆轲\u0026#39;, \u0026#39;17799990011\u0026#39;, \u0026#39;jingke123@163.com\u0026#39;, \u0026#39;会计\u0026#39;, 29, \u0026#39;1\u0026#39;, \u0026#39;0\u0026#39;, \u0026#39;2001-05-11 00:00:00\u0026#39;); INSERT INTO itcast.tb_user (name, phone, email, profession, age, gender, status, createtime) VALUES (\u0026#39;兰陵王\u0026#39;, \u0026#39;17799990012\u0026#39;, \u0026#39;lanlinwang666@126.com\u0026#39;, \u0026#39;工程造价\u0026#39;, 44, \u0026#39;1\u0026#39;, \u0026#39;1\u0026#39;, \u0026#39;2001-04-09 00:00:00\u0026#39;); INSERT INTO itcast.tb_user (name, phone, email, profession, age, gender, status, createtime) VALUES (\u0026#39;狂铁\u0026#39;, \u0026#39;17799990013\u0026#39;, \u0026#39;kuangtie@sina.com\u0026#39;, \u0026#39;应用数学\u0026#39;, 43, \u0026#39;1\u0026#39;, \u0026#39;2\u0026#39;, \u0026#39;2001-04-10 00:00:00\u0026#39;); INSERT INTO itcast.tb_user (name, phone, email, profession, age, gender, status, createtime) VALUES (\u0026#39;貂蝉\u0026#39;, \u0026#39;17799990014\u0026#39;, \u0026#39;84958948374@qq.com\u0026#39;, \u0026#39;软件工程\u0026#39;, 40, \u0026#39;2\u0026#39;, \u0026#39;3\u0026#39;, \u0026#39;2001-02-12 00:00:00\u0026#39;); INSERT INTO itcast.tb_user (name, phone, email, profession, age, gender, status, createtime) VALUES (\u0026#39;妲己\u0026#39;, \u0026#39;17799990015\u0026#39;, \u0026#39;2783238293@qq.com\u0026#39;, \u0026#39;软件工程\u0026#39;, 31, \u0026#39;2\u0026#39;, \u0026#39;0\u0026#39;, \u0026#39;2001-01-30 00:00:00\u0026#39;); INSERT INTO itcast.tb_user (name, phone, email, profession, age, gender, status, createtime) VALUES (\u0026#39;芈月\u0026#39;, \u0026#39;17799990016\u0026#39;, \u0026#39;xiaomin2001@sina.com\u0026#39;, \u0026#39;工业经济\u0026#39;, 35, \u0026#39;2\u0026#39;, \u0026#39;0\u0026#39;, \u0026#39;2000-05-03 00:00:00\u0026#39;); INSERT INTO itcast.tb_user (name, phone, email, profession, age, gender, status, createtime) VALUES (\u0026#39;嬴政\u0026#39;, \u0026#39;17799990017\u0026#39;, \u0026#39;8839434342@qq.com\u0026#39;, \u0026#39;化工\u0026#39;, 38, \u0026#39;1\u0026#39;, \u0026#39;1\u0026#39;, \u0026#39;2001-08-08 00:00:00\u0026#39;); INSERT INTO itcast.tb_user (name, phone, email, profession, age, gender, status, createtime) VALUES (\u0026#39;狄仁杰\u0026#39;, \u0026#39;17799990018\u0026#39;, \u0026#39;jujiamlm8166@163.com\u0026#39;, \u0026#39;国际贸易\u0026#39;, 30, \u0026#39;1\u0026#39;, \u0026#39;0\u0026#39;, \u0026#39;2007-03-12 00:00:00\u0026#39;); INSERT INTO itcast.tb_user (name, phone, email, profession, age, gender, status, createtime) VALUES (\u0026#39;安琪拉\u0026#39;, \u0026#39;17799990019\u0026#39;, \u0026#39;jdodm1h@126.com\u0026#39;, \u0026#39;城市规划\u0026#39;, 51, \u0026#39;2\u0026#39;, \u0026#39;0\u0026#39;, \u0026#39;2001-08-15 00:00:00\u0026#39;); INSERT INTO itcast.tb_user (name, phone, email, profession, age, gender, status, createtime) VALUES (\u0026#39;典韦\u0026#39;, \u0026#39;17799990020\u0026#39;, \u0026#39;ycaunanjian@163.com\u0026#39;, \u0026#39;城市规划\u0026#39;, 52, \u0026#39;1\u0026#39;, \u0026#39;2\u0026#39;, \u0026#39;2000-04-12 00:00:00\u0026#39;); INSERT INTO itcast.tb_user (name, phone, email, profession, age, gender, status, createtime) VALUES (\u0026#39;廉颇\u0026#39;, \u0026#39;17799990021\u0026#39;, \u0026#39;lianpo321@126.com\u0026#39;, \u0026#39;土木工程\u0026#39;, 19, \u0026#39;1\u0026#39;, \u0026#39;3\u0026#39;, \u0026#39;2002-07-18 00:00:00\u0026#39;); INSERT INTO itcast.tb_user (name, phone, email, profession, age, gender, status, createtime) VALUES (\u0026#39;后羿\u0026#39;, \u0026#39;17799990022\u0026#39;, \u0026#39;altycj2000@139.com\u0026#39;, \u0026#39;城市园林\u0026#39;, 20, \u0026#39;1\u0026#39;, \u0026#39;0\u0026#39;, \u0026#39;2002-03-10 00:00:00\u0026#39;); INSERT INTO itcast.tb_user (name, phone, email, profession, age, gender, status, createtime) VALUES (\u0026#39;姜子牙\u0026#39;, \u0026#39;17799990023\u0026#39;, \u0026#39;37483844@qq.com\u0026#39;, \u0026#39;工程造价\u0026#39;, 29, \u0026#39;1\u0026#39;, \u0026#39;4\u0026#39;, \u0026#39;2003-05-26 00:00:00\u0026#39;); 1000w级别数据模拟 数据文件 创建表 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 CREATE TABLE `tb_sku` ( `id` int(11) NOT NULL AUTO_INCREMENT COMMENT \u0026#39;商品id\u0026#39;, `sn` varchar(100) NOT NULL COMMENT \u0026#39;商品条码\u0026#39;, `name` varchar(200) NOT NULL COMMENT \u0026#39;SKU名称\u0026#39;, `price` int(20) NOT NULL COMMENT \u0026#39;价格（分）\u0026#39;, `num` int(10) NOT NULL COMMENT \u0026#39;库存数量\u0026#39;, `alert_num` int(11) DEFAULT NULL COMMENT \u0026#39;库存预警数量\u0026#39;, `image` varchar(200) DEFAULT NULL COMMENT \u0026#39;商品图片\u0026#39;, `images` varchar(2000) DEFAULT NULL COMMENT \u0026#39;商品图片列表\u0026#39;, `weight` int(11) DEFAULT NULL COMMENT \u0026#39;重量（克）\u0026#39;, `create_time` datetime DEFAULT NULL COMMENT \u0026#39;创建时间\u0026#39;, `update_time` datetime DEFAULT NULL COMMENT \u0026#39;更新时间\u0026#39;, `category_name` varchar(200) DEFAULT NULL COMMENT \u0026#39;类目名称\u0026#39;, `brand_name` varchar(100) DEFAULT NULL COMMENT \u0026#39;品牌名称\u0026#39;, `spec` varchar(200) DEFAULT NULL COMMENT \u0026#39;规格\u0026#39;, `sale_num` int(11) DEFAULT \u0026#39;0\u0026#39; COMMENT \u0026#39;销量\u0026#39;, `comment_num` int(11) DEFAULT \u0026#39;0\u0026#39; COMMENT \u0026#39;评论数\u0026#39;, `status` char(1) DEFAULT \u0026#39;1\u0026#39; COMMENT \u0026#39;商品状态 1-正常，2-下架，3-删除\u0026#39;, PRIMARY KEY (`id`) USING BTREE ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT=\u0026#39;商品表\u0026#39;; 将数据文件放在/root/sql目录下 加载文件tb_sku1.sql到数据库中 1 load data local infile \u0026#39;/root/sql/tb_sku1.sql\u0026#39; into table `tb_sku` fields terminated by \u0026#39;,\u0026#39; lines terminated by \u0026#39;\\n\u0026#39;; 同理，继续保存tb_sku2.sql等等数据表(由于数据过多，直接加载1000w，数据过于耗费CPU和内存，分为5个部分进行保存) 1 load data local infile \u0026#39;/root/sql/xxxxx.sql\u0026#39; into table `tb_sku` fields terminated by \u0026#39;,\u0026#39; lines terminated by \u0026#39;\\n\u0026#39;; 需求：\nname字段为姓名字段，该字段的值可能会重复，为该字段创建索引。 1 create index index_user_name on tb_user(name); phone手机号字段的值，是非空，且唯一的，为该字段创建唯一索引。 1 create unique index idx_user_phone on tb_user(phone); 为profession、age、status创建联合索引。 1 create index idx_user_pro_age_sta on tb_user(profession,age,status); 为email建立合适的索引来提升查询效率。 1 create index idx_user_email on tb_user(email); SQL性能分析 SQL执行频率 MySQL客户端连接成功后，通过show [session|global] status命令可以提供服务器状态信息。通过如下指令，可以查看当前数据库的INSERT、UPDATE、DELETE、SELECT的访问频次。\n命令 1 2 # Com后面跟7个下划线，即7个字符 SHOW GLOBAL STATUS LIKE \u0026#39;Com_______\u0026#39;; 慢查询日志 慢查询日志记录了所有执行时间超过指定参数(long_query_time，单位：秒，默认10秒)的所有SQL语句的日志。\n查询慢查询日志是否开启 1 show variables like \u0026#39;slow_query_log\u0026#39;; MySQL的慢查询日志默认没有开启，需要在MySQL的配置文件(/etc/my.cnf)中配置如下信息： 1 2 3 4 5 6 7 [mysqld] ... ... # 开启MySQL慢日志查询开关 slow_query_log=1 # 设置慢日志的时间为2秒，SQL语句执行时间超过2秒，就会视为慢查询，记录慢查询日志 long_query_time=2 配置完毕之后，通过以下指令重新启动MySQL服务器进行测试，查看慢日志文件的信息/var/lib/mysql/localhost-slow.log(我的慢查询日志文件/usr/local/mysql/data/localhost-slow.log)\n注意：我的MySQL数据配置在/usr/local/mysql/data目录下，所以得在这个目录下找\n1 systemctl restart mysqld 再次查询慢日志是否开启 1 show variables like \u0026#39;slow_query_log\u0026#39;; 找到慢查询日志 1 ls -l /usr/local/mysql/data 循环读取慢查询日志 1 tail -f /usr/local/mysql/data/localhost-slow.log 查询tb_user表 1 select * from tb_user; 由于执行速度过快，慢查询日志不会记录\n查询tb_sku表(1000w数据量)数量 1 select count(*) from tb_sku; 耗时9.55秒\n此时再看慢查询日志 已经记录了这次数据\n1 2 3 4 5 6 7 8 Time : 执行的时间 User@Host ： 执行的用户及主机 Query_time ： 查询所用时间 Lock_time ： 锁定时间 Rows_sent ： 查询出来的行数 use itcast; ： 使用的数据库为itcast SET timestamp=1763137964; : 当前操作的时间 select count(*) from tb_sku; ： 使用的sql语句 profile详情 show profiles能够在做SQL优化时帮助我们了解时间都耗费到哪里去了。通过have_profiling参数，能够看到当前MySQL是否支持profile操作： 1 select @@have_profiling; 1 select @@profiling; 默认profiling是关闭的，可以通过set语句在session/global级别开启profiling：\n1 2 3 4 # 开启本次会话的profiling set profiling=1; # 全局配置，但是对当前会话不生效 set global profiling=1; 使用profile查看执行耗时 执行一系列的业务SQL的操作，然后通过如下指令查看指令的执行耗时： 1 2 3 4 5 6 7 8 # 查看每一条SQL的耗时基本情况 show profiles; # 查看指令query_id的SQL语句各个阶段的耗时情况 show profile for query query_id; # 查看指定query_id的SQL语句CPU的使用情况 show profile cpu for query query_id; 练习 查看每一条SQL的耗时基本情况 1 2 3 4 5 6 7 8 9 10 11 # 查询tb_user表id为1的数据 select * from tb_user where id = 1; # 查询tb_user表name为白起的数据 select * from tb_user where name = \u0026#39;白起\u0026#39;; # 查询tb_sku表的数量 select count(*) from tb_sku; # 查看SQL耗时基本情况 show profiles; 查看第4条SQL语句各个阶段的耗时情况 1 show profile for query 4; 可以看到主要耗时时间在执行上。\n查看第4条SQL语句的CPU使用情况 1 show profile cpu for query 4; explain执行计划 EXPLAIN 或者 DESC 命令获取MySQL如何执行SELECT语句的信息，包括在SELECT语句执行过程中表如何连接和连接的顺序。\n语法\n1 2 # 直接在select语句之前加上关键词explain/desc EXPLAIN SELECT 字段列表 FROM 表名 WHERE 条件; 使用explain查看执行信息 1 explain/desc select * from tb_user where id = 1; 字段含义 id select查询的序列号，表示查询中执行select子句或者时操作表的顺序(id相同，执行顺序从上到下；id不同，值越大，越先执行)\nselect_type 表示SELECt的类型，常见的取值由SIMPLE(简单表，即不使用表连接或者子查询)、PRIMARY(著查询，即外层的查询)、UNION(UNION中的第二个或者后面的查询语句)、SUBQUERY(SELECT/WHERE之后包含了子查询)等\ntable 表示当前访问的表名或别名\npartitions 表示设计的分区信息(若表使用了分区功能)\ntype 表示连接类型，性能由好到坏排序：NULL \u0026gt; system \u0026gt; const \u0026gt; eq_ref \u0026gt; ref \u0026gt; range \u0026gt; index \u0026gt; ALL。(只有不访问任何表的情况下，连接类型才会NULL，业务情况下不可能实现。)\npossible_keys 显示可能应用在这张表上的索引，一个或多个。\nkey 实际使用的索引，如果为NULL，则没有使用索引。\nkey_len 表示索引中使用的字节数，该值为索引字段最大可能长度，并非实际使用长度，在不损失精确性的前提下，长度越短越好。\nref 索引比较时使用的列或常量\nrows MySQL认为必须要执行查询的行数，在innodb引擎的表中，是一个估计值，可能并不总是准确的。\nfiltered 表示返回结果的行数占需读取行数的百分比，filtered的值越大越好。\nExtra 额外信息(是否用临时表、是否排序、是否覆盖索引等)\n练习 使用的关联表(详细内容可以看:MySQL基础-多表查询) 查询所有学生的选课情况(执行计划) 1 explain select s.*,c.* from student s,course c,student_course sc where s.id = sc.studentid and c.id = sc.courseid; 查询选修了MySQL课程的学生信息(子查询)(执行计划) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 # 查询MySQL的课程id select id from course c where c.name = \u0026#39;MySQL\u0026#39;; # 输出：3 # 查询选修了课程id为3的学生id select studentid from student_course sc where sc.courseid = 3; # 输出：1 , 2 # 查询学生id为1,2的学生信息 select * from student s where s.id in (1,2); # 查询选修了MySQL课程的学生信息(合并上面三条内容) select * from student s where s.id in (select studentid from student_course sc where sc.courseid = (select id from course c where c.name = \u0026#39;MySQL\u0026#39;)); # 查询选修了MySQL课程的学生信息(执行计划) explain select * from student s where s.id in (select studentid from student_course sc where sc.courseid = (select id from course c where c.name = \u0026#39;MySQL\u0026#39;)); 执行顺序 c表，sc表，子查询\u0026lt;subquery2\u0026gt;，s表\n查询\u0026rsquo;A\u0026rsquo;(执行计划) 1 explain select \u0026#39;A\u0026#39;; 可以看到连接类型为NULL，额外信息表示没有使用表。\n查看tb_user表的索引 1 show index from tb_user; 字段Non_unique为0，表示是唯一索引；字段Non_unique为1，表示是非唯一索引。\n连接类型为const(使用主键或唯一索引访问) 1 2 3 4 # 查询id为1的用户信息 explain select * from tb_user where id = 1; # 查询手机号为17799990014的用户信息 explain select * from tb_user where phone = \u0026#39;17799990014\u0026#39;; 连接类型为ref(使用非唯一索引) 1 2 # 查询name为白起的用户信息 explain select * from tb_user where name = \u0026#39;白起\u0026#39;; 主要关注的字段信息： 1 2 3 最主要：type 其次：possible_key、key、key_len、Extra 参考：rows 索引使用 验证索引效率 通过主键id进行查询 1 2 3 select * from tb_sku where id = 1; # 将每一列都转换成行表示 select * from tb_sku where id = 1\\G; 查询耗时为0.00秒，其中sn为100000003145001(无索引)\n在未建立索引之前，执行如下SQL，查看SQL的耗时。 1 select * from tb_sku where sn = \u0026#39;100000003145001\u0026#39;; 查询耗时为5.56秒\n查询该表索引 1 show index from tb_sku; 总结：id为主键，默认建立了主键索引，而sn没有索引，执行效率就会很低。\n针对sn字段进行创建索引 1 create index idx_sku_sn on tb_sku(sn); 创建耗时为39.30秒，因为这里要为1000w的数据创建B+tree数据结构的索引结构，所以消耗时间比较长。\n查看该表索引 1 show index from tb_sku; 可以看到已经创建了sn的索引\n再次使用sn进行查询(行表示) 1 select * from tb_sku where sn = \u0026#39;100000003145001\u0026#39;\\G; 可以看到，此时查询耗时只用0.00秒，确实比刚刚5.56秒有了显著的提升\n查询sn为100000003145001的数据(执行计划) 1 explain select * from tb_sku where sn = \u0026#39;100000003145001\u0026#39;; 可以看到其中使用的索引为刚刚创建的idx_sku_sn。\n索引设计原则 最左前缀法则 如果索引了多列(联合索引)，要遵守最左前缀法则。最左前缀法则指的是查询从索引的最左列开始，并且不跳过索引中的列。\n如果跳跃某一列，索引将部分失效(后面的字段索引失效)。\n演示 背景：tb_user表\n查看表的索引\n1 show index from tb_user; 可以看到profession、age、status为联合索引\nA、查询专业为软件工程，年龄为31，状态为0的用户信息(执行计划) 1 explain select * from tb_user where profession = \u0026#39;软件工程\u0026#39; and age = 31 and status = \u0026#39;0\u0026#39;; 因为这条sql语句用上了全部的三个字段，不跳过任何一列，符合最左前缀法则，所以索引生效，且索引长度为54。\nB、查询专业为软件工程，年龄为31的用户信息(执行计划) 1 explain select * from tb_user where profession = \u0026#39;软件工程\u0026#39; and age = 31; 因为最左边的字段存在，且没有跳过任何一列，符合最左前缀法则，所以索引会正常生效。 字段长度为49，与A字段长度54相比差距为5，由此可以看出status字段长度为5\nC、查询专业为软件工程的用户信息(执行计划) 1 explain select * from tb_user where profession = \u0026#39;软件工程\u0026#39;; 因为有最左边的字段存在，符合最左前缀法则，所以索引正常生效。 字段长度为47，与B字段长度49相差为2，所以age字段长度为2。\nD、查询年龄为31，状态为0的用户信息(执行计划) 1 explain select * from tb_user where age = 31 and status = \u0026#39;0\u0026#39;; 因为最左边的列不存在，所以不符合最左前缀法则，不走索引，而是走全表扫描。\nE、查询状态为0的用户信息(执行计划) 1 explain select * from tb_user where status = \u0026#39;0\u0026#39;; 因为最左边的列不存在，所以不符合最左前缀法则，不走索引，而是走全表扫描。\nF、查询专业为软件工程，状态为0的用户信息(执行计划) 1 explain select * from tb_user where profession = \u0026#39;软件工程\u0026#39; and status = \u0026#39;0\u0026#39;; 因为最左边的列存在，符合最左前缀法则，但是profession和status中间的列age不存在，跳过了age列，所以status不生效。 从C、B可以看出profession和status字段长度分别为47和5，正常来讲走索引的话，这里的字段长度应该是52，但是这里status不生效，所以字段长度为47。\n查询年龄为31，状态为0，专业为软件工程的用户信息(执行计划) 1 explain select * from tb_user where age = 31 and status = \u0026#39;0\u0026#39; and profession = \u0026#39;软件工程\u0026#39;; 字段长度为54，所以三个索引都用上了，所以只要最左的字段存在，与它所在的位置无关，就符合最左前缀法则(与字段位置无关，字段存在即可)。\n索引失效情况 范围查询 联合索引中，出现范围查询(\u0026gt;，\u0026lt;)，范围查询右侧的列索引失效。 演示 查询专业为软件工程，年龄大于30，状态为0的学生信息(执行计划) 1 explain select * from tb_user where profession = \u0026#39;软件工程\u0026#39; and age \u0026gt; 30 and status = \u0026#39;0\u0026#39;; 字段长度为49，可以看出索引status失效。因为存在范围查询(age \u0026gt; 30)，所以范围查询右侧的列status索引失效。\n查询专业为软件工程，年龄大于等于30，状态为0的学生信息(执行计划) 1 explain select * from tb_user where profession = \u0026#39;软件工程\u0026#39; and age \u0026gt;= 30 and status = \u0026#39;0\u0026#39;; 索引列运算 不要在索引列上进行运算操作，索引将失效。 演示 查询手机号为17799990015的用户信息(执行计划) 1 explain select * from tb_user where phone = \u0026#39;17799990015\u0026#39;; 查询手机号最后两位为15的用户信息(执行计划) 从第10位解决手机号2个数等于15\n1 explain select * from tb_user where substring(phone,10,2) = \u0026#39;15\u0026#39;; 由于对phone字段进行了函数运算，导致索引失效，所以这里是全表扫描。\n字符串不加引号 字符串类型字段使用时，不加引号，索引将失效。 演示 查询手机号为17799990015(不加引号)的用户信息(执行计划) 1 explain select * from tb_user where phone = 17799990015; 因为phone字段没加引号，导致这里不走索引，而是走全表扫描。\n查询专业为软件工程，年龄为31，状态为0(不加引号)的用户信息(执行计划) 1 explain select * from tb_user where profession = \u0026#39;软件工程\u0026#39; and age = 31 and status = 0; 由于status字段没加引号，导致status字段没走索引，所以索引长度为49，少了status长度为5的字段索引。\n模糊查询 如果仅仅是尾部模糊匹配，索引不会失效。如果时头部模糊匹配，索引失效。 演示 查询专业开头为软件的用户信息(执行计划) 1 explain select * from tb_user where profession like \u0026#39;软件%\u0026#39;; 后面模糊匹配，因为profession是联合索引中的第一个字段，符合最左前缀法则，所以正常走索引。\n查询专业结尾为工程的用户信息(执行计划) 1 explain select * from tb_user where profession like \u0026#39;%工程\u0026#39;; 前面使用模糊匹配，可以看到现在走的是全表匹配。\n查询专业中间有工的用户信息(执行计划) 1 explain select * from tb_user where profession like \u0026#39;%工%\u0026#39;; 总结：大数据的情况下，尽量规避模糊查询，在前面加%的情况。\nor连接的条件 用or分割开的条件，如果or前的条件中的列有索引，而后面的列没有索引，那么涉及的索引都不会被用到。 演示 查询id为10或者年龄为23的用户信息(执行计划)\nid有索引，age没有索引(age为联合索引，仅仅用到age，不符合最左前缀法则，不会使用联合索引)\n1 explain select * from tb_user where id = 10 or age = 23; 可以看到可能用到的索引PRIMARY，但实际上没有用到索引。\n查询手机号为17799990017或者年龄为23的用户信息(执行计划) 1 explain select * from tb_user where phone = \u0026#39;17799990017\u0026#39; or age = 23; 解决方法 由于age没有索引，所以即使id、phone有索引，索引也会失效。所以需要针对age也要建立索引。 1 create index idx_user_age on tb_user(age); 数据分布影响 如果MySQL评估使用索引比全表更慢，则不适用索引。 演示 查询手机号大于等于17799990020的用户信息(执行计划) 1 explain select * from tb_user where phone \u0026gt;= \u0026#39;17799990020\u0026#39;; 查询手机号大于等于17799990000(所有用户手机号都是大于等于该手机号)的用户信息(执行计划) 1 explain select * from tb_user where phone \u0026gt;= \u0026#39;17799990000\u0026#39;; 因为所有phone都是大于0000，所以MySQL认为还不如走全表扫描。\n查询手机号大于等于17799990010(绝大部分用户)的用户信息(执行计划) 1 explain select * from tb_user where phone \u0026gt;= \u0026#39;17799990010\u0026#39;; 查询手机号大于等于17799990013(少部分用户)的用户信息(执行计划) 1 explain select * from tb_user where phone \u0026gt;= \u0026#39;17799990013\u0026#39;; SQL提示 背景 查询专业为软件工程的用户信息(执行计划) 1 explain select * from tb_user where profession = \u0026#39;软件工程\u0026#39;; 思考：profession属于联合索引，并且单独使用它符合最左前缀法则，会走联合索引，那么给它加上单列索引，再次查询会走什么索引呢？\n创建profession的单列索引 1 create index idx_user_pro on tb_user(profession); 查询专业为软件工程的用户信息(执行计划) 1 explain select * from tb_user where profession = \u0026#39;软件工程\u0026#39;; 可以看到MySQL走了联合索引。\n那么多个索引的情况下，我能要求MySQL走我指定的索引吗？\n简介 SQL提示，是优化数据库的一个重要手段，简单来说，就是SQL语句中加入一些人为的提示来达到优化操作的目录。 语法 use index(建议数据库用哪个索引) 1 explain select * from tb_user use index(idx_user_pro) where profession = \u0026#39;软件工程\u0026#39;; ignore index(建议数据库不要用哪个索引) 1 explain select * from tb_user ignore index(idx_user_pro) where profession = \u0026#39;软件工程\u0026#39;; force index(强制数据库必须使用哪个索引) 1 explain select * from tb_user force index(idx_user_pro) where profession = \u0026#39;软件工程\u0026#39;; 覆盖索引(重要) 尽量使用覆盖索引(查询使用了索引，并且需要返回的列，在该索引中已经全部能够找到),减少select *; 演示 删除影响演示的索引 1 2 3 drop index idx_user_age on tb_user; drop index idx_user_email on tb_user; drop index idx_user_pro on tb_user; A、查询专业为软件工程，年龄为31，状态为0的所有用户信息(执行计划) 1 explain select * from tb_user where profession = \u0026#39;软件工程\u0026#39; and age = 31 and status = \u0026#39;0\u0026#39;; B、查询专业为软件工程，年龄为31，状态为0的id、profession信息(执行计划) 1 explain select id,profession from tb_user where profession = \u0026#39;软件工程\u0026#39; and age = 31 and status = \u0026#39;0\u0026#39;; C、查询专业为软件工程，年龄为31，状态为0的id、profession、age、status信息(执行计划) 1 explain select id,profession,age,status from tb_user where profession = \u0026#39;软件工程\u0026#39; and age = 31 and status = \u0026#39;0\u0026#39;; D、查询专业为软件工程，年龄为31，状态为0的id、profession、age、status、name信息(执行计划) 1 explain select id,profession,age,status,name from tb_user where profession = \u0026#39;软件工程\u0026#39; and age = 31 and status = \u0026#39;0\u0026#39;; 总结 可以看到四条语句前面的内容全都相同，只有Extra有区别，A、D显示NULL，而B、C显示Using index，这里面的内容和MySQL版本有关。有些版本中A、D会显示Using index condition，B、C显示Using where;Using index。\n知识小贴士：\nNULL或Using index condition : 查找使用了索引，但是需要回表查询数据。(性能低)\nUsing index或Using where;Using index : 查找使用了索引，但是需要的数据都在索引列中能找到，所以不需要回表查询数据。(性能高)\n回表查询 为了大家更清楚的理解，什么是覆盖索引，什么是回表查询，我们一起再来看下面的这组SQL的执行过程。\n表结构及索引示意图: id是主键，是一个聚集索引。 name字段建立了普通索引，是一个二级索引（辅助索引）。\n执行SQL : select * from tb_user where id = 2; 根据id查询，直接走聚集索引查询，一次索引扫描，直接返回数据，性能高。\n执行SQL：selet id,name from tb_user where name = \u0026lsquo;Arm\u0026rsquo;; 虽然是根据name字段查询，查询二级索引，但是由于查询返回在字段为 id，name，在name的二级索引中，这两个值都是可以直接获取到的，因为覆盖索引，所以不需要回表查询，性能高。\n执行SQL：selet id,name,gender from tb_user where name = \u0026lsquo;Arm\u0026rsquo;; 由于在name的二级索引中，不包含gender，所以，需要两次索引扫描，也就是需要回表查询(通过id在聚集索引中获取gender的值)，性能相对较差一点。\n尽量避免使用select *，因为使用select *，很容易出现回表查询，造成性能降低。\n思考题 一张表, 有四个字段(id, username, password, status), 由于数据量大, 需要对以下SQL语句进行优化, 该如何进行才是最优方案:\n1 select id,username,password from tb_user where username = \u0026#39;itcast\u0026#39;; 解：针对于 username, password建立联合索引, sql为: create index idx_user_name_pass on tb_user(username,password); 这样可以避免上述的SQL语句，在查询的过程中，出现回表查询。\n前缀索引 当字段类型为字符串（varchar，text，longtext等）时，有时候需要索引很长的字符串，这会让索引变得很大，查询时，浪费大量的磁盘IO， 影响查询效率。此时可以只将字符串的一部分前 ，建立索引，这样可以大大节约索引空间，从而提高索引效率。 语法 1 create index idx_xxxx on table_name(column(n)) ; 示例 为tb_user表的email字段，建立长度为5的前缀索引。 1 create index idx_email_5 on tb_user(email(5)); 前缀长度 可以根据索引的选择性来决定，而选择性是指不重复的索引值（基数）和数据表的记录总数的比值， 索引选择性越高则查询效率越高， 唯一索引的选择性是1，这是最好的索引选择性，性能也是最好的。 1 2 select count(distinct email) / count(*) from tb_user ; select count(distinct substring(email,1,5)) / count(*) from tb_user ; 前缀索引的查询流程 单列索引\u0026amp;联合索引 简介 单列索引：即一个索引只包含单个列。 联合索引：即一个索引包含了多个列。 在业务场景中，如果存在多个查询条件，考虑针对于查询字段建立索引时，建议建立联合索引，而非单列索引。 示例 我们先来看看 tb_user 表中目前的索引情况: 1 show index from tb_user; 在查询出来的索引中，既有单列索引，又有联合索引。\n查询手机号为17799990010，姓名为韩信的id,phone,name信息(执行计划) 1 explain select id,phone,name from tb_user where phone = \u0026#39;17799990010\u0026#39; and name = \u0026#39;韩信\u0026#39;; 多条件联合查询时，MySQL优化器会评估哪个字段的索引效率更高，会选择该索引完成本次查询。\n通过上述执行计划我们可以看出来，在and连接的两个字段 phone、name上都是有单列索引的，但是最终mysql只会选择一个索引，也就是说，只能走一个字段的索引，此时是会回表查询的。\n创建一个phone和name字段的联合索引来查询一下执行计划。 1 create unique index idx_user_phone_name on tb_user(phone,name); 建议走联合索引查询手机号为17799990010，姓名为韩信的id,phone,name信息(执行计划) 1 explain select id,phone,name from tb_user use index(idx_user_phone_name) where phone = \u0026#39;17799990010\u0026#39; and name = \u0026#39;韩信\u0026#39;; 此时，查询时，就走了联合索引，而在联合索引中包含 phone、name的信息，在叶子节点下挂的是对 应的主键id，所以查询是无需回表查询的。\n在业务场景中，如果存在多个查询条件，考虑针对于查询字段建立索引时，建议建立联合索引， 而非单列索引。\n如果查询使用的是联合索引，具体的结构示意图如下： 索引设计原则 针对于数据量较大，且查询比较频繁的表建立索引。 针对于常作为查询条件（where）、排序（order by）、分组（group by）操作的字段建立索 引。 尽量选择区分度高的列作为索引，尽量建立唯一索引，区分度越高，使用索引的效率越高。 如果是字符串类型的字段，字段的长度较长，可以针对于字段的特点，建立前缀索引。 尽量使用联合索引，减少单列索引，查询时，联合索引很多时候可以覆盖索引，节省存储空间， 避免回表，提高查询效率。 要控制索引的数量，索引并不是多多益善，索引越多，维护索引结构的代价也就越大，会影响增 删改的效率。 如果索引列不能存储NULL值，请在创建表时使用NOT NULL约束它。当优化器知道每列是否包含 NULL值时，它可以更好地确定哪个索引最有效地用于查询。 ","date":"2025-11-06T16:09:43+08:00","permalink":"https://YLine-hub.github.io/p/mysqlmysql%E8%BF%9B%E9%98%B6-%E7%B4%A2%E5%BC%95/","title":"[MySQL]MySQL进阶-索引"},{"content":"问题一：新建项目时出现报错 1 2 Could not install Gradle distribution from \u0026#39;https://services.gradle.org/distributions/gradle-8.13-bin.zip\u0026#39;. Reason: java.net.SocketTimeoutException: Read timed out 原因 下载安装gradle超时 解决方法 方法一 直接使用魔法\n方法二 项目根目录-\u0026gt;gradle-\u0026gt;wrapper-\u0026gt;gradle-wrapper.properties\ngradle阿里云镜像站,查找对应版本的镜像地址 1 2 3 4 ## 原地址 distributionUrl=https\\://services.gradle.org/distributions/gradle-8.13-bin.zip ## 修改成国内镜像地址 distributionUrl=https\\://mirrors.aliyun.com/gradle/distributions/v8.13.0/gradle-8.13-bin.zip 腾讯云镜像 1 2 3 4 ## 原地址 distributionUrl=https\\://services.gradle.org/distributions/gradle-8.13-bin.zip ## 修改成国内镜像地址 distributionUrl=https\\://mirrors.cloud.tencent.com/gradle/gradle-8.13-bin.zip 只需要修改\n1 services.gradle.org/distributions 成\n1 mirrors.cloud.tencent.com/gradle 方法三 1、手动下载gradle-8.13-bin.zip文件到指定目录下\n我这边gradle-8.13文件夹在\n1 C:\\Users\\Administrator\\.gradle\\wrapper\\dists\\gradle-8.13-bin\\5xuhj0ry160q40clulazy9h7d\\gradle-8.13 2、或者，打开File-\u0026gt;Settings-\u0026gt;Build,Execution,Deployment-\u0026gt;Build Tools-\u0026gt;Gradle，配置自己的gradle路径\n3、更改后选择File-\u0026gt;Sync Project with Gradle Files\n问题二：打包项目出现报错 1 2 3 4 5 6 7 8 Could not determine the dependencies of task \u0026#39;:app:compileDebugJavaWithJavac\u0026#39;. \u0026gt; Failed to find Build Tools revision 29.0.2 * Try: Run with --stacktrace option to get the stack trace. Run with --info or --debug option to get more log output. Run with --scan to get full insights. * Get more help at https://help.gradle.org Ask Gemini 原因 打包所需的工具无法获取 解决方法：修改镜像点为国内站点 打开build.gradle文件\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 buildscript { repositories { maven { url \u0026#39;https://maven.aliyun.com/repository/public\u0026#39; } maven { url \u0026#39;https://maven.aliyun.com/repository/central\u0026#39; } maven { url \u0026#39;https://maven.aliyun.com/repository/google\u0026#39; } maven { url \u0026#39;https://maven.aliyun.com/repository/gradle-plugin\u0026#39; } google() jcenter() } dependencies { classpath \u0026#39;com.android.tools.build:gradle:4.1.2\u0026#39; } } allprojects { repositories { maven { url \u0026#39;https://maven.aliyun.com/repository/public\u0026#39; } maven { url \u0026#39;https://maven.aliyun.com/repository/central\u0026#39; } maven { url \u0026#39;https://maven.aliyun.com/repository/google\u0026#39; } maven { url \u0026#39;https://maven.aliyun.com/repository/gradle-plugin\u0026#39; } google() jcenter() } } 使用阿里云的镜像 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 buildscript { repositories { maven { url \u0026#39;https://maven.aliyun.com/nexus/content/repositories/google\u0026#39; } maven { url \u0026#39;https://maven.aliyun.com/nexus/content/repositories/jcenter\u0026#39;} } dependencies { classpath \u0026#39;com.android.tools.build:gradle:4.1.2\u0026#39; } } allprojects { repositories { maven { url \u0026#39;https://maven.aliyun.com/nexus/content/repositories/google\u0026#39; } maven { url \u0026#39;https://maven.aliyun.com/nexus/content/repositories/jcenter\u0026#39;} } } 问题三：打包项目出现错误 1 \u0026gt; Connect to localhost:55061 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: connect 原因 连接为本地的55061端口 解决方法 打开文件gradle.properties 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 ## Project-wide Gradle settings. # # For more details on how to configure your build environment visit # http://www.gradle.org/docs/current/userguide/build_environment.html # # Specifies the JVM arguments used for the daemon process. # The setting is particularly useful for tweaking memory settings. # Default value: -Xmx1024m -XX:MaxPermSize=256m # org.gradle.jvmargs=-Xmx2048m -XX:MaxPermSize=512m -XX:+HeapDumpOnOutOfMemoryError -Dfile.encoding=UTF-8 # # When configured, Gradle will run in incubating parallel mode. # This option should only be used with decoupled projects. More details, visit # http://www.gradle.org/docs/current/userguide/multi_project_builds.html#sec:decoupled_projects # org.gradle.parallel=true #Fri Feb 19 09:43:46 CST 2021 systemProp.http.proxyHost=localhost systemProp.http.proxyPort=55061 将以下两行注释 1 2 #systemProp.http.proxyHost=localhost #systemProp.http.proxyPort=55061 ","date":"2025-11-05T23:29:31+08:00","permalink":"https://YLine-hub.github.io/p/android%E9%97%AE%E9%A2%98/","title":"[Android]问题"},{"content":"android studio安装 下载 android studio 安装 双击运行安装程序 点击下一步 修改安装目录，并继续点击下一步 点击安装 点击下一步 完成并打开 选择不发送 点击下一步 如果期间弹出Android Studio First Run，则点击取消 选择自定义，并点击下一步 选择指定目录并点击下一步 点击下一步 点击接受-\u0026gt;下一步 安装完成后点击完成 创建第一个项目 选择New Project 选择Empty Activity-\u0026gt;Next 填写内容并点击完成 进入以后，自动下载所需要的gradle 但是下载速度非常慢\n解决gradle下载速度慢的问题 在 项目根目录-\u0026gt;gradle-\u0026gt;wrapper-\u0026gt;gradle-wrapper.properties\n找到文件gradle-wrapper.properties\n修改镜像地址 (1)、gradle阿里云镜像站,查找对应版本的镜像地址 1 2 3 4 ## 原地址 distributionUrl=https\\://services.gradle.org/distributions/gradle-8.13-bin.zip ## 修改成国内镜像地址 distributionUrl=https\\://mirrors.aliyun.com/gradle/distributions/v8.13.0/gradle-8.13-bin.zip （2）、腾讯云镜像 1 2 3 4 ## 原地址 distributionUrl=https\\://services.gradle.org/distributions/gradle-8.13-bin.zip ## 修改成国内镜像地址 distributionUrl=https\\://mirrors.cloud.tencent.com/gradle/gradle-8.13-bin.zip 只需要修改\n1 services.gradle.org/distributions 为\n1 mirrors.cloud.tencent.com/gradle 重新下载 取消下载gradle 重新同步gradle 这时速度会比原来快很多\n运行程序 点击右上角的run app 运行成功，但是是在mumu模拟器上 添加虚拟设备 点击设备管理中的+号 选择创建设备 选择设备(我这里就选择Pixel 9) 点击完成 点击确定下载 安装完成后点击完成 选择刚添加的设备，再重新运行 运行成功 ","date":"2025-11-05T22:46:37+08:00","permalink":"https://YLine-hub.github.io/p/winandroidstudio%E5%AE%89%E8%A3%85/","title":"[WIn]AndroidStudio安装"},{"content":"MySQL进阶-存储引擎 MySQL体系结构 连接层 最上层是一些客户端和链接服务，主要完成一些类似于连接处理、授权认证、及相关的安全方案。服务器也会为安全接入的每个客户端验证它所具有的操作权限。\n服务层 第二层架构主要完成大多数的核心服务功能，如SQL接口，并完成缓存的查询，SQL的分析和优化，部分内置函数的执行。所有夸存储引擎的功能也在这一层实现，如 过程、函数等。\n引擎层 存储引擎真正的负责了MySQL中数据的存储和提取，服务器通过API和存储引擎进行通信。不同的存储引擎具有不同的功能，这样我们可以根据自己的需要，来选取合适的存储引擎。\n存储层 主要是将数据存储在文件系统之上，并完成与存储引擎的交互\n存储引擎简介 存储引擎就是存储数据、建立索引、更新/查询数据等技术的实现方式。存储引擎是基于表的，而不是基于库的，所以存储引擎也可被称为表类型。\n查询建表语句 1 2 show create table account -- 默认存存储引擎：InnoDB 选择存储引擎 在创建表时，指定存储引擎 1 2 3 4 5 CREATE TABLE 表名( 字段1 字段1类型 [COMMENT 字段1注释], ...... 字段n 字段n类型 [COMMENT 字段n注释] ) ENGINE=INNODB [COMMENT 表注释]; 查看当前数据库支持的存储引擎 1 SHOW ENGINES; 创建表 my_myisom ，并指定MyISM存储引擎 1 2 3 4 create table my_myisam( id int, name varchar(10) ) engine = MyISAM; 创建表 my_memory ，指定Memory存储引擎 1 2 3 4 create table my_memory( id int, name varchar(10) )engine = Memory; 存储引擎特点 InnoDB 介绍 InnoDB是一种兼顾高可靠性和高性能的通用存储引擎，在MySQL5.5之后，InnoDB是默认的MySQL存储引擎 特点 DML操作遵循ACID模型，支持事务； 行级锁，提高并发访问性能； 支持外键FOREIGN KEY约束，保证数据的完整性和正确性； 文件 xxx.ibd: xxx代表的是表名，innoDB引擎的每张表都会对应这样一个表空间文件，存储该表的表结构（frm、sdi）、数据和索引。 参数：innodb_file_per_table\n查看innodb_file_per_table参数\n1 2 show variables like \u0026#39;innodb_file_per_table\u0026#39;; -- innodb_file_per_table,ON 表示每一张表对应一个idb文件\n数据存储路径：\nD:\\ProgramData\\MySQL\\MySQL Server 8.0\\Data xxx.ibd： 存储的内容\n表结构 表存放的数据 索引 打开方式：cmd输入以下内容\n1 ibd2sdi xxxx.ibd 逻辑存储结构 MyISAM 介绍 MyISAM是MySQL早期的默认存储引擎 特点 不支持事务，不支持外键 支持表锁，不支持行锁 访问速度快 文件 xxx.sdi：存储表结构信息 xxx.MYD: 存储数据 xxx.MYI: 存储索引 查看 my_myisam_690.sdi 文件 直接使用记事本打开即可\n其中为json格式的代码，可以使用https://www.json.cn将其格式化\nMemory 介绍 Memmory引擎的表数据是存储在内存中的，由于收到硬件问题、或断电问题的影响，只能将这些表作为临时表或缓存使用。 特点 内存存放 hash索引（默认） 文件 xxx.sdi: 存储表结构信息 三大存储引擎区别 特点 InnoDB MyISAM Memory 存储限制 64TB 有 有 事务安全 支持 - - 锁机制 行锁 表锁 表锁 B+tree索引 支持 支持 支持 Hash索引 - - 支持 全文索引 支持(5.6版本之后) 支持 - 空间使用 高 低 N/A 内存使用 高 低 中等 批量插入速度 低 高 高 支持外键 支持 - - 存储引擎选择 在选择存储引擎时，应该根据应用系统的特点选择合适的存储引擎。对于复杂的应用系统，还可以根据实际情况选择多种存储引擎进行组合。\nInnoDB：是MySQL的默认存储引擎，支持事务、外键。如果应用对事务的完整性有比较高的要求，在并发条件下要求数据的一致性，数据操作除了插入和查询之外，还包含很多的更新、删除操作，那么InnoDB存储引擎是比较合适的选择。 MyISAM：如果应用是以读操作和插入操作为主，只有很少的更新和删除操作，并且对事务的完整性、并发性要求不是很高，那么选择这个存储引擎是非常合适的。 MEMORY：将所有数据保存在内存中，访问速度快，通常用于临时表及缓存。MEMORY的缺陷就是对表的大小有限制，太大的表无法缓存在内存中，而且无法保障数据的安全性。 ","date":"2025-11-05T22:46:07+08:00","permalink":"https://YLine-hub.github.io/p/mysqlmysql%E8%BF%9B%E9%98%B6-%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E/","title":"[MySQL]MySQL进阶-存储引擎"},{"content":"jemalloc jemalloc是一个malloc()碎片避免和可扩展的并发支持的实现。\n它旨在用作系统提供的内存分配器，如FreeBSD的libc库，以及链接到C / C ++应用程序。jemalloc提供了许多超出标准分配器功能的内省，内存管理和调优功能。\n安装jemalloc 安装环境 1 yum install -y automake autoconf libtool autoreconf bzip2 git make 下载源码 1 git clone https://github.com/jemalloc/jemalloc.git 我这里直接下载压缩包上传到服务器，解压 1 tar -jvxf jemalloc-5.3.0.tar.bz2 -C /usr/local/ 问题一 进入目录 1 cd /usr/local/jemalloc-5.3.0 生成构建文件 1 ./autogen.sh 配置编译选项 1 ./configure 编译并安装 1 2 make -j4 sudo make install mysql配置 创建mysql文件 1 vim /etc/sysconfig/mysql mysql 1 LD_PRELOAD=/usr/local/lib/libjemalloc.so.2 添加服务 创建服务文件 创建文件 1 vim /usr/lib/systemd/system/mysqld.service mysqld.service 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 [Unit] Description=MySQL Server Documentation=man:mysqld(8) Documentation=http://dev.mysql.com/doc/refman/en/using-systemd.html After=network.target After=syslog.target [Service] User=mysql Group=mysql Type=notify TimeoutSec=0 OOMScoreAdjust=-1000 ExecStart=/usr/local/mysql/bin/mysqld --defaults-file=/etc/my.cnf $MYSQLD_OPTS EnvironmentFile=-/etc/sysconfig/mysql LimitNOFILE = 65536 Restart=on-failure RestartPreventExitStatus=1 Environment=MYSQLD_PARENT_PID=1 PrivateTmp=false [Install] WantedBy=multi-user.target 启动服务 重新导入配置 1 systemctl daemon-reload 设置开机自启 1 systemctl enable mysqld 开启mysqld服务 1 systemctl start mysqld 移除服务 停止服务 1 sudo systemctl stop mysqld.service 禁用服务 1 systemctl disable mysqld.service 删除服务文件 1 rm /etc/systemd/system/mysqld.service 重新加载systemd配置 1 2 sudo systemctl daemon-reload sudo systemctl reset-failed 相关配置说明 TimeoutStartSec : \u0026ldquo;等待启动的时间。如果守护进程服务没有在配置的时间内发送启动完成的信号，则该服务将被认为失败， 服务将退出。\u0026rdquo;\nTimeoutStopSec : \u0026ldquo;等待关闭的超时时间\u0026rdquo;\nTimeoutSec : \u0026ldquo;快速配置TimeoutStartSec和TimeoutStopSec时间\u0026rdquo;。以秒为单位， “0”来禁用。默认为， 默认使用DefaultTimeoutStartSec。\nOOMScoreAdjust: \u0026ldquo;设置进程因内存不足而被杀死的优先级。可设为 -1000(禁止被杀死) 到 1000(最先被杀死)之间的整数值\u0026rdquo;\nEnvironmentFile: \u0026ldquo;指定配置文件，在目录前加\u0026rsquo;-\u0026rsquo;，作用是忽略文件不存在\u0026rdquo;\nLimitNOFILE : \u0026ldquo;设置进程最大文件描述符数量的参数\u0026rdquo;\n软限制(Soft Limit)：进程当前实际可用的文件描述符数量 硬限制(Hard Limit)：进程能够设置的最大文件描述符数量 LimitNOFILE = 65536\nLimitNOFILE = 65536:65536 # 软限制:硬限制\nRestartPreventExitStatus : \u0026ldquo;指定当服务以某些退出状态码退出时，不自动重启服务。退出状态码 1 通常表示\u0026quot;通用错误\u0026quot;或\u0026quot;操作不允许\u0026rdquo; \u0026quot;\nEnvironment=MYSQLD_PARENT_PID=1 : \u0026ldquo;设置环境变量，制定父进程PID为1 (systemd)\u0026rdquo;\nPrivateTmp : \u0026ldquo;私有临时目录\u0026rdquo;\n问题解决 问题一 原因：没有安装bzip2安装插件\n解决方法：安装bzip2插件\n1 yum install -y bzip2 ","date":"2025-11-05T20:55:48+08:00","permalink":"https://YLine-hub.github.io/p/linux%E4%BD%BF%E7%94%A8systemctl%E7%AE%A1%E7%90%86mysql/","title":"[Linux]使用systemctl管理mysql"},{"content":"MySQL基础-事务 事务简介 事务：是一组操作的集合，它是一个不可分割的工作单位，事务会把所有的操作作为一个整体一起向系统提交或撤销操作请求，即这些操作要么同时成功，要么同时失败。\n正常情况\n异常情况 回滚事务 默认MySQL的事务是自动提交的，也就是说，当执行一条DML语句，MySQL会立即隐式的提交事务。\n事务操作 数据准备 1 2 3 4 5 6 7 -- 数据准备 create table account( id int auto_increment primary key comment \u0026#39;主键ID\u0026#39;, name varchar(10) comment \u0026#39;姓名\u0026#39;, money int comment \u0026#39;余额\u0026#39; ) comment \u0026#39;账户表\u0026#39;; insert into account(id, name, money) values(null,\u0026#39;张三\u0026#39;,2000),(null,\u0026#39;李四\u0026#39;,2000); 模拟情况 正常情况 1 2 3 4 5 6 7 8 9 -- 转账操作 -- 1、查询张三余额 select * from account where name = \u0026#39;张三\u0026#39;; -- 2、将张三账户余额-1000 update account set money = money - 1000 where name = \u0026#39;张三\u0026#39;; -- 3、将李四账户余额+1000 update account set money = money + 1000 where name = \u0026#39;李四\u0026#39;; 恢复数据 1 update account set money = 2000 where name = \u0026#39;张三\u0026#39; or name = \u0026#39;李四\u0026#39;; 出现异常 1 2 3 4 5 6 7 8 9 10 11 -- 转账操作 -- 1、查询张三余额 select * from account where name = \u0026#39;张三\u0026#39;; -- 2、将张三账户余额-1000 update account set money = money - 1000 where name = \u0026#39;张三\u0026#39;; 程序抛出异常... -- 抛出异常后，程序应该自动提交事务 -- 3、将李四账户余额+1000 update account set money = money + 1000 where name = \u0026#39;李四\u0026#39;; 控制事务 查看/设置事务提交方式 1 2 3 4 5 -- 结果为1，表示自动提交 -- 结果为0，表示手动提交 SELECT @@autocommit; -- 设置事务为手动提交 SET @@autocommit = 0; 提交事务 1 COMMIT; 回滚事务 1 ROLLBACK; 开启事务 1 START TRANSACTION 或 BEGIN; 演示 方式一 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 -- 查看事务提交方式 select @@autocommit; -- 输出：1 -- 设置事务为手动提交 set @@autocommit = 0; -- ------------------------- 事务 ----------------------------- -- 转账操作 -- 1、查询张三余额 select * from account where name = \u0026#39;张三\u0026#39;; -- 2、将张三账户余额-1000 update account set money = money - 1000 where name = \u0026#39;张三\u0026#39;; -- 3、将李四账户余额+1000 update account set money = money + 1000 where name = \u0026#39;李四\u0026#39;; -- ------------------------- 事务 ----------------------------- -- 提交事务 commit; 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 -- ------------------------- 事务 ----------------------------- -- 转账操作 -- 1、查询张三余额 select * from account where name = \u0026#39;张三\u0026#39;; -- 2、将张三账户余额-1000 update account set money = money - 1000 where name = \u0026#39;张三\u0026#39;; 程序报错 ... -- 3、将李四账户余额+1000 update account set money = money + 1000 where name = \u0026#39;李四\u0026#39;; -- ------------------------- 事务 ----------------------------- -- 回滚事务 rollback; 方式二 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 -- 查看事务提交方式 select @@autocommit; -- 输出：0 -- 设置事务为自动提交 set @@autocommit = 1; -- 开启事务 start tansaction; -- ------------------------- 事务 ----------------------------- -- 转账操作 -- 1、查询张三余额 select * from account where name = \u0026#39;张三\u0026#39;; -- 2、将张三账户余额-1000 update account set money = money - 1000 where name = \u0026#39;张三\u0026#39;; 程序报错 ... -- 3、将李四账户余额+1000 update account set money = money + 1000 where name = \u0026#39;李四\u0026#39;; -- ------------------------- 事务 ----------------------------- -- 无异常 commit; -- 抛出异常 rollback; 四大特性ACID 事务的四大特性\n原子性（Atomicity）：事务是不可分割的最小操作单位，要么全部成功，要么全部失败。 一致性（Consistency）：事务完成时，必须使所有的数据都保持一致状态。 隔离性（Isolation）：数据库系统提供的隔离机制，保证事务在不受外部并发操作影响的独立环境下运行。 持久性（Durability）：事务一旦提交或回滚，它对数据库中的数据的改变就是永久的。 查看mysql数据存储位置命令\n1 show variables like \u0026#39;%datadir%\u0026#39;; 我的MySQL存储路径：D:\\ProgramData\\MySQL\\MySQL Server 8.0\\Data\n并发事务问题 问题 描述 脏读 一个事务读到另外一个事务还没有提交的数据。 不可重复读 一个事务先后读取同一条记录，但两次读取的数据不同，称之为不可重复读。 幻读 一个事务按照条件查询数据时，没有对应的数据行，但是在插入数据时，又发现这行数据已经存在，好像出现了“幻影”。 脏读 B事务读取到了A事务还没有提交的数据。\n不可重复读 A事务两次读取id为1的数据中间，B事务修改了id为1的数据。导致A事务两次读取的数据不同。\n幻读 A事务读取时，发现id为1的数据不存在，然后执行插入id为1的数据，但这个同时B事务也插入了id为1的数据，导致A事务插入失败，但是又解决了不可重复读，所以A事务与B事务的插入都失败了。A事务再次读取时发现id为1的数据不存在。\n事务隔离级别 隔离级别 脏读 不可重复读 幻读 Read uncommitted √ √ √ Read committed × √ √ Repeatable Read(默认) × × √ Serializable × × × 查看事务隔离级别 1 SELECT @@TRANSACTION_ISOLATION; 设置事务隔离级别 1 SET [SESSION|GLOBAL] TRANSACTION ISOLATION LEVEL {READ UNCOMMITTED|READ COMMITTED|REPEATABLE READ|SERIALIZABLE} 注意：事务隔离级别越高，数据越安全，但是性能越低\n演示 脏读 打开两个命令行窗口进入mysql进行演示\ncmd1:设置隔离级别为read uncommitted\n1 set session transaction isolation level read uncommitted; cmd1:开启事务 1 start transaction; cmd2:开启事务 1 start transaction; cmd1:查询账户 1 select * from account; cmd2:修改账户余额 1 update account set money = money - 1000 where name = \u0026#39;张三\u0026#39;; cmd1:再次查看账户余额 1 select * from account; 此时cmd2事务的数据还未提交，但是cmd1事务查看的数据已经修改了。 也可以说，cmd1事务能看到cmd2事务未提交的数据。\ncmd2:提交数据 1 commit; cmd1:再次查看账户余额 1 select * from account; 数据无变化\ncmd1:提交事务，结束事务 1 commit; cmd1:设置隔离级别为Read committed 1 set session transaction isolation level read committed; cmd1:开启事务 1 start transaction; cmd1:查询账户余额 1 select * from account; cmd2:开启事务 1 start transaction; cmd2:张三余额再减1000 1 update account set money = money - 1000 where name = \u0026#39;张三\u0026#39;; cmd1:查询余额 1 select * from account; cmd1事务查询的余额不变\ncmd2:提交事务 1 commit; cmd1:查询余额 1 select * from account; 此时余额变化了\ncmd1:结束事务 1 commit; 不可重复读 延续脏读的数据\ncmd1:开启事务\n1 start transaction; cmd2:开启事务 1 start transaction; cmd1:查询余额 1 select * from account; cmd2:张三增加余额1000 1 update account set money = money + 1000 where name = \u0026#39;张三\u0026#39;; cmd1:查询余额 1 select * from account; 此时余额无变化\ncmd2:提交事务 1 commit; cmd1:查询余额 1 select * from account; 此时可以看到余额变化了，但是cmd1这几次查询余额都处于一个事务内，在这个事务内，数据发生变化，也叫做不可重复读。\ncmd1:结束事务 1 commit; cmd1:设置隔离级别repeatable read 1 set session transaction isolation level repeatable read; cmd1:开启事务 1 start transaction; cmd2:开启事务 1 start transaction; cmd1:查询余额 1 select * from account; cmd2:张三余额增加1000 1 update account set money = money + 1000 where name = \u0026#39;张三\u0026#39;; cmd2:提交事务 1 commit; cmd1:查询余额 1 select * from account; 此时数据没有变化\ncmd1:提交事务 1 commit; cmd1:查询余额 1 select * from account; 此时张三的余额增加了1000\n幻读 cmd1:开启事务 1 start transaction; cmd2:开启事务 1 start transaction; cmd1:查询id为3的数据 1 select * from account where id = 3; cmd2:插入id为3的数据 1 insert into account(id,name,money) values(3,\u0026#39;王五\u0026#39;,2000); cmd2:提交事务 1 commit; cmd1:插入id为3的数据 1 insert into account(id,name,money) values(3,\u0026#39;大刀王五\u0026#39;,2000); 此时报错：显示id已经存在\ncmd1:查新id为3的数据 1 select * from account where id = 3; 但是还是没有id为3的数据。\ncmd1:结束事务 1 commit; cmd1:设置隔离级别为serializable 1 set session transaction isolation level serializable; cmd1:开启事务 1 start transaction; cmd2:开启事务 1 start transaction; cmd1:查询余额 1 select * from account; cmd1:查询id为4的数据 1 select * from account where id = 4; 目前没有id为4的数据\ncmd2:插入id为4的数据 1 insert into account(id,name,money) values(4,\u0026#39;赵六\u0026#39;,2000); 此时命令行卡在这里不会继续向下运行，需要等待cmd1提交事务\ncmd1:插入id为4的数据 1 insert into account(id,name,money) values(4,\u0026#39;大刀赵六\u0026#39;,2000); cmd1:提交事务 1 commit; cmd1事务提交后，cmd2的事务才继续向下执行，显示已经有id为4的数据了。\ncmd2:提交事务 1 commit; 生词 serializable / ˈsɪˌriəˌlaɪzəbl / adj、可串行化的；序列化的 isolation / ˌaɪsəˈleɪʃn / n、隔离，孤立 repeatable / rɪˈpiːtəbl / adj、可重复的； ","date":"2025-11-04T21:40:36+08:00","permalink":"https://YLine-hub.github.io/p/mysqlmysql%E5%9F%BA%E7%A1%80-%E4%BA%8B%E5%8A%A1/","title":"[MySQL]MySQL基础-事务"},{"content":"使用web链接打包apk 准备工具 Android Studio 安装android studio 安装教程：[WIn]AndroidStudio安装 打包 项目地址 github1(打包项目): webapp\ngithub2(被打包的web项目): circuitjs1\n环境要求 gradle 6.5 jdk 1.8 Android SDK 29 步骤 克隆导入项目 克隆git项目 1 git clone https://github.com/wskang12138/webapp.git 用android studio打开项目 修改gradle镜像源 若下载gradle速度过慢或者下载gradle报错\n打开gradle-wrapper.properties\n修改distributionUrl 1 distributionUrl=https\\://mirrors.cloud.tencent.com/gradle/gradle-6.5-bin.zip 点击上方的Try Again，重新同步gradle 修改Jdk版本 报错显示 1 java.lang.IllegalArgumentException: Unsupported class file major version 65 点击 File -\u0026gt; Settings... 选择Build, Execution, Deployment-\u0026gt;Build Tools-\u0026gt;Gradle 修改Gradle JDK 这里我改成1.8.0_301版本\n点击Apply，再点击Ok 点击File-\u0026gt;Sync Project with Gradle Files 安装SDK 29版本 出现新的报错信息 1 Failed to find Build Tools revision 29.0.2 点击File-\u0026gt;Settings... 选择Languages \u0026amp; Frameworkd-\u0026gt;Android SDK 在SDK Platforms下选择API Level为29的，然后点击Apply 点击OK 等待安装SDK 安装完成后点击Finish 点击Apply-\u0026gt;OK 点击File-\u0026gt;Sync Project with Gradle Files 安装SDK Tools 29版本 点击File-\u0026gt;Settings... 选择Languages \u0026amp; Frameworkd-\u0026gt;Android SDK 点击SDK Tools，并且将Show Package Details打勾 选择29.0.2版本，并点击Apply 点击确定 等待安装 点击完成 点击应用并确定 运行程序 修改网址地址 打开app-\u0026gt;java-\u0026gt;com.example.app-\u0026gt;MainActivity 将url改成自己要打包的网址地址 修改包名 此时发现有报错信息 1 Package name \u0026#39;com.wekanapp.app\u0026#39; does not correspond to the file path \u0026#39;com.example.app\u0026#39; 包名应该叫com.wekanapp.app而不是com.example.app\n关闭Android Studio(程序打开期间，无法修改文件夹名称)\n找到example文件夹\n路径：D:\\ylline\\code\\webapp\\app\\src\\main\\java\\com\n修改成wekanapp 清理缓存并重启 再次打开Android Studio\n此时发现com文件夹下面没有文件了\n点击File-\u0026gt;Invalidate Caches... 点击Invalidate and Restart 重启后文件就出来了 修改hostname 打开MyWebViewClient 修改hostname(随意取)，原本的是wekanapp.com(网站一级域名) 修改app名称 打开strings.xml文件 修改app名称 修改app图标(png) 原图标所在位置 右键图标-\u0026gt;Open in-\u0026gt;Explorer 这是其中一个图标所在位置 点击上级目录res 这五个文件夹里面都有一样的文件，其中图标分辨率为114x114 在所有文件夹中都放一个我选择的图标 此时mipmap目录下出现了我放的图片 打开AndroidManifest.xml文件 找到android:icon=\u0026quot;@mipmap/ic_launcher\u0026quot;行 修改成自己的图标名 1 android:icon=\u0026#34;@mipmap/icon\u0026#34; 此时前面的图标，也显示了自己的图标\n生成keystore 在java的bin目录下用cmd运行以下代码(如果环境变量里有java/bin目录可以在任何目录下生成)\n查看java环境(要求1.8)\n1 java -version keystore生成代码 1 keytool -genkey -alias test -keyalg RSA -keysize 2048 -validity 36500 -keystore test.keystore 其中alias为test，生成的文件名为test.keystore\n输入密码 这里输入密码，不会显示\n重新输入密码（与上个输入的密码相同） 输入姓名（必填） 剩下的都选填项，我这里就都不填了 确定所填是否正确，确定的话填y，再回车 输入test(alias)的密码，如果和密钥库密码相同直接回车就行 我这里直接回车了\n这段话出来表示已经生成了\n打开C:\\Users\\yline目录 在目录下找到test.keystore 将其复制或者剪切到项目目录下 原先有一个就直接将其覆盖即可\n打包apk 选择Build-\u0026gt;Generate Signed App Bundle or APK... 选择APK，然后点击Next 选择Key store 路径 分别输入密钥库密码，alias和alias的密码 然后点击Next 选择release，然后点击Create 打包成功 包目录所在位置 1 D:\\ylline\\code\\webapp\\app\\release 运行apk 打开设备管理，并点击运行虚拟设备 虚拟设备启动后直接将apk包拖进设备中即可 运行界面 翻译 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 C:\\Users\\yline\u0026gt;keytool -genkey -alias test -keyalg RSA -keysize 2048 -validity 36500 -keystore test.keystore キーストアのパスワードを入力してください: 新規パスワードを再入力してください: 姓名は何ですか。 [Unknown]: yline 組織単位名は何ですか。 [Unknown]: 組織名は何ですか。 [Unknown]: 都市名または地域名は何ですか。 [Unknown]: 都道府県名または州名は何ですか。 [Unknown]: この単位に該当する2文字の国コードは何ですか。 [Unknown]: CN=yline, OU=Unknown, O=Unknown, L=Unknown, ST=Unknown, C=Unknownでよろしいですか。 [いいえ]: y \u0026lt;test\u0026gt;のキー?パスワードを入力してください (キーストアのパスワードと同じ場合はRETURNを押してください): Warning: JKSキーストアは独自の形式を使用しています。\u0026#34;keytool -importkeystore -srckeystore test.keystore -destkeystore test.keystore -deststoretype pkcs12\u0026#34;を使用する業界標準の形式であるPKCS12に移行することをお薦めします。 生词 キース：钥匙 キーストア：密钥库 パスワード：password 密码 入力(にゅうりょく)：输入 新規(ぃんき)：重新做 ","date":"2025-11-04T21:38:30+08:00","permalink":"https://YLine-hub.github.io/p/android%E4%BD%BF%E7%94%A8web%E9%93%BE%E6%8E%A5%E6%89%93%E5%8C%85%E6%88%90apk/","title":"[Android]使用web链接打包成apk"},{"content":"快捷键(win) 文本操作 shift + enter : 光标跳转到下一行 选中一行 先按下home，光标跳转到行首，然后按下shift+end 先按下end，光标跳转到行尾，然后按下shift+home 选中多行 先按下home，光标跳转到行首，然后shift+↓或shift+↑，不断移动选择多行 ","date":"2025-11-02T21:34:14+08:00","permalink":"https://YLine-hub.github.io/p/idea%E4%BD%BF%E7%94%A8%E6%94%BB%E7%95%A5/","title":"[IDEA]使用攻略"},{"content":"多表查询 多表关系 项目开发中，在进行数据库表结构设计时，会根据业务需求及业务模块之间的关系，分析并设计表结构，由于业务之间相互关联，所以各个表结构之间也存在着各种联系，基本上分三种：\n一对多(多对一) 多对多 一对一 一对多(多对一) 案例：部门 与 员工的关系 关系：一个部门对应多个员工，一个员工对应一个部门 实现：在多的一方建立外键，指向一的一方的主键 多对多 案例：学生 与 课程的关系 关系：一个学生可以选修多门课程，一门课程也可以供多个学生选择 实现：建立第三张中间表，中间表至少包含两个外键，分别关联两方主键 演示 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 ----------------------------------------------------------- 多对多 -------------------------------------------------------- create table student( id int auto_increment primary key comment \u0026#39;主键ID\u0026#39;, name varchar(10) comment \u0026#39;姓名\u0026#39;, no varchar(10) comment \u0026#39;学号\u0026#39; ) comment \u0026#39;学生表\u0026#39;; insert into student values(null,\u0026#39;黛绮丝\u0026#39;,\u0026#39;2000100101\u0026#39;),(null,\u0026#39;谢逊\u0026#39;,\u0026#39;2000100102\u0026#39;),(null,\u0026#39;殷天正\u0026#39;,\u0026#39;2000100103\u0026#39;),(null,\u0026#39;韦一笑\u0026#39;,\u0026#39;2000100104\u0026#39;); create table course( id int auto_increment primary key comment \u0026#39;主键ID\u0026#39;, name varchar(10) comment \u0026#39;课程名称\u0026#39; ) comment \u0026#39;课程表\u0026#39;; insert into course values(null,\u0026#39;Java\u0026#39;),(null,\u0026#39;PHP\u0026#39;),(null,\u0026#39;MySQL\u0026#39;),(null,\u0026#39;Hadoop\u0026#39;); create table student_course( id int auto_increment comment \u0026#39;主键\u0026#39; primary key, studentid int not null comment \u0026#39;学生ID\u0026#39;, courseid int not null comment \u0026#39;课程ID\u0026#39;, constraint fk_courseid foreign key (courseid) references course(id), constraint fk_studentid foreign key (studentid) references student(id) ) comment \u0026#39;学生课程中间表\u0026#39;; insert into student_course values(null,1,1),(null,1,2),(null,1,3),(null,2,2),(null,2,3),(null,3,4); 右键点击学生课程中间表，选择Diagrams-\u0026gt;Show Diagram... 一对一 案例：用户 与 用户详情的关系 关系：一对一关系，多用于单表拆分，将一张表的基础字段放在一张表中，其他详情字段放在另一张表中，以提升操作效率 实现：在任意一方加入外键，关联另外一方的主键，并且设置外键为唯一的(UNIQUE) 拆分为两个表 建立外键实现约束 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 -------------------------------- 一对一 ----------------------------- create table tb_user( id int auto_increment primary key comment \u0026#39;主键ID\u0026#39;, name varchar(10) comment \u0026#39;姓名\u0026#39;, age int comment \u0026#39;年龄\u0026#39;, gender char(1) comment \u0026#39;1: 男，2: 女\u0026#39;, phone char(11) comment \u0026#39;手机号\u0026#39; )comment \u0026#39;用户基本信息表\u0026#39;; create table tb_user_edu( id int auto_increment primary key comment \u0026#39;主键ID\u0026#39;, degree varchar(20) comment \u0026#39;学历\u0026#39;, major varchar(50) comment \u0026#39;专业\u0026#39;, primaryschool varchar(50) comment \u0026#39;小学\u0026#39;, middleschool varchar(50) comment \u0026#39;中学\u0026#39;, university varchar(50) comment \u0026#39;大学\u0026#39;, userid int unique comment \u0026#39;用户ID\u0026#39;, constraint fk_userid foreign key (userid) references tb_user(id) )comment \u0026#39;用户教育信息表\u0026#39;; insert into tb_user(id,name,age,gender,phone) values (null,\u0026#39;黄渤\u0026#39;,45,\u0026#39;1\u0026#39;,\u0026#39;18800001111\u0026#39;), (null,\u0026#39;冰冰\u0026#39;,35,\u0026#39;2\u0026#39;,\u0026#39;18800002222\u0026#39;), (null,\u0026#39;码云\u0026#39;,55,\u0026#39;1\u0026#39;,\u0026#39;18800008888\u0026#39;), (null,\u0026#39;李彦宏\u0026#39;,50,\u0026#39;1\u0026#39;,\u0026#39;18800009999\u0026#39;); insert into tb_user_edu(id,degree,major,primaryschool,middleschool,university,userid) values (null,\u0026#39;本科\u0026#39;,\u0026#39;舞蹈\u0026#39;,\u0026#39;静安区第一小学\u0026#39;,\u0026#39;静安区第一中学\u0026#39;,\u0026#39;北京舞蹈学院\u0026#39;,1), (null,\u0026#39;硕士\u0026#39;,\u0026#39;表演\u0026#39;,\u0026#39;朝阳区第一小学\u0026#39;,\u0026#39;朝阳区第一中学\u0026#39;,\u0026#39;北京电影学院\u0026#39;,2), (null,\u0026#39;本科\u0026#39;,\u0026#39;英语\u0026#39;,\u0026#39;杭州市第一小学\u0026#39;,\u0026#39;杭州市第一中学\u0026#39;,\u0026#39;杭州师范大学\u0026#39;,3), (null,\u0026#39;本科\u0026#39;,\u0026#39;应用数学\u0026#39;,\u0026#39;阳泉区第一小学\u0026#39;,\u0026#39;阳泉区第一中学\u0026#39;,\u0026#39;清华大学\u0026#39;,4); 概述 从多张表中查询数据 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 -- 删除并重新创建emp和dept表 create table dept( id int auto_increment comment \u0026#39;ID\u0026#39; primary key, name varchar(50) not null comment \u0026#39;部门名称\u0026#39; )comment \u0026#39;部门表\u0026#39;; insert into dept(id,name) values(1,\u0026#39;研发部\u0026#39;),(2,\u0026#39;市场部\u0026#39;),(3,\u0026#39;财务部\u0026#39;),(4,\u0026#39;销售部\u0026#39;),(5,\u0026#39;总经办\u0026#39;); create table emp( id int auto_increment comment \u0026#39;ID\u0026#39; primary key, name varchar(50) not null comment \u0026#39;姓名\u0026#39;, age int comment \u0026#39;年龄\u0026#39;, job varchar(20) comment \u0026#39;职位\u0026#39;, salary int comment \u0026#39;薪资\u0026#39;, entrydate date comment \u0026#39;入职时间\u0026#39;, managerid int comment \u0026#39;直属领导ID\u0026#39;, dept_id int comment \u0026#39;部门ID\u0026#39; ) comment \u0026#39;员工表\u0026#39;; -- 删除并重新创建emp和dept表 alter table emp drop foreign key fk_emp_dept_id; truncate table dept; truncate table emp; -- 插入数据 insert into dept(id,name) values(1,\u0026#39;研发部\u0026#39;),(2,\u0026#39;市场部\u0026#39;),(3,\u0026#39;财务部\u0026#39;),(4,\u0026#39;销售部\u0026#39;),(5,\u0026#39;总经办\u0026#39;); insert into emp(id,name,age,job,salary,entrydate,managerid,dept_id) values (1,\u0026#39;金庸\u0026#39;,66,\u0026#39;总裁\u0026#39;,20000,\u0026#39;2000-01-01\u0026#39;,null,5), (2,\u0026#39;张无忌\u0026#39;,20,\u0026#39;项目经理\u0026#39;,12500,\u0026#39;2005-12-05\u0026#39;,1,1), (3,\u0026#39;杨逍\u0026#39;,33,\u0026#39;开发\u0026#39;,8400,\u0026#39;2000-11-03\u0026#39;,2,1), (4,\u0026#39;韦一笑\u0026#39;,48,\u0026#39;开发\u0026#39;,11000,\u0026#39;2002-02-05\u0026#39;,2,1), (5,\u0026#39;常遇春\u0026#39;,43,\u0026#39;开发\u0026#39;,10500,\u0026#39;2004-09-07\u0026#39;,3,1), (6,\u0026#39;小昭\u0026#39;,19,\u0026#39;程序员鼓励师\u0026#39;,6600,\u0026#39;2004-10-12\u0026#39;,2,1), (7,\u0026#39;灭绝\u0026#39;,60,\u0026#39;财务总监\u0026#39;,8500,\u0026#39;2002-09-12\u0026#39;,1,3), (8,\u0026#39;周芷若\u0026#39;,19,\u0026#39;会计\u0026#39;,48000,\u0026#39;2006-06-02\u0026#39;,7,3), (9,\u0026#39;丁敏君\u0026#39;,23,\u0026#39;出纳\u0026#39;,5250,\u0026#39;2009-05-13\u0026#39;,7,3), (10,\u0026#39;赵敏\u0026#39;,20,\u0026#39;市场部总监\u0026#39;,12500,\u0026#39;2004-10-12\u0026#39;,1,2), (11,\u0026#39;鹿杖客\u0026#39;,56,\u0026#39;职员\u0026#39;,3750,\u0026#39;2006-10-03\u0026#39;,10,2), (12,\u0026#39;鹤笔翁\u0026#39;,19,\u0026#39;职员\u0026#39;,3750,\u0026#39;2007-05-9\u0026#39;,10,2), (13,\u0026#39;方东白\u0026#39;,19,\u0026#39;职员\u0026#39;,5500,\u0026#39;2009-02-12\u0026#39;,10,2), (14,\u0026#39;张三丰\u0026#39;,88,\u0026#39;销售总监\u0026#39;,14000,\u0026#39;2004-10-12\u0026#39;,1,4), (15,\u0026#39;俞莲舟\u0026#39;,38,\u0026#39;销售\u0026#39;,4600,\u0026#39;2004-10-12\u0026#39;,14,4), (16,\u0026#39;宋远桥\u0026#39;,40,\u0026#39;销售\u0026#39;,4600,\u0026#39;2004-10-12\u0026#39;,14,4), (17,\u0026#39;陈友谅\u0026#39;,42,null,2000,\u0026#39;2011-10-12\u0026#39;,1,null); 1 2 3 4 -- 单表查询 select * from emp; -- 多表查询 -- 笛卡尔积 select * from emp,dept; 笛卡尔积：笛卡尔乘积是指在数学中，两个集合A集合和B集合的所有组合情况。（在多表查询时，需要消除无效的笛卡尔积） 消除无效的笛卡尔积 1 select * from emp, dept where emp.dept_id = dept.id; 多表查询分类 连接查询\n内连接：相当于查询A、B交集部分数据 外连接： 左外连接：查询左表所有数据，以及两张表交集部分数据 右外连接：查询右表所有数据，以及两张表交集部分数据 自连接：当前表与自身的连接查询，自连接必须使用表别名 子查询\n内连接 内连接查询语法 隐式内连接\n1 SELECT 字段列表 FROM 表1,表2 WHERE 条件...; 显式内连接\n1 SELECT 字段列表 FROM 表1 [INNER] JOIN 表2 ON 连接条件...; 内连接查询的时两张表的交集部分\n演示 查询每一个员工的姓名，及关联的部门的名称（隐式内连接实现） 1 2 3 4 -- 没使用别名 select emp.name ,dept.name from emp, dept where emp.dept_id = dept.id; -- 使用别名（注意：from后面使用别名后，select 和 where后面就只能使用别名） select e.name ,d.name from emp e, dept d where e.dept_id = d.id; 查询每一个员工的姓名，及关联的部门的名称（显式内连接实现） 1 2 3 4 -- 不省略inner select e.name ,d.name from emp e inner join dept d on e.dept_id = d.id; -- 省略inner select e.name ,d.name from emp e join dept d on e.dept_id = d.id; 外连接 外连接查询语法 左外连接\n1 SELECT 字段列表 FROM 表1 LEFT [OUTER] JOIN 表2 ON 条件...; 相当于查询表1(左表)的所有数据包含表1和表2交集部分的数据\n右外连接\n1 SELECT 字段列表 FROM 表1 RIGHT [OUTER] JOIN 表2 ON 条件...; 相当于查询表2(右表)的所有数据包含表1和表2交集部分的数据\n演示 查询emp表的所有数据，和对应的部门信息（左外连接） 1 2 3 4 -- 不省略outer select e.*,d.name from emp e left outer join dept d on e.dept_id = d.id; -- 省略outer select e.*,d.name from emp e left join dept d on e.dept_id = d.id; 查询dept表的所有数据，和对应的员工信息（右外连接） 1 2 3 4 -- 不省略outer select d.*, e.* from emp e right outer join dept d on e.dept_id = d.id; -- 省略outer select d.*, e.* from emp e right join dept d on e.dept_id = d.id; 自连接 自连接查询语法 1 SELECT 字段列表 FROM 表A 别名A JOIN 表A 别名B ON 条件...; 自连接查询，可以时内连接查询，也可以是外连接查询。\n演示 查询员工 及其 所属领导的名字 1 select a.name, b name from emp a, emp b where a.managerid = b.id; 查询所有员工 emp 及其领导的名字 emp。如果员工没有领导，也需要查询出来 1 select a.name \u0026#39;staff\u0026#39;, b.name \u0026#39;leader\u0026#39; from emp a left join emp b on a.managerid = b.id; 联合查询 对于union查询，就是把多次查询的结果合并起来，形成一个新的查询结果集。 联合查询语法 关键词：union，union all 1 2 3 SELECT 字段列表 FROM 表A ... UNION [ALL] SELECT 字段列表 FROM 表B ...; 对于联合查询的多张表的列数必须保持一致 union all 会将全部的数据直接合并在一起，union会对合并之后的数据去重 演示 将薪资低于5000的员工，和年龄大于50岁的员工全部查询出来 1 2 3 4 -- union all 是直接将查询的结果合并 select * from emp where salary \u0026lt; 5000 union all select * from emp where age \u0026gt; 50; 1 2 3 4 -- union 是将查询的结果合并后，去重 select * from emp where salary \u0026lt; 5000 union select * from emp where age \u0026gt; 50; 子查询 介绍 概念：SQL语句中嵌套SELECT语句，称为嵌套查询，又称子查询。 1 SELECT * FROM t1 WHERE column1 = (SELECT column1 FROM t2); 子查询外部的语句可以使INSERT/UPDATE/DELETE/SELECT的任何一个\n根据子查询结果不同，分为：\n标量子查询(子查询结果为单个值) 列子查询(子查询结果为一列) 行子查询(子查询结果为一行) 表子查询(子查询结果为多行多列) 根据子查询位置，分为：\nWHERE之后 FROM之后 SELECT之后 标量子查询 子查询返回的结果是单个值(数字、字符串、日期等)，最简单的形式，这种子查询称为标量子查询。\n常用的操作符：=、\u0026lt;\u0026gt;、\u0026gt;、\u0026gt;=、\u0026lt;、\u0026lt;=\n演示 查询“销售部”的所有员工信息 1 2 3 4 -- 查询“销售部”部门ID select id from dept where name = \u0026#39;销售部\u0026#39;; -- 根据“销售部”部门ID，查询员工信息 select * from emp where dept_id = (select id from dept where name = \u0026#39;销售部\u0026#39;); 查询在“方东白”入职之后的员工信息 1 2 3 4 -- 查询“方东白”的入职日期 select entrydate from emp where name = \u0026#39;方东白\u0026#39;; -- 根据“方东白”的入职日期，查询员工信息 select * from emp where entrydate \u0026gt; (select entrydate from emp where name = \u0026#39;方东白\u0026#39;); 列子查询 子查询返回的结果是一列（可以是多行），这种子查询称为列子查询。 常用的操作符：IN、NOT IN、ANY、SOME、ALL 操作符 描述 IN 在指定的集合范围之内，多选一 NOT IN 不在指定的集合范围之内 ANY 子查询返回列表中，有任意一个满足即可 SOME 与ANY等同，使用SOME的地方都可以使用ANY ALL 子查询返回列表的所有值都必须满足 演示 查询“销售部”和“市场部”的所有员工信息 1 2 3 4 -- 查询“销售部”和“市场部”的部门ID select id from dept where name = \u0026#39;销售部\u0026#39; or name = \u0026#39;市场部\u0026#39;; -- 根据部门ID，查询员工信息 select * from emp where dept_id in (select id from dept where name = \u0026#39;销售部\u0026#39; or name = \u0026#39;市场部\u0026#39;); 查询比财务部所有人工资都高的员工信息 1 2 3 4 5 6 -- 查询“财务部”的部门ID select id from dept where name = \u0026#39;财务部\u0026#39;; -- 查询“研发部”所有人员的工资 select salary from emp where dept_id = (select id from dept where name = \u0026#39;财务部\u0026#39;); -- 查询比“财务部”所有人工资都高的员工信息 select * from emp where salary \u0026gt; all (select salary from emp where dept_id = (select id from dept where name = \u0026#39;财务部\u0026#39;)); 查询比研发部其中任意一人工资高的员工信息 1 2 3 4 5 6 -- 查询“研发部”的部门ID select id from dept where name = \u0026#39;研发部\u0026#39;; -- 查询“研发部”所有人员的工资 select salary from emp where dept_id = (select id from dept where name = \u0026#39;研发部\u0026#39;); -- 查询比“研发部”任意一人工资高的员工信息（这里可以用any或者some） select * from emp where salary \u0026gt; any (select salary from emp where dept_id = (select id from dept where name = \u0026#39;研发部\u0026#39;)); 行子查询 子查询返回的结果是一行（可以是多列），这种子查询称为行子查询。 常用操作符：=、\u0026lt;\u0026gt;、IN、NOT IN 演示 查询与“张无忌”的薪资及直属领导相同的员工信息 1 2 3 4 5 6 -- 查询“张无忌”的薪资及直属领导的id select salary,managerid from emp where name = \u0026#39;张无忌\u0026#39;; -- 查询与“张无忌”的薪资及直属领导相同的员工信息 select * from emp where salary = 12500 and managerid = 1; select * from emp where (salary,managerid) = (12500,1); select * from emp where (salary,managerid) = (select salary,managerid from emp where name = \u0026#39;张无忌\u0026#39;); 表子查询 子查询返回的结果是多行多列，这种子查询称为表子查询 常用操作符：IN 演示 查询与“鹿杖客”，“宋远桥”的职位和薪资相同的员工信息 1 2 3 4 -- 查询“鹿杖客”和“宋远桥”的职位和薪资 select job,salary from emp where name = \u0026#39;鹿杖客\u0026#39; or name = \u0026#39;宋远桥\u0026#39;; -- 查询与“鹿杖客”和“宋远桥”的职位和薪资相同的员工信息 select * from emp where (job,salary) in (select job,salary from emp where name = \u0026#39;鹿杖客\u0026#39; or name = \u0026#39;宋远桥\u0026#39;); 查询入职日期是“2006-01-01”之后的员工信息，及其部门信息 1 2 3 4 -- 入职日期是“2006-01-01”之后的员工信息 select * from emp where entrydate \u0026gt; \u0026#39;2006-01-01\u0026#39;; -- 查询这部分员工，对应的部门信息 select e.*, d.* from (select * from emp where entrydate \u0026gt; \u0026#39;2006-01-01\u0026#39;) e left join dept d on e.dept_id = d.id; 案例 新增薪资等级表 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 create table salgrade( grade int, losal int, hisal int ) comment \u0026#39;薪资等级表\u0026#39;; insert into salgrade values (1,0,3000), (2,3001,5000), (3,5001,8000), (4,8001,10000), (5,10001,15000), (6,15001,20000), (7,20001,25000), (8,25001,30000); 练习 查询员工的姓名、年龄、职位、部门信息(隐式内连接) 1 select e.name,e.age,e.job,d.name from emp e,dept d where e.dept_id = d.id; 查询年龄小于30岁的员工姓名、年龄、职位、部门信息(显示内连接) 1 select e.name, e.age, e.job, d.name from emp e inner join dept d on e.dept_id = d.id where e.age \u0026lt; 30; 查询拥有员工的部门ID、部门名称 1 2 -- 去重关键词：distinct select distinct d.id, d.name from emp e,dept d where e.dept_id = d.id; 查询所有年龄大于40岁的员工，及其归属的部门名称；如果员工没有分配部门，也需要展示出来 1 select e.*, d.name from emp e left join dept d on e.dept_id = d.id where age \u0026gt; 40; 查询所有员工的工资等级 1 2 3 4 5 -- 表：emp , salgrade -- 连接条件：emp.salary \u0026gt;= salgrade.losal and emp.salary \u0026lt;= salgrade.hisal select e.* , s.* from emp e,salgrade s where e.salary \u0026gt;= s.losal and e.salary \u0026lt;= s.hisal; select e.* , s.* from emp e,salgrade s where e.salary between s.losal and s.hisal; 查询“研发部”所有员工的信息及工资等级 1 2 3 4 -- 表：emp，salgrade，dept -- 连接条件：emp.salary between salgrade.losal and salgrade.hisal , emp.dept_id = dept.id -- 查询条件：dept.name = \u0026#39;研发部\u0026#39; select e.*, s.*, d.name from emp e, dept d, salgrade s where e.dept_id = d.id and (e.salary between s.losal and s.hisal) and d.name = \u0026#39;研发部\u0026#39;; 查询“研发部”员工的平均工资 1 2 3 4 -- 表：emp，dept -- 连接条件：emp.dept_id = dept.id -- 查询条件：dept.name = \u0026#39;研发部\u0026#39; select avg(e.salary) from emp e,dept d where e.dept_id = d.id and d.name = \u0026#39;研发部\u0026#39;; 查询工资比“灭绝”高的员工信息 1 2 3 4 -- 查询“灭绝”的薪资 select salary from emp where name = \u0026#39;灭绝\u0026#39;; -- 查询比“灭绝”工资高的员工信息 select * from emp where salary \u0026gt; (select salary from emp where name = \u0026#39;灭绝\u0026#39;); 查询比平均薪资高的员工信息 1 2 3 4 -- 查询平均薪资 select avg(salary) from emp; -- 查询薪资比平均薪资高的员工信息 select * from emp where salary \u0026gt; (select avg(salary) from emp); 查询低于本部门平均工资的员工信息(重点) 1 2 3 4 5 6 7 8 9 10 -- 表：emp，dept -- 查询各个部门的平均薪资 select avg(e1.salary) from emp e1 where e1.dept_id = 1; -- 部门1 select avg(e1.salary) from emp e1 where e1.dept_id = 2; -- 部门2 -- 查询低于本部门平均薪资的员工信息 select * from emp e2 where e2.salary \u0026lt; \u0026#39;薪资\u0026#39;; -- 查询低于本部门平均薪资的员工信息 select *,(select avg(e1.salary) from emp e1 where e1.dept_id = e2.dept_id) as avg_sal from emp e2 where e2.salary \u0026lt; (select avg(e1.salary) from emp e1 where e1.dept_id = e2.dept_id); 查询所有的部门信息，并统计部门的员工人数(重点) 1 2 3 4 5 6 7 8 -- 查询所有部门的信息 select id, name, id \u0026#39;人数\u0026#39; from dept; -- 统计各个部门的员工人数 select count(*) from emp where dept_id = 1; -- 统计所有部门的员工人数 select d.id, d.name, (select count(*) from emp where dept_id = d.id ) \u0026#39;人数\u0026#39; from dept d; 查询所有学生的选课情况，展示出学生名称，学号，课程名称(自己的练习) 1 2 3 4 5 6 7 8 9 10 11 12 13 -- 表：student、course、student_course -- 查询每个学生的选课情况 -- 学生id为1的选课情况 select * from student_course sc where sc.studentid = 1; -- 根据id查询课程名称 select name from course c where c.id = 1; -- 根据学生id查询学生名称，学号 select s.name,s.no from student s where s.id = 1; -- 学生的选课情况 select sc.studentid,(select s.name from student s where s.id = sc.studentid),(select s.no from student s where s.id = sc.studentid),(select name from course c where c.id = sc.courseid) courseName from student_course sc where sc.studentid = (select s.id from student s where s.id = sc.studentid); 查询所有学生的选课情况，展示出学生名称，学号，课程名称(重点) 1 2 3 -- 表：student、course、student_course -- 连接条件：student.id = student_course.studentid、course.id=student_course.courseid select s.name,s.no,c.name from student s, course c, student_course sc where s.id = sc.studentid and c.id = sc.courseid; ","date":"2025-11-02T20:34:03+08:00","permalink":"https://YLine-hub.github.io/p/mysqlmysql%E5%9F%BA%E7%A1%80-%E5%A4%9A%E8%A1%A8%E6%9F%A5%E8%AF%A2/","title":"[MySQL]MySQL基础-多表查询"},{"content":"约束 概述 概念：约束是作用于表中字段上的规则，用于限制存储在表中的数据。 目的：保证数据库中数据的正确、有效性和完整性 分类： 约束 描述 关键字 非空约束 限制字段的数据不能为空 NOT NULL 唯一约束 保证该字段的所有数据都是唯一、不重复的 UNIQUE 主键约束 主键是一行数据的唯一标识，要求非空且唯一 PRIMARY KEY 默认约束 保存数据时，如果未指定该字段的值，则采用默认值 DEFAULT 检查约束(8.0.16版本之后) 保证字段值满足某一个条件 CHECK 外键约束 用来让两张表的数据之间建立连接，保证数据的一致性和完整性 FOREIGN KEY 注意：约束是作用于表中字段上的，可以在创建表/修改表的时候添加约束。\n案例：创建表 根据需求，完成表结构的创建 字段名 字段含义 字段类型 约束条件 约束关键字 id ID唯一标识 int 主键，并且自动增长 PRIMARY KEY,AUTO_INCREMENT name 姓名 varchar(10) 不为空，并且唯一 NOT NULL,UNIQUE age 年龄 int 大于0，并且小于等于120 CHECK status 状态 char(1) 如果没有指定该值，默认为1 DEFAULT gender 性别 char(1) 无 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 create table user( id int primary key auto_increment comment \u0026#39;主键\u0026#39;, name varchar(10) not null unique comment \u0026#39;姓名\u0026#39;, age int check(age \u0026gt; 0 \u0026amp;\u0026amp; age \u0026lt;= 120) comment \u0026#39;年龄\u0026#39;, status char(1) default \u0026#39;1\u0026#39; comment \u0026#39;状态\u0026#39;, gender char(1) comment \u0026#39;性别\u0026#39; ) comment \u0026#39;用户表\u0026#39;; -- 插入数据 insert into user(name,age,status,gender) values(\u0026#39;Tom1\u0026#39;,19,\u0026#39;1\u0026#39;,\u0026#39;男\u0026#39;),(\u0026#39;Tom2\u0026#39;,25,\u0026#39;0\u0026#39;,\u0026#39;男\u0026#39;); -- 1,Tom1,19,1,男 -- 2,Tom2,25,0,男 insert into user(name,age,status,gender) values(\u0026#39;Tom3\u0026#39;,19,\u0026#39;1\u0026#39;,\u0026#39;男\u0026#39;); -- 3,Tom3,19,1,男 insert into user(name,age,status,gender) values(null,19,\u0026#39;1\u0026#39;,\u0026#39;男\u0026#39;); -- [2025-11-02 21:32:27] [23000][1048] Column \u0026#39;name\u0026#39; cannot be null insert into user(name,age,status,gender) values(\u0026#39;Tom3\u0026#39;,19,\u0026#39;1\u0026#39;,\u0026#39;男\u0026#39;); -- [2025-11-02 21:39:16] [23000][1062] Duplicate entry \u0026#39;Tom3\u0026#39; for key \u0026#39;user.name\u0026#39; insert into user(name,age,status,gender) values(\u0026#39;Tom4\u0026#39;,80,\u0026#39;1\u0026#39;,\u0026#39;男\u0026#39;); -- 5,Tom4,80,1,男 -- 注意，这里id为5，是因为虽然上一段插入语句没有成功，但是已经向数据库申请了主键4，所以这里是继续向数据库申请了4后面的主键 insert into user(name,age,status,gender) values(\u0026#39;Tom5\u0026#39;,-1,\u0026#39;1\u0026#39;,\u0026#39;男\u0026#39;); -- [2025-11-02 21:44:20] [HY000][3819] Check constraint \u0026#39;user_chk_1\u0026#39; is violated. insert into user(name,age,status,gender) values(\u0026#39;Tom5\u0026#39;,121,\u0026#39;1\u0026#39;,\u0026#39;男\u0026#39;); -- [2025-11-02 21:44:39] [HY000][3819] Check constraint \u0026#39;user_chk_1\u0026#39; is violated. insert into user(name,age,gender) values(\u0026#39;Tom5\u0026#39;,120,\u0026#39;男\u0026#39;); -- 6,Tom5,120,1,男 外键约束 概念：外链用来让两张表的数据之间建立连接，从而保证数据的一致性和完整性。 注意：目前上述的两张表，在数据库层面，并未建立外键关联，所以是无法保证数据的一致性和完整性的。\n准备数据 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 create table dept( id int auto_increment comment \u0026#39;ID\u0026#39; primary key, name varchar(50) not null comment \u0026#39;部门名称\u0026#39; )comment \u0026#39;部门表\u0026#39;; insert into dept(id,name) values(1,\u0026#39;研发部\u0026#39;),(2,\u0026#39;市场部\u0026#39;),(3,\u0026#39;财务部\u0026#39;),(4,\u0026#39;销售部\u0026#39;),(5,\u0026#39;总经办\u0026#39;); create table emp( id int auto_increment comment \u0026#39;ID\u0026#39; primary key, name varchar(50) not null comment \u0026#39;姓名\u0026#39;, age int comment \u0026#39;年龄\u0026#39;, job varchar(20) comment \u0026#39;职位\u0026#39;, salary int comment \u0026#39;薪资\u0026#39;, entrydate date comment \u0026#39;入职时间\u0026#39;, managerid int comment \u0026#39;直属领导ID\u0026#39;, dept_id int comment \u0026#39;部门ID\u0026#39; ) comment \u0026#39;员工表\u0026#39;; insert into emp(id,name,age,job,salary,entrydate,managerid,dept_id) values (1,\u0026#39;金庸\u0026#39;,66,\u0026#39;总裁\u0026#39;,20000,\u0026#39;2000-01-01\u0026#39;,null,5),(2,\u0026#39;张无忌\u0026#39;,20,\u0026#39;项目经理\u0026#39;,12500,\u0026#39;2005-12-05\u0026#39;,1,1), (3,\u0026#39;杨逍\u0026#39;,33,\u0026#39;开发\u0026#39;,8400,\u0026#39;2000-11-03\u0026#39;,2,1),(4,\u0026#39;韦一笑\u0026#39;,48,\u0026#39;开发\u0026#39;,11000,\u0026#39;2002-02-05\u0026#39;,2,1), (5,\u0026#39;常遇春\u0026#39;,43,\u0026#39;开发\u0026#39;,10500,\u0026#39;2004-09-07\u0026#39;,3,1),(6,\u0026#39;小昭\u0026#39;,19,\u0026#39;程序员鼓励师\u0026#39;,6600,\u0026#39;2004-10-12\u0026#39;,2,1); -- 添加外键 alter table emp add constraint fk_emp_dept_id foreign key (dept_id) references dept(id); -- 删除外键 alter table emp drop foreign key fk_emp_dept_id; -- 外键的删除和更新行为 alter table emp add constraint fk_emp_dept_id foreign key (dept_id) references dept(id) on update cascade on delete cascade; alter table emp add constraint fk_emp_dept_id foreign key (dept_id) references dept(id) on update set null on delete set null; 添加外键 1 2 3 4 5 CREATE TABLE 表名( 字段名 数据类型, ... [CONSTRAINT] [外键名称] FOREIGN KEY(外键字段名) REFERENCES 主表(主表列名) ); 1 ALTER TABLE 表名 ADD CONSTAINT 外键名称 FOREIGN KEY(外键字段名) REFERENCES 主表(主表列名) 无外键约束 虽然emp表有dept_id表示和dept的id关联\n但是此时随时可以删除关联的内容\n重新添加研发部 建立外键约束\n1 alter table emp add constraint fk_emp_dept_id foreign key (dept_id) references dept(id); 运行以后，可以看到dept_id前面出现了蓝色的小钥匙，表明该字段变为外键\n再次删除dept表研发部\n1 2 delete from dept where id = 1 -- [2025-11-03 08:15:52] [23000][1451] Cannot delete or update a parent row: a foreign key constraint fails (`itfox`.`emp`, CONSTRAINT `fk_emp_dept_id` FOREIGN KEY (`dept_id`) REFERENCES `dept` (`id`)) 此时报错说不能直接删除，因为有一个外键约束。\n删除外键 1 ALTER TABLE 表名 DROP FOREIGN KEY 外键名称; 删除外键 1 alter table emp drop foreign key fk_emp_dept_id; 删除后，可以看到dept_id前的蓝色小钥匙没了。\n删除/更新行为 行为 说明 NO ACTION 当在父表中删除/更新对应记录时，首先检查该记录是否有对应外键，如果有则不允许删除/更新。(与RESTRICT一致) RESTRICT 当在父表中删除/更新对应记录时，首先检查该记录是否有对应外键，如果有则不允许删除/更新。(与RESTRICT一致) CASCADE 当在父表中删除/更新对应记录时，首先检查该记录是否有对应外键，如果有，则也删除/更新外键在子表中的记录。 SET NULL 当在父表中删除对应记录时，首先检查该记录是否有对应外键，如果有则设置子表中该外键值为null。(这就要求该外键允许取null) SET DEFAULT 父表有变更时，子表将外键设置成一个默认的值。(Innodb不支持) 1 ALTER TABLE 表名 ADD CONSTRAINT 外键名称 FOREIGN KEY (外键字段) REFERENCES 主表名(主表字段名) ON UPDATE CASCADE ON DELETE CASCADE; 设置有删除/更新行为的外键 1 alter table emp add constraint fk_emp_dept_id foreign key (dept_id) references dept(id) on update cascade on delete cascade; 此时可以看到emp表的dept_id有出现了外键标识的蓝色小钥匙。\n修改dept表的研发部id为6 1 update dept set id = 6 where id = 1 能够看到dept表的研发部id能够修改（普通外键无法修改）\n此时，emp表原先dept_id为1的员工都变为6\n删除dept表的研发部 1 delete from dept where id = 6; id为6的研发部，能够被删除\n子表emp表dept_id为6的数据也被全部删除\n删除并重新创建emp表和dept表\n设置set null行为的外键\n1 alter table emp add constraint fk_emp_dept_id foreign key (dept_id) references dept(id) on update set null on delete set null; dept_id 上添加了外键标识\n删除研发部门 1 delete from dept where id = 1; dept表中id为1研发部被删除\nemp表中dept_id为1的数据全都变为null\n生词 constraint / kənˈstreɪnt / n、限制，束缚；克制，拘束 ","date":"2025-11-02T20:30:41+08:00","permalink":"https://YLine-hub.github.io/p/mysqlmysql%E5%9F%BA%E7%A1%80-%E7%BA%A6%E6%9D%9F/","title":"[MySQL]MySQL基础-约束"},{"content":"MySQL基础-函数 函数 函数： 指一段可以直接被另一段程序调用的程序或代码。\n字符串函数 数值函数 日期函数 流程函数 字符串函数 函数 功能 CONCAT(S1,S2,\u0026hellip;Sn) 字符串拼接，将S1，S2，\u0026hellip;Sn拼接成一个字符串 LOWER(str) 将字符串str全部转为小写 UPPER(str) 将字符串str全部转为大写 LPAD(str,n,pad) 左填充，用字符串pad对str的左边进行填充，达到n个字符串长度 RPAD(str,n,pad) 右填充，用字符串pad对str的右边进行填充，达到n个字符串长度 TRIM(str) 去掉字符串头部和尾部的空格 SUBSTRING(str,start,len) 返回从字符串str从start位置起的len个长度的字符串 练习：\nconcat 1 2 select concat(\u0026#39;Hello\u0026#39;,\u0026#39; MySQL\u0026#39;); -- Hello MySQL lower 1 2 select lower(\u0026#39;Hello\u0026#39;); -- hello upper 1 2 select upper(\u0026#39;Hello\u0026#39;); -- HELLO lpad 1 2 select lpad(\u0026#39;01\u0026#39;,5,\u0026#39;-\u0026#39;); -- ---01 rpad 1 2 select rpad(\u0026#39;01\u0026#39;,5,\u0026#39;-\u0026#39;) -- 01--- trim 1 2 select trim(\u0026#39; Hello MySQL\u0026#39;); -- Hello MySQL substring 1 2 select substring(\u0026#39;Hello MySQL\u0026#39;,1,5); -- Hello 案例 由于业务需求变更，企业员工的工号，统一为5位数，目前不足5位数的全部在前面补0.比如：1号员工的工号应该为00001。 1 update emp set workno=lpad(workno,5,\u0026#39;0\u0026#39;); 数值函数 函数 功能 CEIL(x) 向上取整 FLOOR(x) 向下取整 MOD(x,y) 返回x/y的模 RAND() 返回0~1内的随机数 ROUND(x,y) 求参数x的四舍五入的值，保留y位小数 练习：\nceil 1 2 select ceil(1.1); -- 2 floor 1 2 select floor(1.9); -- 1 mod，3除以4的余数 1 2 select mod(3,4); -- 3 rand 1 select rand(); round 1 2 select round(2.345,2); -- 2.35 案例 通过数据库的函数，生成一个六位数的随机验证码 1 2 3 select floor(rand()*899999 + 100000); select lpad(round(rand()*1000000,0),6,\u0026#39;0\u0026#39;); 日期函数 函数 功能 CURDATE() 返回当前日期 CURTIME() 返回当前时间 NOW() 返回当前日期和时间 YEAR(date) 获取指定date的年份 MONTE(date) 获取指定date的月份 DAY(date) 获取指定date的日期 DATE_ADD(date,INTERVAL expr type) 返回一个日期加上一个时间间隔expr后的时间值 DATEDIFF(date1,date2) 返回起始时间date1和结束时间date2之间的天数 练习：\ncurdate() 1 2 select curdate(); -- 2025-11-01 curtime() 1 2 select curtime(); -- 13:30:56 now() 1 2 select now(); -- 2025-11-01 13:31:38 YEAR, MONTH, DAY 1 2 3 select YEAR(now()); -- 2025 select MONTH(now()); -- 11 select DAY(now()); -- 1 date_add 1 2 select date_add(now(),INTERVAL 70 DAY); -- 2025-11-06 13:38:04 datediff 1 2 select datediff(\u0026#39;2025-12-01\u0026#39;,\u0026#39;2025-11-01\u0026#39;); -- 30 案例 查询所有员工的入职天数，并根据入职天数倒叙排序 1 select name,datediff(now(),entrydate) entrydays from emp order by entrydays desc; 流程函数 函数 功能 IF(value,t,f) 如果value为true，则返回t，否则返回f IFNULL(value1,value2) 如果value1不为空，返回value1，否则返回value2 CASE WHEN [val1] THEN [res1] \u0026hellip; ELSE [default] END 如果val1为true，返回res1，\u0026hellip;否则返回default默认值 CASE [expr] WHEN [val1] THEN [res1] \u0026hellip; ELSE [default] END 如果expr的值等于val1，返回res1，\u0026hellip;否则返回default默认值 练习：\nif 1 select if(false,\u0026#39;OK\u0026#39;,\u0026#39;Error\u0026#39;); ifnull 1 2 3 select ifnull(\u0026#39;ok\u0026#39;,\u0026#39;Default\u0026#39;); select ifnull(\u0026#39;\u0026#39;,\u0026#39;Default\u0026#39;); select ifnull(null,\u0026#39;Default\u0026#39;); case when then else end 需求：查询emp表的员工姓名和工作地址（北京/上海\u0026mdash;-\u0026gt;一线城市，其他\u0026mdash;-\u0026gt;二线城市） 1 2 3 4 select name, ( case workaddress when \u0026#39;北京\u0026#39; then \u0026#39;一线城市\u0026#39; when \u0026#39;上海\u0026#39; then \u0026#39;一线城市\u0026#39; else \u0026#39;二线城市\u0026#39; end ) \u0026#39;工作地址\u0026#39; from emp 案例 统计班级各个学院的成绩，展示的规则如下： \u0026gt;= 85，展示优秀 \u0026gt;= 60，展示及格 否则，不及格 学员分数表\n1 2 3 4 5 6 7 8 create table score( id int comment \u0026#39;ID\u0026#39;, name varchar(20) comment \u0026#39;姓名\u0026#39;, math int comment \u0026#39;数学\u0026#39;, english int comment \u0026#39;英语\u0026#39;, chinese int comment \u0026#39;语文\u0026#39; ) comment \u0026#39;学员成绩表\u0026#39;; insert into score(id,name,math,english,chinese) values(1,\u0026#39;Tom\u0026#39;,67,88,97),(2,\u0026#39;Rose\u0026#39;,23,66,90),(3,\u0026#39;Jack\u0026#39;,56,98,76); 1 2 3 4 5 6 7 select name, (case when math \u0026gt;= 85 then \u0026#39;优秀\u0026#39; when math \u0026gt;= 60 then \u0026#39;及格\u0026#39; else \u0026#39;不及格\u0026#39; end) math, (case when english \u0026gt;= 85 then \u0026#39;优秀\u0026#39; when english \u0026gt;= 60 then \u0026#39;及格\u0026#39; else \u0026#39;不及格\u0026#39; end) english, (case when chinese \u0026gt;= 85 then \u0026#39;优秀\u0026#39; when chinese \u0026gt;= 60 then \u0026#39;及格\u0026#39; else \u0026#39;不及格\u0026#39; end) chinese from score 生词 interval / ˈɪntərv(ə)l / n、间隔，间隙；中场休息 ","date":"2025-10-31T23:08:43+08:00","permalink":"https://YLine-hub.github.io/p/mysqlmysql%E5%9F%BA%E7%A1%80-%E5%87%BD%E6%95%B0/","title":"[MySQL]MySQL基础-函数"},{"content":"需求一 将下列所有图片名后面的数字+3，例如 image-1.png 修改为 image-4.png\n将image.png文件名修改为image-0.png 在当前目录下，创建文件 before.bat 编辑该文件，并输入以下内容 1 2 dir /b \u0026#34;*.png\u0026#34; \u0026gt; before.xls pause 注意：dir /b是只输出该目录所有目录和文件名，dir /b \u0026quot;*.png\u0026quot;是只输出该目录下所有\u0026quot;.png\u0026quot;为结尾的文件名，\u0026gt; before.xls是将输出结果写入文件before.xls中\n修改后保存文件，双击执行该文件\n执行后弹出黑框，按回车或点右上角的叉叉关闭\n此时该目录生成了before.xls的文件 双击该文件打开，里面是该目录下所有\u0026quot;png\u0026quot;结尾的文件名 在C1单元格输入以下内容并回车 1 =CONCAT(\u0026#34;image-\u0026#34;,TEXTJOIN(\u0026#34;\u0026#34;,TRUE,IFERROR(MID(A1,SEQUENCE(LEN(A1)),1)*1,\u0026#34;\u0026#34;))+3,\u0026#34;.png\u0026#34;) 向下填充C1单元格的数据 这段公式的作用是将A1单元格中的数字提取出来，并加上3。再以image-数字.png的形式输出。\n其中以下公式是提取A1单元格内的数字\n1 TEXTJOIN(\u0026#34;\u0026#34;,TRUE,IFERROR(MID(A1,SEQUENCE(LEN(A1)),1)*1,\u0026#34;\u0026#34;)) 使用公式以A列和C列为辅助，得到E列 1 =CONCAT(\u0026#34;ren \u0026#34;,A1,\u0026#34; \u0026#34;,C1) 向下填充E列，得到所有脚本 在G1使用函数，将E1:E9的数据倒置 1 =SORTBY(E1:E9,ROW(E1:E9),-1) 在当前目录下创建新文件after.bat，并将G列内容复制进去 这就是所得到的脚本 双击after.bat文件\n此时所有文件名都被修改成我们需要的格式了\n","date":"2025-10-27T21:57:30+08:00","permalink":"https://YLine-hub.github.io/p/win%E4%BD%BF%E7%94%A8bat%E5%92%8Cexcel%E6%89%B9%E9%87%8F%E4%BF%AE%E6%94%B9%E6%96%87%E6%9C%AC%E5%90%8D/","title":"[Win]使用bat和excel批量修改文本名"},{"content":"学习链接 systemctl管理服务 开机启动 支持systemd的软件，安装时，会自动在/usr/lib/systemd/system目录添加一个配置文件 下面以mysql为例来说明如何设置开机启动 1 systemctl enable mysqld 执行上面的命令之后，在/etc/systemd/system/multi-user.target.wants目录下添加一个符号链接，这个链接指向/usr/lib/systemd/system里面的mysqld.service文件\n设置开机启动后，需要等下一次开机的时候，才会自动执行/etc/systemd/system目录中的文件\n如果忘记了一个服务有没有设置成开机启动，可以使用systemctl is-enable 服务名来查看\n1 systemctl is-enabled mysqld 启动服务 执行systemctl start 服务名可以启动服务，下面还是以mysql为例来说明 1 systemctl start mysqld 服务启动之后，可以执行systemctl status 服务名来检查服务是否启动成功 1 systemctl status mysqld 上面结果中各个字段含义\n1 2 3 4 5 Loaded: 配置文件的位置，这里是/usr/lib/systemd/system/mysqld.service Active: 状态，active (running)表示启动，如果是inactive (dead)表示已关闭 Docs: 服务器文档 Main PID：主进程ID CGroup：进程中所有子进程 除了使用systemctl status 服务名之外，还可以使用以下的命令来查看服务的状态\n查看mysql服务状态 1 systemctl is-active mysqld 关闭mysql，并查看服务状态 1 2 systemctl stop mysqld systemctl is-active mysqld active表示mysql处于开启状态，is-active表示mysql处于关闭状态\n停止服务 停止正在运行的mysql 1 systemctl stop mysqld 重启mysql服务 1 systemctl restart mysqld 服务配置文件 从上面mysql的例子可以看出，它的配置文件位于/usr/lib/systemd/system/mysqld.service，其他的服务文件也是位于此目录下，只不过具体的文件名不一样\n服务是根据它的配置来启动和停止的，我们使用编辑器或使用systemctl cat 服务名查看服务的配置文件，下面我们以sshd服务的配置文件来说明\n查看sshd服务的配置文件 1 systemctl cat sshd sshd.service 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 # /usr/lib/systemd/system/sshd.service [Unit] Description=OpenSSH server daemon Documentation=man:sshd(8) man:sshd_config(5) After=network.target sshd-keygen.service Wants=sshd-keygen.service [Service] Type=notify EnvironmentFile=/etc/sysconfig/sshd ExecStart=/usr/sbin/sshd -D $OPTIONS ExecReload=/bin/kill -HUP $MAINPID KillMode=process Restart=on-failure RestartSec=42s [Install] WantedBy=multi-user.target 配置文件字段说明\nUnit：启动顺序单元的依赖关系 1 2 3 4 5 6 Description：服务描述，描述服务的一段文字 Documentation：服务的文档位置 After：当前服务在指定的服务之后启动，这里表示sshd服务需要在network和sshd-keygen服务启动之后再启动。 如果sshd服务需要在指定服务之前启动的话，使用Before字段。 Wants：服务的依赖，这种依赖是一种弱依赖关系，在这里表示的是sshd和sshd-keygen存在依赖关系，但是它们之间是一种弱依赖。也就是说，如果sshd-keygen启动失败了，是不会影响sshd的。 如果要表示强依赖关系，使用Requires字段，也即 如果sshd-keygen启动失败，或者退出了，sshd也必须退出。 Service：服务的启动命令以及启动参数 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 Type：启动类型，常用的值如下所示 - simple 默认值，ExecStart字段启动的进程为主进程 - forking ExecStart字段将以fork()方式启动，此时父进程将会退出，子进程将会成为主进程。 - notify 类似simple，启动结束后会发出通知信号，然后Systemd再启动其他服务。 EnviromentFile：服务的环境变量文件，当前配置文件可以用$KEY的方式引用环境变量中的参数，上面的例子中，sshd的环境变量文件是/etc/sysconfig/sshd ExecStart：启动服务执行的命令 ExecReload：重启服务执行的命令 KillMode：如何停止服务，可能的值有 - control-group 默认值，当前的控制组里面的所有进程都会被杀掉。 - process 只杀主进程 - mixed 主进程收到SIGTERM信号，子进程收到SIGKILL信号 - 没有进程会被杀掉，只执行服务的stop命令 Restart：服务因为何种原因退出才会重启服务，可能的值有 - always 不论服务因为何种情况退出，总是重启。 - on-succes 正常退出时 - on-failure 非正常退出时 - on-abnormal 被信号终止和超时时，才重启 - on-abort 只有收到了没有捕捉的信号时，才重启 - on-watchdog 超时退出，才重启 大部分的情况下，设置为on-failure就可以了 RestartSec：服务重启前需等待多少秒 Install：如何安装配置文件，也即定义如何做到开机启动 WantedBy 字段表示服务所在的Target，这里的Target可以理解成一组服务 WantedBy 的值时一个或多个Target，当前Unit（单元）激活时（enable）符号链接会放入 /etc/systemd/system 目录下面以 Target 名 + .wants 后缀构成的子目录中 比如：sshd的WantedBy 字段值是multi-user.target，执行 systemctl enable sshd之后相当于执行了 ln -s /usr/lib/systemd/system/sshd.service /etc/systemd/system/multi-user.target.wants/sshd.service命令\n与之相对的，当执行 systemctl disable sshd命令之后，会去掉上图中两个目录之间的符号链接，相当于开机不会启动sshd服务\n关于上图中配置文件名 sshd.service 的后缀 .service 表示Unit（单元）的种类，如果省略，默认的后缀是.servicce ，所以sshd会被当做sshd.service\n重新加载配置 如果修改了服务的配置i文件，需要重新加载配置文件，然后重启服务\n1 2 systemctl daemon-reload systemctl restart mysqld 救援模式 当出现系统无法正常引导的情况时，可以将系统置于救援模式。救援模式提供了用于修复系统问题的单用户界面。执行 systemctl rescue 命令可以进入救援模式\n1 systemctl rescue 进入救援模式后，当前登陆的其他用户会收到一套系统将进入救援模式的通知。\n","date":"2025-10-25T22:36:45+08:00","permalink":"https://YLine-hub.github.io/p/linux%E4%BD%BF%E7%94%A8systemctl%E6%9D%A5%E7%AE%A1%E7%90%86%E6%9C%8D%E5%8A%A1/","title":"[Linux]使用systemctl来管理服务"},{"content":"TypeScript基础 Typescript安装 打开终端ctrl+r，输入cmd并回车 全局安装typescript 1 npm install typescript -g 查看typescript版本 1 tsc -v 创建第一个代码 app.ts\n1 2 var message:string = \u0026#34;Hello World\u0026#34; console.log(message) 使用命令将ts转换为js代码 1 tsc app.ts 生成的app.js代码如下 app.js\n1 2 var message = \u0026#34;Hello World\u0026#34;; console.log(message); 使用node命令来执行app.js 1 node app.js TypeScript特性 关键特性 静态类型检查\n类型推断\n接口和类型定义\n类和模块支持\n工具和编译器支持\n兼容JavaScript\n静态类型 TypeScript最大特性就是增加了静态类型系统。在TS中，开发者可以显式声明变量、参数、返回值类型，这样可以在编译时捕获很多潜在类型错误。\n1 2 let name:string = \u0026#34;Alice\u0026#34;; let age:number = 25; 类型推断 TypeScript可以自动推断变量类型，即使不显式声明类型，TS也会根据变量的赋值内容来推断类型，从而在大多数情况下减少类型注解的书写量。\n1 let name = \u0026#34;Alice\u0026#34;; // 推断为string 接口（Interfaces） TypeScript提供了接口，允许定义复杂的对象结构。接口可以定义属性和方法，还可以通过implements关键字实现接口，或者通过extentds进行扩展，便于定义复杂的数据类型。\n1 2 3 4 5 6 7 8 9 10 11 12 13 interface Person { name: string; age: number; greet(): void; } class Student implements Person { constructor(public name: string,public age: number){} greet(){ console.log(`Hello, my name is $(this.name)`) } } 枚举（Enums） TypeScript引入了enum类型，用于定义一组命名的常量，提高代码的可读性。枚举在JavaScript中没有直接的对应。\n1 2 3 4 5 6 7 enum Direction { Up, Down, Left, Right, } let dir: Direction = Direction.Up; 元组（Tuples） 元组允许定义具有固定数量和类型的数组。它适用于需要固定数据结构的场景，比如坐标或RGB颜色值。\n1 let point: [number, number] = [10,20]; 访问控制修饰符（Access Modifiers） TypeScript在类中提供了public、private和protected修饰符，允许控制属性或方法的可见性，支持更好的封装。\n1 2 3 4 5 6 7 8 class Person { private name: string; protected age: number; public constructor(name: string,age: number) { this.name = name; this.age = age } } 抽象类（Abstract Classes） TypeScript支持抽象类，抽象类不能直接实例化，需要有子类实现。抽象类适用于定义通用行为和抽象方法的类层结构。\n1 2 3 4 5 6 7 8 9 abstract class Animal { abstract makeSound(): void; } class Dog extends Animal { makeSound() { console.log(\u0026#34;Woof!\u0026#34;); } } 泛型 (Generics) TypeScript 支持泛型，允许在类、接口和函数中使用参数化类型，使得代码可以适应不同的类型需求，同时保持类型安全。\n1 2 3 4 5 function identity\u0026lt;T\u0026gt;(value: T): T { return value; } let num = identity\u0026lt;number\u0026gt;(42); 模块和命名空间 TypeScript 提供了基于 ES6 的模块系统，使用 import 和 export 导入和导出模块。此外，TypeScript 还支持命名空间（Namespace），用于组织代码和避免命名冲突。\n1 2 3 4 5 6 7 8 // math.ts export function add(a: number, b: number): number { return a + b; } // main.ts import { add } from \u0026#34;./math\u0026#34;; console.log(add(2, 3)); 类型守卫 (Type Guards) TypeScript 提供了类型守卫，可以在代码中检查变量类型，帮助编译器推断更加具体的类型。这对于联合类型尤为重要。\n1 2 3 4 5 6 7 function printId(id: string | number) { if (typeof id === \u0026#34;string\u0026#34;) { console.log(id.toUpperCase()); } else { console.log(id.toFixed(2)); } } 可选链和空值合并运算符 TypeScript 增加了 JavaScript 的可选链 (?.) 和空值合并运算符 (??)，简化了代码中对可能为 null 或 undefined 值的处理。\n1 2 3 4 5 let user = { name: \u0026#34;Alice\u0026#34;, address: { city: \u0026#34;Wonderland\u0026#34; } }; console.log(user?.address?.city); // 如果 address 存在则输出 city，否则返回 undefined let value = null; console.log(value ?? \u0026#34;default\u0026#34;); // 如果 value 为 null 或 undefined，则返回 \u0026#34;default\u0026#34; 类型兼容性和工具类型 TypeScript 提供了一些工具类型，如 Partial、Pick、Readonly、Record 等，这些类型可以帮助生成新的类型，简化类型定义。\n1 2 3 4 5 6 interface Todo { title: string; description: string; } let partialTodo: Partial\u0026lt;Todo\u0026gt; = { title: \u0026#34;Learn TypeScript\u0026#34; }; // 可选属性 编译期错误检查 TypeScript 提供的编译期错误检查可以捕获 JavaScript 中不易发现的错误，如拼写错误、类型不匹配等，帮助提升代码质量。\nES 新特性支持 TypeScript 提前支持了一些还未在所有环境中普及的 ES 特性，如装饰器（Decorators）、异步迭代器等，且能够将其编译成兼容 JavaScript 版本。\n基础语法 ","date":"2025-10-22T21:35:21+08:00","permalink":"https://YLine-hub.github.io/p/typescripttypescript%E5%9F%BA%E7%A1%80/","title":"[TypeScript]TypeScript基础"},{"content":"Mac和Win实现文件互传 Windows篇看:[Windows]Mac和Win实现文件互传 Mac连接Win共享文件夹 打开Finder，点击菜单栏的移動，选择サーバへ接続 接続（せつぞく）：连接\n在红框内输入smb:// + ip，然后点击接続 然后分别输入win登陆用的用户名和密码，再点击接続 选择共享文件夹再点击ok 就弹出了win的共享文件夹 mac创建共享文件夹 点击左上角的苹果按钮，选择システム設定 在按边栏中选择一般，再点击共有 开启ファウル共有，再点击右边的叹号进入设置共享文件夹 点击左边的+号添加共享文件夹 选择要共享的文件夹再点击追加 点击添加的文件夹，再点击すべての人后面的読み出しのみ 选择読み/書き 设定完成以后点击完了 在终端输入ifconfig，找到ip ","date":"2025-10-22T21:31:57+08:00","permalink":"https://YLine-hub.github.io/p/macmac%E5%92%8Cwin%E5%AE%9E%E7%8E%B0%E6%96%87%E4%BB%B6%E4%BA%92%E4%BC%A0/","title":"[Mac]mac和win实现文件互传"},{"content":"nginx 基础 nginx基础配置 最小配置文件 文件位置 默认位置 1 /usr/local/nginx/conf/nginx.conf 文件内容 nginx.conf 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 worker_processes 1; #error_log logs/error.log; #error_log logs/error.log notice; #error_log logs/error.log info; #pid logs/nginx.pid; events { worker_connections 1024; } http { include mime.types; default_type application/octet-stream; #log_format main \u0026#39;$remote_addr - $remote_user [$time_local] \u0026#34;$request\u0026#34; \u0026#39; # \u0026#39;$status $body_bytes_sent \u0026#34;$http_referer\u0026#34; \u0026#39; # \u0026#39;\u0026#34;$http_user_agent\u0026#34; \u0026#34;$http_x_forwarded_for\u0026#34;\u0026#39;; #access_log logs/access.log main; sendfile on; #tcp_nopush on; #keepalive_timeout 0; keepalive_timeout 65; #gzip on; server { listen 80; server_name localhost; #charset koi8-r; #access_log logs/host.access.log main; location / { root html; index index.html index.htm; } #error_page 404 /404.html; # redirect server error pages to the static page /50x.html # error_page 500 502 503 504 /50x.html; location = /50x.html { root html; } # proxy the PHP scripts to Apache listening on 127.0.0.1:80 # #location ~ \\.php$ { # proxy_pass http://127.0.0.1; #} # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000 # #location ~ \\.php$ { # root html; # fastcgi_pass 127.0.0.1:9000; # fastcgi_index index.php; # fastcgi_param SCRIPT_FILENAME /scripts$fastcgi_script_name; # include fastcgi_params; #} # deny access to .htaccess files, if Apache\u0026#39;s document root # concurs with nginx\u0026#39;s one # #location ~ /\\.ht { # deny all; #} } # another virtual host using mix of IP-, name-, and port-based configuration # #server { # listen 8000; # listen somename:8080; # server_name somename alias another.alias; # location / { # root html; # index index.html index.htm; # } #} # HTTPS server # #server { # listen 443 ssl; # server_name localhost; # ssl_certificate cert.pem; # ssl_certificate_key cert.key; # ssl_session_cache shared:SSL:1m; # ssl_session_timeout 5m; # ssl_ciphers HIGH:!aNULL:!MD5; # ssl_prefer_server_ciphers on; # location / { # root html; # index index.html index.htm; # } #} } 简化文件（去掉所有注释） 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 # 工作进程个数 为1 worker_processes 1; events { # 每个worker进程能创建1024个连接 worker_connections 1024; } http { # 引入配置文件mime.types # mime.types 解析文件类型并以相应的方式去读取文件 # 作用：告诉浏览器以什么方式去打开什么文件 include mime.types; # default_type表示默认类型，及如果这种类型不包含在mime.types 里面，就以application/octet-stream传输给我们的客户端（浏览器） default_type application/octet-stream; # sendfile：数据零拷贝 # 数据零拷贝：不需要复制和拷贝 # off : nginx复制一份文件，并读到应用程序内存中，再把数据复制给网络接口，最后发送出去 # on ： nginx推送给网络接口sendfile信号，网络接口直接读取文件，再发送出去 sendfile on; # 保持连接超时 keepalive_timeout 65; # 虚拟主机 vhost server { # 端口号 listen 80; # 域名、主机名 server_name localhost; # http://location/index.html location / { # 匹配页面的根目录 root html; # 默认页 index index.html index.htm; } # 发生服务器端错误时：500 502 503 504 # 跳转到 http://location/50x.html error_page 500 502 503 504 /50x.html; location = /50x.html { root html; } } } 虚拟主机与域名解析 使用ip访问虚拟机的nginx 使用hosts文件解析域名 hosts文件位置[mac] mac:\n/private/etc/hosts hosts:\n1 2 3 4 5 6 7 8 9 ## # Host Database # # localhost is used to configure the loopback interface # when the system is booting. Do not change this entry. ## 127.0.0.1 localhost 255.255.255.255 broadcasthost ::1 localhost win:\nC:\\Windows\\System32\\drivers\\etc\\hosts 使用hosts解析虚拟机ip为域名 编辑hosts 1 sudo vim /etc/hosts 在hosts文件末尾添加以下内容 1 172.16.140.102 vm-2.com 使用浏览器打开vm-2.com nginx虚拟主机配置 配置两个网站 创建网站 创建项目目录 /www/book/index.html 1 this is a book web /www/vod/index.html 1 this is a vod web 配置hosts文件 模拟公网域名，给服务器添加两个二级域名 1 2 172.16.140.102 book.vm-2.html 172.16.140.102 vod.vm-2.html 配置nginx 在虚拟机中配置nginx 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 server { listen 80; server_name book.vm-2.com; location / { root /www/book; index index.html index.htm; } error_page 500 502 503 504 /50x.html; location = /50x.html { root html; } } server { listen 80; server_name vod.vm-2.com; location / { root /www/vod; index index.html index.htm; } } nginx重新加载配置文件 1 systemctl reload nginx 浏览网站测试 serverName匹配规则 匹配顺序 从第一个server开始匹配，按顺序向下匹配，比如第一个server匹配的为book.vm-2.com，第二个server匹配的为*.vm-2.com。这时候请求的网址为test.vm-2.com，先会和第一个进行匹配，与book.vm-2.com匹配不上，就会向第二个server进行匹配，这时候与*.vm-2.com匹配上，就会请求第二个server的网页\n配置多个域名 1 2 3 4 5 6 7 8 9 10 server { listen 80; server_name vod.vm-2.com vod1.vm-2.com; location / { root /www/vod; index index.html index.htm; } } 通配符匹配 除了book.vm-2.com，全部匹配到第二个服务 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 server { listen 80; server_name book.vm-2.com; location / { root /www/book; index index.html index.htm; } error_page 500 502 503 504 /50x.html; location = /50x.html { root html; } } server { listen 80; # 通配符匹配 server_name *.vm-2.com; location / { root /www/vod; index index.html index.htm; } } 通配符结束匹配 www.vm-2.com匹配到第一个server，www.vm-2.com匹配到第二个server\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 server { listen 80; server_name www.vm-2.com; location / { root /www/book; index index.html index.htm; } error_page 500 502 503 504 /50x.html; location = /50x.html { root html; } } server { listen 80; # 通配符结束匹配 server_name www.vm-2.*; location / { root /www/vod; index index.html index.htm; } } ","date":"2025-10-22T21:27:31+08:00","permalink":"https://YLine-hub.github.io/p/nginxnginx%E5%9F%BA%E7%A1%80/","title":"[Nginx]nginx基础"},{"content":"使用mac搭建第一个centos虚拟机 安装前置 VMware Fusion： VMware Download\nCentOS7镜像： Centos7-iso-quark\nCentOS9镜像(Linux 5.x)\n阿里源：CentOS9-arm-iso 清华源(推荐)：CentOS9-arm-iso CentOS10镜像(Linux 6.x)：\n清华源：CentO10-arm-iso 安装 配置虚拟机 点击新建 新規（しんき）：新规章；新建\n点击继续 イメージ：image 形象；图像；映像\n选择镜像路径并继续 选择linux-\u0026gt;Linux 5.x arm，然后点击继续 点击自定设置 カスタマイズ：customise 定制；个性化设置\n设置虚拟机名称并保存 分别修改处理器、内存和硬盘 プロセッサ：processor 处理器\nメモリ：memory 内存\nハードディスク：hard disk　硬盘\n选择2个处理器和2048m内存，然后点击すべてを表示返回全部 ハードディスク选择50G然后点击适用 適用（てきよう）：适用；应用\n选择完后就点叉叉关闭 启动虚拟机 点击中间的播放键 选择安装centos7 配置语言（使用默认英语即可），然后点击继续 这个界面分别要配置时区，硬盘，网络，root密码，用户 时区选择上海，然后配置当前时间\n硬盘选择custom，然后点击Done\n硬盘选择如下配置，然后点击Done 点击接受改变 网络自动获取即可，左下角的hostname可以自己设置，也可以不改 全部配置完之后点击开始安装 等待安装 使用shell连接linux服务器 登陆服务器以后查询ip 1 hostname -i ip : 172.16.140/128\n使用命令连接服务器 1 ssh -Y username@ip 输入密码（密码不会显示） 克隆虚拟机 フル：full全部的 作成（さくせい）：制作\n点击自己要克隆的虚拟机，选择仮想マシンー\u0026gt;フル　クローンを作成 设置虚拟机的名称然后保存到虚拟机目录下 将两台虚拟机打开，克隆的虚拟机ip是原本虚拟机的ip+1 如果想要设置静态ip：可以查看我的博客：Linux 网络配置 传输文件到Linux服务器 右键iterm 新建窗口 使用scp命令上传文件 常用参数：\n-r : 递归上传，常用上传文件夹及其子目录和文件 上传文件\n1 2 # scp 【本地文件路径】 【远程服务器用户名】@【远程服务器ip】:【服务器存放路径】 scp local_folder remote_username@remote_ip:remote_folder 上传文件夹 1 scp -r local_folder remote_username@remote_ip:remote_folder 使用scp命令下载文件 下载文件 1 2 #scp 【服务器用户名】@【服务器地址】：【服务器上存放文件的路径】【本地文件的路径】 scp remote_username@remote_ip:remote_folder local_folder 下载文件夹 1 scp -r remote_username@remote_ip:remote_folder local_folder 示例 上传一个文件到服务器 本地文件截屏 2025-09-10 14.41.41.40.png\n远程服务器172.16.140.129\n目录/home/lin\n1 scp 截屏2025-09-10\\ 14.41.40.png root@172.16.140.129:/home/lin 上传文件夹markdown到上述服务器 1 scp -r markdown root@172.16.140.129:/home/lin 下载/opt目录到本地 1 scp -r root@172.16.140.129:/opt /Users/line/project/linux ","date":"2025-10-22T21:24:28+08:00","permalink":"https://YLine-hub.github.io/p/macmac%E6%90%AD%E5%BB%BAcentos7/","title":"[Mac]mac搭建centos7"},{"content":"后台运行 方法一（加“\u0026amp;”符号） 执行文件 1 npm install \u0026amp; 可以看到创建的进程ID为 32470\n但是运行程序的话，进程内容还是会输出在终端上\nctrl + c 退出程序后 查询进程 1 ps -ef | grep npm 关闭进程 1 2 kill -9 32470 kill -9 32487 注意：kill -9 为立即结束进程\n发现关闭这两个进程后程序依然在运行 查询端口号8080占用情况 1 lsof -i:8080 关闭进程 1 kill -9 32504 这时候程序才被终止\n方法二（nohup命令） 1 nohup npm start \u0026gt; output.log 2\u0026gt;\u0026amp;1 \u0026amp; 这是该目录下会出现一个output.log的日志 查看日志 1 cat output.log 这个日志就是把程序的输出信息，保存到日志里\n这时候，日志不会再输出到终端上\n关闭进程方法与方法一相同\n查看占用8080端口占用的进程\n1 lsof -i:8080 关闭进程 1 kill -15 36774 注意：kill -15 为正常结束进程\n方法三（screen） 安装screen 1 yum install screen -y 创建一个新窗口 1 screen -S node_1 然后所有东西都被清空，这表明已经进入了一个新的窗口\n执行命令 1 npm start 退出当前窗口 1 2 3 ctrl+a+d (方法一：保留当前窗口) screen -d (方法二：保留当前窗口) exit (方法三：退出程序，并关闭窗口) 使用ctrl+a+d 查看窗口 1 screen -ls 重新连接窗口 1 screen -r id或窗口名称 1 screen -r 40443 使用ctrl+c停止程序 方法四 - systemctl 挂起、恢复进程 ctrl+z : 将正在执行的命令放到后台，并且处于暂停状态\njobs : 查看当前有多少在后台运行的命令\nfg : 将后台中的命令调回前台继续运行。\n语法 1 2 # jobnumber为命令编号，而不是进程号 fg %jobnumber 示例 将后台编号为1的进程调回前台运行 1 fg 1 bg : 将后台暂停的命令，变成在后台继续执行\nkill\nkill %num (jobs查看job号) kill pid (ps查看进程号) ","date":"2025-10-22T21:21:24+08:00","permalink":"https://YLine-hub.github.io/p/linux%E5%90%8E%E5%8F%B0%E8%BF%9B%E7%A8%8B%E8%BF%90%E8%A1%8C%E6%8C%82%E8%B5%B7%E6%81%A2%E5%A4%8D/","title":"[Linux]后台进程运行、挂起、恢复"},{"content":"nvm 配置国内镜像 配置nvm镜像 找到nvm目录下的setting.txt 淘宝镜像 1 2 node_mirror: https://npmmirror.com/mirrors/node/ npm_mirror: https://npmmirror.com/mirrors/npm/ 配置npm镜像 打开命令行输入 1 npm config set registry https://registry.npmmirror.com 将镜像配置复制到文件内 nvm常用命令 nvm查看可用版本号 1 2 3 nvm ls available # 或者 nvm list available 类型 说明 CURRENT 当前最新版本 LTS 长期支持版本 OLD STABLE 旧稳定版本 OLD UNSTABLE 旧非稳定版本 安装node 1 nvm install \u0026lt;version\u0026gt; 显示已安装的列表 1 2 3 nvm ls # 或者 nvm list 卸载指定版本node 1 nvm uninstall \u0026lt;version\u0026gt; 使用指定版本node 1 nvm use \u0026lt;version\u0026gt; ","date":"2025-10-22T20:36:07+08:00","permalink":"https://YLine-hub.github.io/p/windowsnvm%E9%85%8D%E7%BD%AE%E9%95%9C%E5%83%8F%E5%8F%8A%E4%BD%BF%E7%94%A8/","title":"[Windows]nvm配置镜像及使用"},{"content":"docker docker理念 一次镜像，处处运行。 docker是什么 Docker是基于Go语言实现的云开源项目。\nDocker的主要目标是“Build，Ship and Run Any App，Anywhere”，也就是通过对应组件的封装、分发、部署、运行的那个生命周期的管理，使用户的APP（可以是一个WEB应用或数据库应用等等）及其运行环境能呕做到“一次镜像，处处运行”。\nLinux容器技术的出现就解决了这样一个问题，而Docker就是在它的基础上发展过来的。将应用打成镜像，通过镜像成为运行在Docker容器上面的实例，而Docker容器在任何操作系统上都是一致的，这就实现了跨平台、跨服务器。只需要一次配置好环境，换到别的机子上就可以一键部署好，大大简化了操作。\n总结：解决了运行环境和配置问题的软件容器，方便做持续集成并有助于整体发布的容器虚拟化技术。\n容器与虚拟机 虚拟机 虚拟机：带环境安装的一种解决方案。它可以在一种操作系统里运行另一种操作系统。\n缺点： 资源占用多 冗余步骤多 启动慢 Linux容器 Linux容器：与系统其它部分隔离开的一系列进程，从另一个镜像运行，并由该镜像提供支持进程所需的全部文件。\n对比 Docker容器是在操作系统层面上实现虚拟化，直接复用本地主机的操作系统，而传统虚拟机则是在硬件层面实现虚拟化。与传统虚拟机相比，Docker优势体现为启动速度快，占用体积小。\nDocker与传统虚拟机：\n传统虚拟机技术是虚拟出一套硬件后，在其上运行一个完整操作系统，在该系统上再运行所需应用进程； 容器内的应用进程直接运行于宿主的内核，容器内没有自己的内核且也没有进行硬件虚拟。因此容器要比传统虚拟机更为轻便。 每个容器之间相互隔离，每个容器有自己的文件系统，容器之间进程不会相互影响，能区分计算资源。 docker作用 一次构建、随处运行。 更快速的应用交付和部署 更便捷的升级和扩缩容。 更简单的系统运维。 更高效的计算资源利用。 docker三要素 镜像（image）：一个只读的模板。镜像可以用来创建Docker容器，一个镜像可以创建很多容器。 容器（container）：用镜像创建的运行实例。 仓库（repository）：集中存放镜像文件的场所。 公开仓库：最大的公开仓库Docker Hub 私有仓库 镜像与容器 从面向对象角度 Docker利用容器独立运行的一个或一组应用，应用程序或服务运行在容器里，容器就类似于一个虚拟化的运行环境，容器是用镜像创建的运行实例。就像是Java中的类和实例对象一样，镜像是静态的定义，容器是镜像运行时的实体。容器为镜像提供了一个标准的和隔离的运行环境，它可以被启动、开始、停止、删除。每个容器都是相互隔离的、保证安全的平台。\n从镜像容器角度 可以把容器看作是一个简易版的Linux环境（包括root用户权限、进程空间、用户空间和网络空间等）和运行在其中的应用程序。\nCentOS7上安装docker 检查centos内核版本 Docker要求CentOS系统的内核版本高于3.10，验证CentOS版本是否支持Docker。 1 uname -r 更新yum包 1 sudo yum update -y 卸载老版本docker 1 2 3 4 5 6 7 8 9 10 11 yum remove docker \\ docker-client \\ docker-client-latest \\ docker-common \\ docker-latest \\ docker-latest-logrotate \\ docker-logrotate \\ docker-selinux \\ docker-engine-selinux \\ docker-engine \\ docker-ce 安装docker所需依赖 1 yum -y install yum-utils device-mapper-persistent-data lvm2 设置docker镜像源为阿里源 1 yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo 安装docker 1 yum -y install docker-ce 问题一：找不到docker-ce阿里云网址 1 2 failure: repodata/repomd.xml from mirrors.aliyun.com_docker-ce_linux_centos_docker-ce.repoyum-config-manager: [Errno 256] No more mirrors to try. http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repoyum-config-manager/repodata/repomd.xml: [Errno 14] HTTP Error 404 - Not Found 启动docker 1 2 3 4 # 设置开机启动 systemctl enable docker # 启动 systemctl start docker 安装成功 检验是否安装成功 1 docker version 第一个docker：hello-world 1 docker run hello-world 问题二：无法连接 1 docker: Error response from daemon: Get \u0026#34;https://registry-1.docker.io/v2/\u0026#34;: dial tcp 96.44.137.28:443: i/o timeout. 问题解决方法在下文\nhello-world运行成功 问题 问题一：找不到docker-ce阿里云网址 解决方法：删除再重新配置\n进入/etc/yum.repos.d目录下 1 cd /etc/yum.repos.d 删除有关docker的镜像 1 rm -rf docker-ce.repo mirrors.aliyun.com_docker-ce_linux_centos_docker-ce.repoyum-config-manager.repo 重新配置docker源，下载 问题二：无法连接 解决方法：修改docker源\n编辑配置文件（默认没有，需要自己创建） 1 vim /etc/docker/daemon.json 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 { \u0026#34;registry-mirrors\u0026#34; : [ \u0026#34;https://docker.registry.cyou\u0026#34;, \u0026#34;https://docker-cf.registry.cyou\u0026#34;, \u0026#34;https://dockercf.jsdelivr.fyi\u0026#34;, \u0026#34;https://docker.jsdelivr.fyi\u0026#34;, \u0026#34;https://dockertest.jsdelivr.fyi\u0026#34;, \u0026#34;https://mirror.aliyuncs.com\u0026#34;, \u0026#34;https://dockerproxy.com\u0026#34;, \u0026#34;https://mirror.baidubce.com\u0026#34;, \u0026#34;https://docker.m.daocloud.io\u0026#34;, \u0026#34;https://docker.nju.edu.cn\u0026#34;, \u0026#34;https://docker.mirrors.sjtug.sjtu.edu.cn\u0026#34;, \u0026#34;https://docker.mirrors.ustc.edu.cn\u0026#34;, \u0026#34;https://mirror.iscas.ac.cn\u0026#34;, \u0026#34;https://docker.rainbond.cc\u0026#34;, \u0026#34;https://do.nark.eu.org\u0026#34;, \u0026#34;https://dc.j8.work\u0026#34;, \u0026#34;https://dockerproxy.com\u0026#34;, \u0026#34;https://gst6rzl9.mirror.aliyuncs.com\u0026#34;, \u0026#34;https://registry.docker-cn.com\u0026#34;, \u0026#34;http://hub-mirror.c.163.com\u0026#34;, \u0026#34;http://mirrors.ustc.edu.cn/\u0026#34;, \u0026#34;https://mirrors.tuna.tsinghua.edu.cn/\u0026#34;, \u0026#34;http://mirrors.sohu.com/\u0026#34; ], \u0026#34;insecure-registries\u0026#34; : [ \u0026#34;registry.docker-cn.com\u0026#34;, \u0026#34;docker.mirrors.ustc.edu.cn\u0026#34; ], \u0026#34;debug\u0026#34;: true, \u0026#34;experimental\u0026#34;: false } 重启docker 1 2 3 4 # 重载生效 systemctl daemon-reload # 重启docker systemctl restart docker 查看镜像是否安装成功 1 docker info 安装docker-compose 1 2 sudo curl -L https://github.com/docker/compose/releases/download/v2.20.2/docker-compose-`uname -s`-`uname -m` -o /usr/local/bin/docker-compose sudo chmod +x /usr/local/bin/docker-compose CentOS9上安装docker 安装步骤 官方文档：Install Docker Engine on CentOS\n环境要求：CentOS Stream 9 或者 CentOS Stream 10\n删除老版本 1 2 3 4 5 6 7 8 sudo dnf remove docker \\ docker-client \\ docker-client-latest \\ docker-common \\ docker-latest \\ docker-latest-logrotate \\ docker-logrotate \\ docker-engine 使用rpm仓库安装 生词： repository / rɪˈpɑːzətɔːri / n、仓库 步骤 安装仓库 1 sudo dnf -y install dnf-plugins-core 设置仓库源 国内源（推荐） 1 sudo dnf config-manager --add-repo https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo 官方源 1 sudo dnf config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo 安装docker引擎 1 2 # 安装最新版本docker引擎 sudo dnf install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin 配置国内镜像加速 1 vim /etc/docker/daemon.json 1 2 3 4 5 6 7 { \u0026#34;registry-mirrors\u0026#34;: [ \u0026#34;https://docker.m.daocloud.io\u0026#34;, \u0026#34;https://hub-mirror.c.163.com\u0026#34;, \u0026#34;https://mirrors.tuna.tsinghua.edu.cn/docker-ce/\u0026#34; ] } 开始docker引擎 1 sudo systemctl enable --now docker 验证 1 sudo docker version 第一个镜像 1 sudo docker run hello-world 报错 docker: Error response from daemon: Get \u0026ldquo;https://registry-1.docker.io/v2/\": dial tcp: lookup registry-1.docker.io on 172.16.140.2:53: no such host\n解决方法：配置DNS\n设置静态ip及dns:\n查看网络信息 1 ifconfig 可以看到网卡为ens160\n查找网络文件 1 2 # 在/etc目录文件匹配关键字\u0026#39;ens160\u0026#39;查找 grep -rnw \u0026#39;/etc\u0026#39; -e \u0026#39;ens160\u0026#39; 编辑网络配置文件 1 vim /etc/NetworkManager/system-connections/ens160.nmconnection 初始网络配置文件 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 [connection] id=ens160 uuid=cda03551-52cb-3117-ac32-60f962d7c856 type=ethernet autoconnect-priority=-999 interface-name=ens160 timestamp=1760902922 [ethernet] [ipv4] method=auto [ipv6] addr-gen-mode=eui64 method=auto [proxy] 添加如下内容 1 2 3 4 [ipv4] ... address1=ip/24,gateway dns=dnsip1;dnsip2; 重新加载配置文件 1 nmcli c reload 启动ens160网卡 1 nmcli c up ens160 再次运行hello-world 1 docker run hello-world 卸载 阿里云镜像加速器配置 登陆阿里云，并点击控制台 在控制台中点击左上角的三横杠 在产品与服务中找到容器镜像服务 选择镜像工具下的镜像加速器 通过操作文档配置镜像加速 1 2 3 4 5 6 7 8 sudo mkdir -p /etc/docker sudo tee /etc/docker/daemon.json \u0026lt;\u0026lt;-\u0026#39;EOF\u0026#39; { \u0026#34;registry-mirrors\u0026#34;: [\u0026#34;https://********.mirror.aliyuncs.com\u0026#34;] } EOF sudo systemctl daemon-reload sudo systemctl restart docker 为什么docker会比虚拟机块 docker有着比虚拟机更少的抽象层 由于docker不需要Hypervisor（虚拟机）实现硬件资源虚拟化，运行在docker容器上的程序直接使用的都是实际物理机的硬件资源。因此在CPU、内存利用率上docker将会在效率上有明显优势。\ndocker利用的是宿主机的内核，而不需要加载操作系统OS内核 当新建一个容器时，docker不需要和虚拟机一样重新加载一个操作系统内核。进而避免引寻、加载操作系统内核返回等比较费事费资源的过程，当新建一个虚拟机时，虚拟机软件需要加载OS，返回新建过程时分钟级别的。而docer由于直接利用宿主机的操作系统，则省略了返回过程，因此新建一个docker容器只需要几秒钟。\nDocker容器 虚拟机（VM） 操作系统 与宿主机共享OS 宿主机OS上运行虚拟机OS 存储大小 镜像小，便于存储和传输 镜像庞大（vmdk、vdi等） 运行性能 几乎无额外性能损失 操作系统额外的CPU、内存消耗 移植性 轻便、灵活，适应于Linux 笨重，与虚拟化技术耦合度高 硬件亲和性 面向软件开发者 面向硬件运维者 部署速度 速度快，秒级 较慢，10s以上 Docker常用命令 帮助启动类 启动类 1 2 3 4 5 systemctl start docker # 启动docker systemctl stop docker # 停止docker systemctl restart docker # 重启docker systemctl status docker # 查看docker状态 systemctl enable docker # 开机启动 帮助类 1 2 3 docker info # 查看docker概要信息 docker --help # 查看docker总体帮助文档 docker 具体命令 help # 查看docker命令帮助文档 镜像命令 查询本地镜像 1 docker images 列名 说明 REPOSITORY 表示镜像的仓库源 TAG 镜像的标签版本号 IMAGE ID 镜像ID CREATED 镜像创建时间 VIRTUAL SIZE 镜像大小 同一个仓库源有多个TAG版本，代表这个仓库源的不同个版本，我们使用REPOSITORY:TAG来定义不同的镜像。如果你不指定一个镜像的版本标签，例如你只使用ubuntu，docker将默认使用ubuntu:latest镜像\noptions 参数 说明 -a 列出本地所有的镜像（含历史映像层） -q 只显示镜像ID 列出所有镜像ID 1 docker images -qa 搜索仓库镜像 1 docker search INAEM（镜像名称） 参数 说明 NAME 镜像名称 DESCRIPTION 镜像描述 STARS 点赞数量 OFFICIAL 是否是官方的 AUTOMATED 是否是自动构建的 options:\n--limit N:只列出N个镜像，默认25个 查询前5个名称中有redis的镜像\n1 docker search --limit 5 redis 拉取镜像 下载最新版 1 docker pull \u0026lt;image-name\u0026gt; 下载指定版本 1 docker pull \u0026lt;image-name\u0026gt;[:TAG] 下载redis:6.0.8 生词 suppress / səˈpres / v、（武力）镇压；阻止（进程）；隐瞒（消息） verbose / vɜːrˈboʊs / adj、冗长的；啰嗦的 查看镜像/容器/数据卷所占空间 1 docker system df 列名 说明 TYPE 类型 TOTAL 总数 ACTIVE 正在使用数 SIZE 大小 RECLAIMABLE 可回收的磁盘空间大小 TYPE 说明 Images 镜像 Containers 容器 Local Volumes 本地卷（用于持久化数据） Build Cache 建缓存（用于加速 Docker 构建过程） 生词 reclaimable / rɪˈkleɪməbəl / adj、可回收的 volumes / ˈvɑːljəmz / n、体积，容量；卷 删除镜像 删除镜像 1 docker rmi INAME_or_IMAGEID options 删除单个镜像 1 docker rmi -f INAME_or_IMAGEID 删除多个镜像 1 docker rmi -f INAME1:TAG_or_IMAGEID INAME2:TAG_or_IMAGEID 删除全部镜像 1 docker rmi -f $(docker images -qa) 面试题 谈谈docker虚悬镜像是什么？ 是什么？ 仓库名、标签名都是\u0026lt;none\u0026gt;的镜像，俗称虚悬镜像dangling image\n容器命令 拉取镜像（ubuntu） 1 docker pull ubuntu 新建并启动容器 1 docker run [option] IMAGE [COMMAND] [ARG...] options 参数 说明 \u0026ndash;name=\u0026ldquo;NAME\u0026rdquo; 为容器指定一个名称 -d 后台运行容器并返回容器ID，也即启动守护式容器（后台运行） -i 以交互模式运行容器，通常与-t同时使用 -t 为容器分配一个伪输入终端，与-i同时使用，也即启动交互式容器（前台有伪终端，等待交互） -P 随机端口映射，大写P -p 指定端口映射，小写p docker启动ubuntu 1 2 # 启动ubuntu docker run ubuntu 启动后自动退出 原因：需要用伪终端交互打开\n1 2 3 4 # 使用伪终端交互使用ubuntu，并设置shell交互命令的接口(bin或者/bin/bash) # 在容器内使用bash命令 docker run -it ubuntu /bin/bash docker run -it ubuntu bash 查看docker正在运行的镜像 运行ubuntu并命名myu1 1 docker run -it --name=myu1 ubuntu bash 生词 -i : interactive / ˌɪntərˈæktɪv / adj、交互式的\n-t : tty 终端\nallocate / ˈæləkeɪt / v、分配\n查看容器 1 docker ps [options] options 参数 说明 -a show all containers -l show the latest created container -n show n last created containers -q only display container IDs 展示最后创建的容器 1 docker ps -l 展示正在运行的容器 1 docker ps 展示最后4个创建的容器 1 docker ps -n 4 只展示容器的ID 1 docker ps -q 生词 -q quiet / ˈkwaɪət / n/v、（使）安静 ； adj、安静的；沉默寡言的 退出容器 创建两个容器 1 docker run -it ubuntu bash 方式一：exit\nrun进去容器，exit退出，容器停止 退出容器 0a48ed6d8300\n发现运行中的容器0a48ed6d8300已经没了\n方式二：ctrl+p+q run进去容器，ctrl+p+q退出，容器不停止 使用ctrl+p+q，退出了容器，但是容器还在运行\n启动已经停止的容器 1 docker start CONTAINER_ID_OR_NAME 查看最后两个容器 1 docker ps -n 2 可以看到其中ID为0a48ed6d8300的状态已经停止了\n重启0a48ed6d8300 1 docker start 0a48ed6d8300 可以看到重启的容器状态已经是开启了\n重启容器 1 docker restart CONTAINER_ID_OR_NAME 停止容器 1 docker stop CONTAINER_ID_OR_NAME 强制停止容器 1 docker kill CONTAINER_ID_OR_NAME 删除已停止的容器 1 docker rm CONTAINER_ID 删除正在运行的容器 1 docker rm 0a48ed6d8300 1 2 Error response from daemon: cannot remove container \u0026#34;0a48ed6d8300\u0026#34;: container is running: stop the container before removing or force remove 来自daemon的错误响应：不能移除容器\u0026#34;0a48ed6d8300\u0026#34;，容器正在运行：移除之前停止这个容器或者强制移除 停止容器并删除 1 2 3 4 # 停止容器0a48ed6d8300 docker stop 0a48ed6d8300 # 删除容器0a48ed6d8300 docker rm 0a48ed6d8300 成功删除容器\n再次启动容器0a48ed6d8300 1 2 3 4 5 Error response from daemon: No such container: 0a48ed6d8300 Error: failed to start containers: 0a48ed6d8300 来自daemon的错误响应：没有这样的容器：0a48ed6d8300 错误：启动失败容器：0a48ed6d8300 强制删除容器3c64d193e546 1 docker rm -f 3c64d193e546 一次性删除多个容器 方式一 1 docker rm -f $(docker ps -a -q) 分析：\n1 2 # 查询所有容器，并只展示ID docker ps -a -q 1 2 # 将查询出来的容器IDs作为参数传给 docker rm -f docker rm -f $(docker ps -a -q) 方式二 1 docer ps -a -q | xargs docker rm 分析：\ndocker ps -a -q 查询出来的数据传给xargs，然后作为参数执行docker rm\n容器命令（重要） 下载镜像(redis) 1 docker pull redis 启动守护式容器（后台服务器） 在大部分的场景下，我们希望docker服务式在后台运行的，我们可以过-d指定容器的后台运行模式\n启动守护式容器 1 docker run -d \u0026lt;container_name\u0026gt; ubuntu前后台启动演示:\n使用镜像ubuntu以后台模式启动一个容器 1 docker run -d ubuntu 发现docker中没有运行中的容器\n查看docker容器运行（含历史映像） 1 docker ps -a 发现容器8d9e73743b1b已经退出了\n原因：Docker容器后台运行，就必须有一个前台进程。容器运行的命令如果不是那些一直挂起的命令（比如运行top，tail），就是会自动退出的。\n这个是docker的机制问题，比如你的web容器，我们以nginx为例，正常情况下，我们配置服启动服务只需要启动响应式的service即可。例如service nginx start。但是，这样做，nginx为后台进程模式运行，就导致docker前台没有运行的应用，这样的容器后台启动后，就会立即自杀，因为他觉得他没事可做了。 所以，最佳的解决方案是，将你要运行的程序以前台进程的形式运行，常见就是命令行模式，表示我还有交互操作，别中断。\n前台运行ubuntu 1 docker run -it ubuntu redis前后台启动演示：\n前台交互式启动 1 docker run -it redis 如果不小心关掉，或者ctrl+c退出进程，redis就直接停止服务\n后台守护式启动 1 docker run -d redis 查看容器日志 语法 1 docker logs \u0026lt;container_id\u0026gt; 查看容器 1 docker ps 查看redis容器日志 1 docker logs a55b19d4ab06 查看容器内运行的进程 1 docker top \u0026lt;container_id\u0026gt; 查看redis容器内部运行的进程 1 docker top 查看容器内部细节 1 docker inspect \u0026lt;container_id\u0026gt; 查看redis容器内部细节 1 docker inspect 进入正在运行的容器并以命令行交互 方法一：docker exec\n语法 1 docker exec [options] \u0026lt;container_id\u0026gt; \u0026lt;command\u0026gt; 创建一个ubuntu 1 docker run -it ubuntu /bin/bash id为1fac0e86217b\n使用ctrl+p+q退出容器 查看正在运行的容器 1 docker ps 重新进入ubuntu容器 1 docker exec -it 1fac0e86217b /bin/bash 方法二：docker attach\n1 docker attach \u0026lt;container_id\u0026gt; 进入ubuntu容器 1 docker attach 1fac0e86217b docker exec和docker attach的区别\nattach直接进入容器启动命令的终端，不会启动新的进程用exit退出，会导致容器的停止。 exec是在容器中打开新的终端，并且可以启动新的进程，用exit退出，不会导致容器的停止。\ndocker exec docekr attach 可以看到使用exit退出后就没了\n可以看到容器处于停止状态\n推荐使用exec 进入正在运行的redis容器进行交互 查看容器id 1 docker ps 进入redis容器，使用/bin/bash 1 docker exec -it a55b19d4ab06 /bin/bash 使用redis客户端进入redis 1 redis-cli -p 6379 测试redis功能 退出容器 使用redis客户端打开redis容器 1 docker exec -it a55b19d4ab06 redis-cli 从容器内拷贝拷贝文件到主机上 语法 1 docker cp \u0026lt;container_id\u0026gt;:path destination_path 新建ubuntu 1 docker run -it ubuntu /bin/bash 在容器内创建a.txt文件 1 2 3 4 # 进入临时目录 cd /tmp # 创建a.txt文件 touch a.txt 复制文件a.txt到本地/opt目录下 path:/tmp/a.txt\n1 docker cp 006e879ee419:/tmp/a.txt /opt 查看拷贝的文件 1 ls /opt 导入导出容器 export 导入容器的内容流作为一个tar归档文件[对应import命令] 1 docker export [container_id] \u0026gt; [file_name].tar import 从tar包中的内容创建一个新的文件系统再导入为镜像[对应expor] 1 cat \u0026lt;file_name\u0026gt;.tar | docker import - \u0026lt;image_user\u0026gt;/\u0026lt;image_name\u0026gt;:\u0026lt;image_version\u0026gt; 案例 查询容器id 1 docker ps 导出ubuntu容器(默认导出到当前目录) 1 docker export 006e879ee419 \u0026gt; ubuntu_backup.tar 删除正在运行的ubuntu容器 1 docker rm -f 006e879ee419 导入容器 1 cat ubuntu_back.tar | docker import - yline/ubuntu:6.6.6 运行刚刚导入的镜像，并找到a.txt 1 docker run -it 7fd7d82b1ac0 /bin/bash 生词 detach / dɪˈtætʃ / v、使分离；脱离；派遣 override / ˌoʊvərˈraɪd / v、否决，推翻；比\u0026hellip;.更重要；n、（预算、薪金等）增加；（对决定等的）否决，撤销 sequence / ˈsiːkwəns / v、按顺序排列； n、顺序，次序 alias / ˈeɪliəs / n、别名 destination / ˌdestɪˈneɪʃ(ə)n / n、目的地 Docker镜像 镜像是什么 是一种轻量级、可执行的独立软件包，它包含运行某个软件所需的所有内容，我们把应用程序和配置依赖打包好形成一个可交付的运行环境（包括代码、运行时需要的库、环境变量和配置文件等），这个打包好的运行环境就是image镜像文件。\n只有通过这个镜像文件才能生成Docker容器实例（类似java中new出一个对象）。\n分层的镜像 可以看到镜像下载是一层一层的\nUnionFS（联合文件系统） Unios文件系统（UnionFS）是一种分层、轻量级并且高性能的文件系统，它支持对文件系统的修改作为一次提交来一层层的叠加，同时可以将不同目录挂载到同一个虚拟机文件系统下。Union文件系统时Docker镜像的基础。镜像可以通过分层来进行继承，基于基础镜像（没有父镜像），可以制作各种具体的应用镜像。\n特性：一次同时加载多个文件系统，但从外面看起来，只能看到一个文件系统，联合加载会把各层文件系统叠加起来，这样最终文件系统会包含所有底层文件和目录。 Docker镜像加载原理 Docker的镜像实际上由一层一层的文件系统组成，这样层级的文件系统UnionFS。 bootfs(boot file system)主要包含bootloader和kernel，bootloader主要时引导加载kernel，Linux刚启动时会加载bootfs文件系统，在Docker镜像的最底层是引导文件系统bootfs。这一层与我们典型的Linux/Unix系统是一样的，包含boot加载器和内核。当boot加载器完成之后整个内核就都在内存中了，此时内存的使用权已由bootfs转交给内核，此时系统也会卸载bootfs。 rootfs(root file system)，在bootfs之上。包含的就是典型Linux系统中的/dev，/proc，/bin，/etc等标准目录和文件。rootfs就是各种不同的操作系统发行版，比如Ubuntu，Centos等等。 镜像分层最大的一个好处就是共享资源，方便复制迁移，就是为了复用\n比如说由多个镜像都从相同base镜像构建而来，那么Docker Host只需要在磁盘上保存一份base镜像；同时内存中也只需加载一份base镜像，就可以为所有容器服务了。而且镜像的每一层都可以被共享。\n重点理解 Docker镜像层都是只读的，容器层是可读的。 当容器启动时，一个新的可写层被加载到镜像的顶部。这一层通常被称作“容器层”，“容器层”之下的都叫“镜像层”。\nDocker镜像commit操作案例 案例：创建并官方ubuntu（无vim），给它安装vim命令，提交使之成为一个新的镜像（自带vim的ubuntu）\n启动ubuntu容器 1 docker run -it ubuntu /bin/bash 启动容器839be55792c9\n检测是否带有vim命令 1 vim a.txt 显示： bash: vim: command not found\n安装vim命令\n更新包管理工具，并等待更新 1 apt-get update 安装vim 1 apt-get install vim -y 检测vim命令 1 vim a.txt 提交容器副本使之成为一个新的镜像\n1 docker commit -m=\u0026#34;注释\u0026#34; -a=\u0026#34;作者\u0026#34; 容器ID 包名/镜像名:版本号 1 docker commit -m=\u0026#34;add vim cmd\u0026#34; -a=\u0026#34;yline\u0026#34; 839be55792c9 yline/myubuntu:1.1 查看镜像 1 docker images 能看到，只加了一个vim就从78.1MB变成了205MB\n启动新镜像与原来的对比 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # 查看本地镜像 docker images # 启动官方docker docker run -it ubuntu /bin/bash # 测试vim命令 vim a.txt # 退出 exit # 启动刚刚提交的镜像 docker run -it 18e98d78449d /bin/bash # 测试vim命令 vim a.txt # 查看a.txt cat a.txt 从中可以看到刚刚提交的镜像，默认自带vim命令，以及之前创建的a.txt，也会默认自带。也就是得到了原本镜像的vim扩展镜像。\n小总结 Docker中的镜像分层，支持通过扩展镜像，创建新的镜像。类似Java继承于一个Base基础类，自己再按需扩展。新镜像是从base镜像一层一层叠加生成的。每安装一个软件，就在现有镜像的基础上增加一层。\n本地镜像发布到阿里云 流程图 镜像的生成方法 1 docker commit [OPTIONS] 容器ID [RRPOSITORY[:TAG]] 示例 1 docker commit -m=\u0026#34;add vim cmd\u0026#34; 18e98d78449d yline/myubuntu:1.1 将本地镜像推送到阿里云 本地镜像素材原型 阿里云 阿里云 创建仓库镜像 打开阿里云首页，进入控制台 进入容器镜像服务 选择个人实例 创建个人实例 选择第一个地域（一般第一个对于当前网络是最快的） 同意使用须知后，点击立即创建 设置Registry登陆密码 设置完成后点击命名空间 创建命名空间 点击镜像仓库 创建镜像仓库 选择刚刚创建的命名空间，并输入仓库名称和摘要 选择本地仓库，然后点击创建镜像仓库 通过镜像推送命令，将镜像推送到阿里云 1 2 3 $ docker login --username=ylinehub **********.cn-hangzhou.personal.cr.aliyuncs.com $ docker tag [ImageId] **********.cn-hangzhou.personal.cr.aliyuncs.com/yline/myubuntu:[镜像版本号] $ docker push **********.cn-hangzhou.personal.cr.aliyuncs.com/yline/myubuntu:[镜像版本号] 将镜像推送到阿里云 查询需要推送的镜像id 1 docker images 镜像ID：18e98d78449d\ndocker登陆阿里云仓库 1 docker login --username=ylinehub **********.cn-hangzhou.personal.cr.aliyuncs.com 登陆成功\n标记镜像 1 docker tag 18e98d78449d **********.cn-hangzhou.personal.cr.aliyuncs.com/yline/myubuntu:1.1 推送镜像 1 docker push **********.cn-hangzhou.personal.cr.aliyuncs.com/yline/myubuntu:1.1 推送成功\n在阿里云上选择镜像版本，查看镜像 将阿里云上的镜像拉取到本地 1 docker pull **********.cn-hangzhou.personal.cr.aliyuncs.com/yline/myubuntu:[镜像版本号] 删除本地镜像 1 docker rmi -f 18e98d78449d 下载镜像 1 docker pull *********.cn-hangzhou.personal.cr.aliyuncs.com/yline/myubuntu:1.1 查看镜像 1 docker images 运行镜像并测试 1 2 # 运行镜像 docker run -it 18e98d78449d /bin/bash docker私有库 是什么 Docker Registry 将本地镜像推送到私有库 下载镜像Docker registry 1 docker pull registry 运行私有库registry，相当于本地有个私有Docker hub 1 docker run -d -p 5000:5000 -v /yline/myregistry/:/tmp/registry --privileged=true registry -d 表示容器在后台运行，-p 表示端口映射，这里是宿主机5000端口和容器5000端口映射。默认情况下，仓库创建在容器的/var/lib/registry目录下，建议自行用容器卷映射，方便与宿主机联调\n案例演示创建一个新镜像，ubuntu安装ifconfig命令 从hub上下载ubuntu镜像到本地并成功运行 1 docker run -it ubuntu /bin/bash 容器id为35c637630e00\n原始的ubuntu镜像是不带着ifconfig命令 1 ifconfig 外网连通的情况下，安装ifconfig命令测试并通过 1 2 3 apt-get update apt-get install net-tools ifconfig 使用ctrl+p+q退出容器\n查看容器\n1 docker ps commit新镜像 1 docker commit -m=\u0026#34;add ifconfig cmd\u0026#34; -a=\u0026#34;yline\u0026#34; 35c6e7630e00 ylineubuntu:1.2 查看镜像 1 docker images 启动我们的新镜像并和原来的对比 1 docker run -it 60bd00c20db2 /bin/bash curl 验证私服库上有什么镜像 查询宿主机ip 1 hostname -i 可以看到ip为192.168.172.137\n使用curl向宿主机的5000端口的 /v2/_catalog接口 发送get请求 1 curl -XGET http://192.168.172.137:5000/v2/_catalog 红框内表示仓库此时没有任何镜像\n将新镜像ylineubuntu:1.2修改符合私服规范的Tag 语法\n1 docker tag 镜像:Tag Host:Port/Repository:Tag 1 docker tag ylineubuntu:1.2 192.168.172.137:5000/ylineubuntu:1.2 修改配置文件使之支持http 打开/etc/docker/daemon.json\n1 vim /etc/docker/daemon.json 添加如下配置\n1 2 3 { \u0026#34;insecure-registries\u0026#34;:[\u0026#34;192.168.172.137:5000\u0026#34;] } 修改后的配置如下\n1 2 3 4 5 6 7 8 9 10 { \u0026#34;registry-mirrors\u0026#34;: [ \u0026#34;https://alzgoonw.mirror.aliyuncs.com\u0026#34;, \u0026#34;https://docker.m.daocloud.io\u0026#34;, \u0026#34;https://dockerhub.icu\u0026#34;, \u0026#34;https://docker.anyhub.us.kg\u0026#34;, \u0026#34;https://docker.1panel.live\u0026#34; ], \u0026#34;insecure-registries\u0026#34;: [\u0026#34;192.168.172.137:5000\u0026#34;] } 重新加载配置，并重启docker 1 2 systemctl daemon-reload systemctl restart docker push推送到私服库 公式\n1 docker push 容器名 查看容器名\n1 docker images 推送到仓库\n1 docker push image_name:image_tag 1 docker push 192.168.172.137:5000/ylineubuntu:1.2 出现报错：connection refused 查看docker运行的容器 1 docker ps 因为docker服务重启，所以docker容器都关闭了\n重启docker私服库 1 docker ps -a 1 docker start 7f08a89d1fd9 再次推送镜像到仓库 1 docker push 192.168.172.137:5000/ylineubuntu:1.2 请求仓库，查看仓库 1 curl -XGET http://192.168.172.137:5000/v2/_catalog pull到本地运行 1 2 # 删除本地镜像 docker rmi -f 192.168.172.137:5000/ylineubuntu:1.2 1 2 # 拉取镜像 docker pull 192.168.172.137:5000/ylineubuntu:1.2 测试 1 2 docker run -it 192.168.172.137:5000/ylineubuntu:1.2 /bin/bash ifconfig 生词 volume / ˈvɑːljəm / n、体积；总数；音量；卷 bind / baɪnd / v、使紧密联系；捆绑 mount / maʊnt / v、组织；爬上；增多； 网络释义、挂载 privilege / ˈprɪvəlɪdʒ / v、给予特权；免除（某人） n、特权； docker容器数据卷 坑：容器卷记得加入 --privileged=true Docker挂载主机目录访问如果出现 cannot open directory .: Permission denied\n解决办法： 在挂载目录后多加一个\u0026ndash;privileged=true参数即可。保证拥有root用户的权限。\n简介 映射，容器内的数据备份+持久化到本地主机目录\n一句话：有点类似我们Redis里面的rdb和aof文件。将docker容器内的数据保存进宿主机的磁盘中，运行一个带有容器卷存储功能的容器实例。\n语法\n1 docker run -it --privileged=true -v /宿主机绝对路径目录:/容器内目录 镜像名 作用 将运用与运行的环境打包镜像，run后形成容器实例运行，但是我们对数据的希望是持久化的\nDocker 容器产生的数据，如果不备份，那么当容器实例被删除后，容器内的数据自然也没有了。为了能保存数据在docker中我们使用卷。\n特点：\n数据卷可在容器之间共享或重用数据。 卷中的更改可以直接实时生效。 数据卷中的更改不会包含在镜像的更新中。 数据卷的生命周期一直持续到没有容器使用它为止。 案例 宿主vs容器之间映射添加容器卷 命令 1 docker run -it --privileged=true -v /宿主机绝对路径目录:/容器内目录 镜像名 映射ubuntu容器内的/tmp/docker_data到本地的/tmp/host_data 1 docker run -it --privileged=true -v /tmp/host_data:/tmp/docker_data --name=u1 ubuntu 进入映射的卷，并创建一个文件 1 2 3 cd /tmp/docker_data/ touch dockerin.txt ls 查看宿主机挂载的目录 1 ls /tmp/host_data 在宿主机的目录下添加文件并修改 1 2 touch hostin.txt echo \u0026#39;hello docker\u0026#39; \u0026gt; a.txt 查看容器下的目录 使用docker inspect 容器ID 1 docker inspect 在其中找到Mounts这段 1 2 3 4 5 6 7 8 9 10 \u0026#34;Mounts\u0026#34;: [ { \u0026#34;Type\u0026#34;: \u0026#34;bind\u0026#34;, # 类型：绑定 \u0026#34;Source\u0026#34;: \u0026#34;/tmp/host_data\u0026#34;, # 源目录 \u0026#34;Destination\u0026#34;: \u0026#34;/tmp/docker_data\u0026#34;, # 目标目录 \u0026#34;Mode\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;RW\u0026#34;: true, \u0026#34;Propagation\u0026#34;: \u0026#34;rprivate\u0026#34; } ], 停止容器然后修改映射目录 停止容器 1 docker stop 1e15ae792fb2 创建文件 1 echo \u0026#39;stop: hello docker\u0026#39; \u0026gt; c.txt 重启容器并查看 1 2 3 4 docker start 1e15ae792fb2 docker exec -it 1e15ae792fb2 /bin/bash cd /tmp/docker_data/ cat c.txt 读写规则映射添加说明 读写（默认） 语法：与上述案例相同，不加读写规则，默认就是rw 1 docker run -it --privileged=true -v /宿主机绝对路径目录:/容器内目录:rw 镜像名 只读 语法（ro：read only） 1 docker run -it --privileged=true -v /宿主机绝对路径目录:/容器内目录:ro 镜像名 在容器内：只能读取，不能写入。\n在宿主机：可以读写，宿主机写入内容，容器可以读取到。\n1 docker run -it --privileged=true -v /mydocker/u:/tmp/u:ro --name u2 ubuntu 宿主机写入数据 1 2 cd /mydocker/u/ echo \u0026#39;u2: host update\u0026#39; \u0026gt; a.txt 容器内部查看 1 2 3 cd /tmp/u/ ls cat a.txt 在容器内创建文件 1 touch b.txt 卷的继承和共享 容器u3完成和宿主机的映射 创建容器u3 1 docker run -it --privileged=true -v /mydocker/u3:/tmp/u --name u3 ubuntu 进入映射目录下，并创建文件 1 2 3 4 cd /tmp/u ls touch u3data.txt ls 容器u4继承容器u3的卷规则 语法 1 docker run -it --privileged=true --volumes-from 父容器名 --name 子容器名 镜像名 创建容器u4，并继承容器u3的卷规则 1 docker run -it --privileged=true --volumes-from u3 --name u4 ubuntu 进入/tmp/u目录下并查看 1 2 cd /tmp/u/ ls 在u4容器创建新文件 1 touch u4data.txt 在宿主机创建新文件，并查看文件 1 2 3 cd /mydocker/u3/ touch hostdata.txt ls 容器u3下该目录 容器u4下该目录 docker 上安装常用软件 总体步骤 搜索镜像 官方仓库网址：dockerhub\n1 docker search 拉取镜像 1 docker pull 查看镜像 1 docker images 启动镜像 1 docker run 停止镜像 1 docker stop 移除镜像 1 docker rmi 安装tomcat 最新版 进入dockerhub官网:docker hub 搜索tomcat 点击三个点会弹出拉取该版本的命令 我们直接用默认命令，拉取最新版本 1 docker pull tomcat 因为我们已经下载了，所以这里没有再下载\n查看镜像 1 docker images tomcat 使用tomcat镜像创建容器实例 1 docker run -d -p 8080:8080 --name t1 tomcat 访问tomcat 浏览器输入：ip:8080\n问题 404 进入tomcat 1 docker exec -it 2839835a050a /bin/bash 查看当前目录下的文件 tomcat返回的页面在webapps下\n进入webapps目录，并查看 1 2 cd webapps ll 发现该目录下并没有文件\n原因：新版本tomcat，将文件放在了webapps.dist目录下\n解决方法：删除webapps目录，并将webapps.dist 目录重命名为webapps\n1 2 rm -r webapps mv webapps.dist/ webapps ctrl+f5强制刷新页面 免修改版 删除最新版容器 1 2 docker stop t1 docker rm -f t1 下载免修改版 1 docker pull billygoo/tomcat8-jdk8 运行免修改版 1 docker run -d -p 8080:8080 --name mytomcat8 billygoo/tomcat8-jdk8 使用浏览器打开 安装mysql docker hub上查找mysql镜像 从docker hub上（阿里云加速器）拉取mysql镜像到本地标签为5.7 拉取mysql:5.7镜像 1 docker pull mysql:5.7 使用mysql5.7镜像创建容器（运行容器） 简单版 运行容器 1 docker run -p 3306:3306 -e MYSQL_ROOT_PASSWORD=123456 -d mysql:5.7 查看容器 1 docker ps 进入mysql容器 1 docker exec -it 6ffc4c39b796 /bin/bash 进入mysql 1 mysql -uroot -p123456 查看数据库 1 show databases; 创建数据库 1 create database db01; 使用数据库 1 use db01; 创建表 1 create table t1(id int,name varchar(20)); 插入数据 1 insert into t1 values(1,\u0026#39;z3\u0026#39;); 查询数据 1 select * from t1; 使用navicat连接mysql\n点击连接选择mysql 输入连接名，主机ip和密码，并点击测试连接 点击确定，连接mysql 右键db01数据库，点击新建查询 可以在查询界面，实现sql操作\n查询t1表，并插入数据 1 2 3 select * from t1; insert into t1 values (2,\u0026#39;li4\u0026#39;); insert into t1 values (3,\u0026#39;王五\u0026#39;); 问题一：插入中文数据后报错\n插入带中文的数据 1 insert into t1 values (3,\u0026#39;王五\u0026#39;); 1 报错信息：1366 - Incorrect string value: \u0026#39;\\xE7\\x8E\\x8B\\xE4\\xBA\\x94\u0026#39; for column \u0026#39;name\u0026#39; at row 1 原因：docker上默认字符集编码隐患\n在mysql容器里查看字符集 1 SHOW VARIABLES LIKE \u0026#39;character%\u0026#39;; 不建议在navicat中执行，他会自动将一些客户端设置成utf8mb4 问题二：删除容器后，里面的mysql数据怎么办\n实战版 删除数据库 1 docker rm -f 6ffc4c39b796 新建mysql容器实例 1 docker run -d -p 3306:3306 --privileged=true -v /yline/mysql/log:/var/log/mysql -v /yline/mysql/data:/var/lib/mysql -v /yline/mysql/conf:/etc/mysql/conf.d -e MYSQL_ROOT_PASSWORD=123456 --name mysql mysql:5.7 新建my.cnf，解决无法输入中文问题 1 2 3 4 5 6 # 进入配置文件目录 cd /yline/mysql/conf # 查看当前目录下的文件 ls # 创建并编辑my.cnf文件 vim my.cnf my.cnf\n1 2 3 4 5 [client] default_character_set=utf8mb4 [mysqld] collation_server=utf8mb4_general_ci character_set_server=utf8mb4 查阅配置文件 1 cat my.cnf 重新启动mysql容器实例再重新进入并查看字符编码 1 2 3 4 5 6 # 重启mysql docker restart mysql # 进入mysql容器 docker exec -it mysql /bin/bash # 进入mysql mysql -uroot -p123456 在新建库新建表，插入中文测试 1 2 3 4 5 6 7 8 9 10 11 # 字符集编码格式 SHOW VARIABLES LIKE \u0026#39;character%\u0026#39;; # 创建db01数据库 create database db01; # 使用db01数据库 use db01; # 创建t1表 create table t1 (id int,name varchar(20)); # 插入数据 insert into t1 values(1,\u0026#39;z3\u0026#39;)； insert into t1 values(2,\u0026#39;王五\u0026#39;); 删除mysql，并再次启动 1 2 3 4 # 删除mysql数据库 docker rm -f mysql # 新建mysql docker run -d -p 3306:3306 --privileged=true -v /yline/mysql/log:/var/log/mysql -v /yline/mysql/data:/var/lib/mysql -v /yline/mysql/conf:/etc/mysql/conf.d -e MYSQL_ROOT_PASSWORD=123456 --name mysql mysql:5.7 进入mysql查询数据 1 2 3 4 5 6 # 进入mysql容器 docker exec -it mysql /bin/bash # 进入mysql mysql -uroot -p123456 # 查询数据库 show databases; 进入db01库，并查看数据是否还在 1 2 3 use db01; show tables; select * from t1; 结论 假如将当前容器实例删除，再重新来一次，之前建的db01实例和建的表数据都还存在。\n安装redis 拉取redis镜像 1 docker pull redis:6.0.8 在宿主机下新建目录/app/redis 1 mkdir -p /app/redis 上传原始的redis.conf文件到/app/redis目录下 1 cd /app/redis 修改redis.conf文件 1 2 3 4 5 6 7 8 9 10 # 开启redis验证 （可选） requirepass 123456 # 注释掉bind 127.0.0.1 ，表示允许redis外地连接 # bind 127.0.0.1 # 将daemonize yes注释起来或者 设置 daemonize no，因为该配置和docker run中-d参数冲突，会导致容器一直启动失败 daemonize no # 开启redis数据持久化 appendonly yes （可选） redis 验证我就不开启了\n运行redis 1 docker run -d -p 6379:6379 --name myredis --privileged=true -v /app/redis/redis.conf:/etc/redis/redis.conf -v /app/redis/data:/data -d redis:6.0.8 redis-server /etc/redis/redis.conf 验证宿主机redis.conf是否生效 进入redis容器 1 docker exec -it myredis /bin/bash 使用redis-cli连接redis 选择数据库15 1 select 15 在宿主机修改redis.conf 1 vim /app/redis/redis.conf 1 databases 10 修改成databases 10，并保存\n重启redis 1 docker restart myredis 再次进入测试 1 2 3 docker exec -it myredis /bin/bash redis-cli select 15 此时可以看到，数据库15已经超出了选择范围\n","date":"2025-10-19T22:51:05+08:00","permalink":"https://YLine-hub.github.io/p/linuxdocker%E5%9F%BA%E7%A1%80/","title":"[Linux]docker基础"},{"content":"Linux网络管理命令 netstat 简介 用于显示网络状态 语法 1 netstat [options] 常用参数 参数 含义 -n 不解析域名，以数字显示 -a 显示所有连线中的Socket -t 列出tcp网络封包的数据 -u 列出udp网络封包的数据 -p pid，显示进程号 -l 仅列出在监听的服务状态 -i 列出网卡信息 -r 列出路由表信息 列名分析 netstat -a 1 netstat -a | head 列名 含义 备注 proto(protocol) 网络连接的协议类型 如tcp、udp等 Recv-Q 接收socket(套接字)队列中的数据量 以字节为单位 Send-Q 发送socket(套接字)队列中的数据量 以字节为单位 Local Address 运行netstat命令的本地计算机地址 Foreign Address 与本机端口通信的外部eocket地址 State 每个服务网络连接的状态 netstat -r 1 netstat -r 列名 含义 备注 Destination 目标计算机的地址 Gateway 中间网关地址 Genmask 网络掩码 用于指定网络中的可用主机 Flags 标识路由类型 MSS 默认最大段大小 Window 默认窗口大小 irtt 发送信号并接收其确认的总时间 Iface 数据表将通过其路由的接口 netstat -i 1 netstat -i 列名 含义 备注 Iface 接口类型 MTU 最大传输单位 RX 接收数据包 TX 发送数据包 OK 无错误数据包 ERR 有错误数据包 DRR 丢包数量 OVR 数据包由于溢出而丢失 Fig 定义接口配置的标志 示例 显示系统网络状态的所有连接 1 netstat -a 显示系统网络状态的UDP连接信息 1 netstat -anu 显示网卡状态信息 1 netstat -i 显示网络路由表信息 1 netstat -r 查看关于sshd的PID值 1 netstat -p | grep ssh 使用管道符查看某个在运行的服务信息 1 nestat -antup | grep mysql 访问每种协议的统计信息 1 netstat -s ss 简介 显示套接字信息。（与netstat相似，速度更快更高效） 语法 filter : 过滤器\n1 ss [options] [filter] 基本参数 参数 含义 -n 不解析域名 -a 显示所有套接字 -l 仅显示监听状态的套接字 -o 显示TCP计时器信息 -e 显示详细的套接字信息 -m 显示socket的内存情况 -p 显示使用套接字的过程 -i 显示内部的TCP信息 -s 显示socket使用情况 -4 显示ipv4的套接字信息 -6 显示ipv6的套接字信息 -0 显示PACKET套接字信息 -t 显示TCP套接字信息 -u 显示UDP套接字信息 -d 显示DCCP套接字信息 -w 显示RAW套接字信息 -D 将原始TCP套接字信息转储到文件 -r 解析IP和端口号，解析主机名 列名分析 ss 1 ss | head -5 列名 含义 备注 Netid 网络标识符 State 每个服务的连接状态 Recv-Q 接收socket(套接字)队列中的数据量 以字节为单位 Send-Q 发送socket(套接字)队列中的数据量 以字节为单位 Local Address 运行本地的计算机地址 Port 服务端口 Peer Address 对等地址 常用命令 显示本地打开的所有端口 1 ss -l 显示每个进程具体打开的socket 1 ss -pl 显示所有tcp socket 1 ss -t -a 显示所有的udp socket 1 ss -u -a 显示所有已建立的SMTP连接 1 ss -o state established \u0026#39;( dport = :smtp or sport = :smtp )\u0026#39; 显示所有已建立的HTTP连接 1 ss -o state established \u0026#39;( dport = :http or sport = :http )\u0026#39; 找出所有连接X服务器的进程 1 ss -x src /tmp/.X11-unix/* 列出当前socket详细信息 1 ss -s 实例 列出已建立的连接 默认情况，只使用ss命令，不加任何参数的情况下，它会显示所有已建立连接的套接字列表信息 1 2 3 4 5 # 统计行数 ss | wc -l # 列出前三条 # 同 ss | head -3 ss | head -n 3 监听TCP协议的套接字信息 可以使用-l参数监听所有tcp协议的套接字内容 1 ss -lt 查看主机监听的端口 -n表示不解析域名，显示的是IP+端口的格式 1 ss -tnl 显示在运行进程的信息 需要使用到-p的参数，结合-tl是显示tcp协议的服务并且处于监听状态下的信息 1 ss -tlp 显示所有已经建立的信息 需要使用-a参数，表示显示所有的连接信息 1 ss -a | wc -l 还可以在加上-t -n参数使用 1 2 ss -ant ss -nt 显示套接字的使用信息 显示使用信息需要用到-s的参数 1 ss -s 匹配远程与本地地址和端口号 匹配远程地址和端口号 1 2 3 ss dst ip # 或者 ss dst ip:端口号 匹配本地端口和端口号 1 2 3 ss src ip # 或者 ss src ip:端口号 显示来源端口小于50的端口号的内容 1 ss -ntul sport lt 50 ss列出在FIN-WAIT-1状态的http、https连接 1 ss -o state fin-wait-1 \u0026#39;( sport = :http or sport = :https )\u0026#39; nc 简介 用于设置路由器 主要作用 实现任意 TCP/UDP 端口的侦听，nc 可以作为 server 以 TCP 或 UDP 方式侦听指定端口 端口的扫描，nc 可以作为 client 发起 TCP 或 UDP 连接 机器之间传输文件 机器之间网络测速 常用参数 参数 含义 -p\u0026lt;通信端口\u0026gt; 设置本地主机使用的通信端口 -l 监听模式 -u 使用UDP传输(tcp 不带参数，默认) -v 显示指令执行过程 -w\u0026lt;超时秒数\u0026gt; 设置连接超时时间 -z 使用0输入/输出模式，只在扫描通信端口时使用 实例 tcp端口扫描 1 nc -v -z -w 1 192.168.254.130 20-23 扫描192.168.254.130的端口，范围是20-23，-w 1表示1秒超时，v表示详细输出\nudp端口扫描 1 nc -u -z -w 2 192.168.254.130 20-23 扫描80端口 1 nc -nvv 192.168.254.130 80 扫描22端口 1 nc -nvv 192.168.254.130 22 终端之间通信聊天 服务端监听服务, 客户端请求 (服务端 \u0026lt;== 请求 ==\u0026gt; 客户端) 文件传输 ","date":"2025-10-17T13:38:23+08:00","permalink":"https://YLine-hub.github.io/p/linux%E7%BD%91%E7%BB%9C%E7%AE%A1%E7%90%86%E5%91%BD%E4%BB%A4/","title":"[Linux]网络管理命令"},{"content":"使用攻略 快捷键(win) 文本操作 ctrl + \u0026lt;- : 移动到整个单词前面 ctrl + -\u0026gt; : 移动到整个单词后面 home : 移动到行首 end : 移动到行尾 ctrl + home : 移动到文件首行 ctrl + end : 移动到文件末行 ctrl + shift + k : 删除当前行 ctrl + L(小写) : 选中光标所在行 键盘没有home和end键 快捷键 功能 备注 shift+7(小键盘) home 或者关闭Num灯直接按7 shift+1(小键盘) end 或者关闭Num灯直接按1 快捷打开 ctrl+` : 快速打开命令行 快捷键(mac) 文本操作 command + shift + k : 删除当前行 mac和win的按键对应 mac win Command Win Option Alt Control Ctrl Delete Backspace Return Enter 注意：快捷键中 mac 的command 对应 win 的ctrl\n","date":"2025-10-17T12:53:41+08:00","permalink":"https://YLine-hub.github.io/p/vscode%E4%BD%BF%E7%94%A8%E6%94%BB%E7%95%A5/","title":"[VScode]使用攻略"},{"content":"安装前准备 卸载mariadb 查看是否安装mariadb 1 rpm -qa | grep mariadb 卸载 1 rpm -e --nodeps mariadb-libs-5.5.60-1.el7_5.x86_64 查看那是否卸载干净 1 rpm -qa | grep mariadb 检查依赖 libaio 查看是否安装libaio 1 rpm -qa | grep libaio 如果没有安装则执行 1 yum install libaio -y numactl 检查是否安装numactl 1 rpm -qa | grep numactl 如果没有则执行安装 1 yum install -y numactl 安装mysql 下载依赖包 检查glibc版本 1 ldd --version 下载相应glibc版本的mysql 直接下载安装包并上传到服务器，或者复制下载地址 在服务器上下载 1 wget https://downloads.mysql.com/archives/get/p/23/file/mysql-8.0.35-linux-glibc2.17-x86_64.tar.xz 解压并重命名 注：本文上传到了/opt目录下\n进入下载目录 1 cd /opt 解压安装包 1 tar -xvf mysql-8.0.35-linux-glibc2.17-x86_64.tar.xz 移动解压目录到/usr/local目录下并改名为mysql 1 mv mysql-8.0.35-linux-glibc2.17-x86_64 /usr/local/mysql 创建存储数据文件夹 1 mkdir /usr/local/mysql/data 设置用户组并赋权 创建用户组 1 groupadd mysql 创建用户(无登录模式) 1 useradd -s /usr/sbin/nologin -r -g mysql mysql 更改属主和属组 1 chown -R mysql:mysql /usr/local/mysql/ 更改权限 1 chmod -R 755 /usr/local/mysql/ 初始化mysql 进入mysql/bin目录 1 cd /usr/local/mysql/bin 初始化 1 ./mysqld --initialize --user=mysql --datadir=/usr/local/mysql/data --basedir=/usr/local/mysql 初始密码：qt\u0026amp;ASa4cif\u0026amp;o\n配置参数文件 编辑my.cnf文件 1 vim /etc/my.cnf my.cnf 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 [client] port = 3306 socket = /usr/local/mysql/data/mysql.sock default-character-set = utf8mb4 [mysql] default-character-set = utf8mb4 [mysqld] character-set-client-handshake = FALSE character-set-server = utf8mb4 collation-server = utf8mb4_general_ci init_connect = \u0026#39;SET NAMES utf8mb4\u0026#39; port = 3306 socket = /usr/local/mysql/data/mysql.sock skip-external-locking key_buffer_size = 16M max_allowed_packet = 1M table_open_cache = 64 sort_buffer_size = 512K net_buffer_length = 8K read_buffer_size = 256K read_rnd_buffer_size = 512K myisam_sort_buffer_size = 8M datadir = /usr/local/mysql/data [mysqldump] quick max_allowed_packet = 16M [mysql] no-auto-rehash [myisamchk] key_buffer_size = 20M sort_buffer_size = 20M read_buffer = 2M write_buffer = 2M [mysqlhotcopy] interactive-timeout 修改/etc/my.cnf权限为644 1 chmod 644 /etc/my.cnf 启动mysql 设置软连接 设置软链接 1 2 3 ln -s /usr/local/mysql/support-files/mysql.server /etc/init.d/mysql ln -s /usr/local/mysql/bin/mysql /usr/bin/mysql ln -s /usr/local/mysql/mysql.sock /var/mysql.sock 启动mysql 1 service mysql start 登录并更改密码 登录mysql 1 mysql -uroot -p 输入密码（密码不会显示） 两种改密方式二选一 第一种 1 alter user \u0026#39;root\u0026#39;@\u0026#39;localhost\u0026#39; identified by \u0026#39;123456\u0026#39;; 第二种 1 set password for root@localhost = \u0026#39;123456\u0026#39;; 问题：开放远程连接后如果想修改密码发生报错 1 2 3 ERROR 1396 (HY000): Operation ALTER USER failed for \u0026#39;root\u0026#39;@\u0026#39;localhost\u0026#39; ERROR 1133 (42000): Can\u0026#39;t find any matching row in the user table 检查user表中的用户和主机名 使用mysql库 1 use mysql; 查询用户和主机名 1 select user, host from user; 如果 root 用户的主机名不是 localhost，而是 %，则需要修改修改密码命令。 第一种 1 alter user \u0026#39;root\u0026#39;@\u0026#39;%\u0026#39; identified by \u0026#39;123456\u0026#39;; 第二种 1 set password for \u0026#39;root\u0026#39;@\u0026#39;%\u0026#39; = \u0026#39;123456\u0026#39;; 开放远程连接并测试登录 使用mysql数据库 1 use mysql; 更新权限 1 update user set user.Host=\u0026#39;%\u0026#39; where user.User=\u0026#39;root\u0026#39;; 刷新权限 1 flush privileges; 开放3306端口 查询所有开放端口 1 firewall-cmd --list-ports 开放3306端口 1 firewall-cmd --zone=public --add-port=3306/tcp --permanent 重启防火墙 1 firewall-cmd --reload 生词 flush : 刷新 privilege : 特权 ","date":"2025-10-17T10:12:01+08:00","permalink":"https://YLine-hub.github.io/p/centos7.6mysql8%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/","title":"[CentOS7.6]mysql8安装部署"},{"content":"[Windows]Mac和Win实现文件互传 Mac篇看:[Mac]mac和win实现文件互传 环境 mac笔记本\nwin电脑\n同一个wifi\nMac和Win实现文件互传 win设置共享文件夹 右键需要共享的文件夹，选择属性 点击共享-\u0026gt;高级共享 詳細（しょうさい）：详细；详尽\n共有（きょうゆう）：共享；共有\n勾选共享此文件复选框，在点击アクセス許可 許可（きょか）：批准；许可\n选择所有人，勾选フル　コントロール，再点击適用 コントロール： control 控制；管理；操纵；调节\n適用（てきよう）：应用\n点击ok以后，再点击共有 选择Everyone，再点击追加 追加（ついか）：添加\nアクセス許可のレベル选择読み取り/書き込み，再点击共有 レベル：level 水平；等级\n打开cmd，输入ipconfig查看本机ip 问题：ipconfig不是外部或内部命令 重新配置ipconfig环境变量 1 2 # 路径 C:\\Windows\\System32 再次查看 win连接win的共享文件夹 适用win+R，打开快速运行\n然后在框内输入\\\\ + ip，回车即可\n注意：我这前面两个￥￥其实是\\\\，因为我的电脑是用的是日语语言，\\\\这个被显示成了￥￥\n输入连接电脑的账号密码 ","date":"2025-10-16T21:37:53+08:00","permalink":"https://YLine-hub.github.io/p/windowsmac%E5%92%8Cwin%E5%AE%9E%E7%8E%B0%E6%96%87%E4%BB%B6%E4%BA%92%E4%BC%A0/","title":"[Windows]Mac和Win实现文件互传"},{"content":"部署环境 Node 21.6.2 : [CentOS7.6]node安装配置 MongoDB 7.0.25 : [CentOS7.6]MongoDB7安装配置 nginx 1.22.1 : [CentOS7.6]nginx安装配置 部署项目 下载项目 项目下载地址 1 https://github.com/didi/xiaoju-survey.git 创建code目录，并到code目录下 1 mkdir /opt/code \u0026amp;\u0026amp; cd /opt/code 下载源码 1 git clone https://github.com/didi/xiaoju-survey.git （如果没有git命令）安装git 1 yum install git -y 配置项目 下载的项目直接是一个文件夹\n创建目录/www/wwwroot\n1 mkdir -p /www/wwwroot 移动项目到/www/wwwroot下 1 mv xiaoju-survey/ /www/wwwroot/ 到项目目录下 1 cd /www/wwwroot/xiaoju-survet 配置数据库 到server目录下 1 cd /wwww/wwwroot/xiaoju-survet/serve 查看数据库配置 1 2 3 4 5 vim .env # 开发环境 vim .env.development # 生产环境 vim .env.production 可以按照他的来，也可以自己创建数据库使用\n创建数据库并创建账号 连接mongodb 1 mongosh -u admin -p a123456 创建数据库 1 use xiaojuSurvey; 创建用户（读写权限） 1 db.createUser({user:\u0026#34;xiaojuSurvey\u0026#34;,pwd:\u0026#34;x123456\u0026#34;,roles:[{role:\u0026#34;readWrite\u0026#34;,db:\u0026#34;xiaojuSurvey\u0026#34;}]}); 查看用户 1 show users; 配置数据库 编辑.env.production（生产环境） 1 vim .env.production 配置数据库 1 2 3 XIAOJU_SURVEY_MONGO_DB_NAME=xiaojuSurvey # mongodb://username:passwd@127.0.0.1:27017 XIAOJU_SURVEY_MONGO_URL=mongodb://xiaojuSurvey:x123456@127.0.0.1:27017 编译并启动项目 全局安装pm2 1 npm install pm2 -g 运行server 到server目录下 1 cd /www/wwwroot/xiaoju-survey/server 编译并运行 1 2 3 npm install npm run build pm2 -n xiaoju-survey start npm -- run start:prod 运行web 到/web目录下 1 cd /www/wwwroot/xiaoju-survey/web 编译并运行 1 2 npm install npm run serve 部署前端到nginx上 构建前端代码，产生dist文件 1 2 3 4 # 到xiaoju-survey/web目录下 # 编译项目 npm run build 编辑nginx 1 vim /usr/local/nginx/conf/nginx.conf nginx 配置 编辑xiaoju-survey下的配置文件 1 vim /www/wwwroot/xiaoju-survey/nginx/nginx.conf nginx.conf 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 # 启动的 worker 进程数量 worker_processes auto; # 错误日志路径和级别 error_log /var/log/nginx/error.log warn; # TODO: 配置错误日志地址 events { # 最大连接数 worker_connections 1024; } http { # include /etc/nginx/mime.types; # https://github.com/nginx/nginx/blob/master/conf/mime.types types { text/html html htm shtml; text/css css; text/javascript js; image/jpeg jpeg jpg; image/png png; } default_type application/octet-stream; log_format main \u0026#39;$remote_addr - $remote_user [$time_local] \u0026#34;$request\u0026#34; \u0026#39; \u0026#39;$status $body_bytes_sent \u0026#34;$http_referer\u0026#34; \u0026#39; \u0026#39;\u0026#34;$http_user_agent\u0026#34; \u0026#34;$http_x_forwarded_for\u0026#34;\u0026#39;; access_log /var/log/nginx/access.log main; # TODO: 配置日志地址 sendfile on; keepalive_timeout 65; server { listen 8080; # IPv6端口 listen [::]:8080; server_name localhost; # 为不同的域名或子域名指定不同的配置 # gzip config gzip on; gzip_min_length 1k; gzip_comp_level 9; gzip_types text/plain text/css text/javascript application/json application/javascript application/x-javascript application/xml; gzip_vary on; gzip_disable \u0026#34;MSIE [1-6]\\.\u0026#34;; root /www/wwwroot/siaoju-survey/web/dist; # TODO: 前端打包出来的资源地址 location / { try_files $uri $uri /management.html; # 处理本地静态文件，适用于直接返回页面或在文件不存在时提供备选页面（如 404 页面、静态资源） } # B端页面 location /management/ { try_files $uri $uri/ /management.html; } # B端预览页 location /management/preview/ { try_files $uri $uri/ /render.html; } # C端页面 location /render/ { try_files $uri $uri/ /render.html; } # server接口 location /api { proxy_pass http://127.0.0.1:3000; } # server下载模块的文件存储地址 location /exportfile { proxy_pass http://127.0.0.1:3000; } # server上传模块的文件存储地址 # 文件夹的配置在 server/src/modules/file/config/index.ts SERVER_LOCAL_CONFIG.FILE_KEY_PREFIX location /userUpload { proxy_pass http://127.0.0.1:3000; } error_page 500 502 503 504 /500.html; client_max_body_size 20M; } } 创建nginx错误日志目录 1 mkdir -p /var/log/nginx/ 创建nginx错误日志 1 touch /var/log/nginx/error.log 备份nginx内的nginx.conf 1 mv /usr/local/nginx/conf/nginx.conf /usr/local/nginx/conf/nginx.conf.back 将xiaoju-survey内的nginx.conf移到nginx/confmuluxia 1 mv /www/wwwroot/xiaoju-survey/nginx/nginx.conf /usr/local/nginx/conf 启动或重启nginx 1 systemctl start nginx 开放8080端口 1 2 firewall-cmd --zone=public --add-port=8080/tcp --permanent firewall-cmd --reload 问题一：Error: spawn xdg-open ENOENT 解决方法 1 sudo yum install xdg-utils ","date":"2025-10-16T13:35:40+08:00","permalink":"https://YLine-hub.github.io/p/linux%E9%83%A8%E7%BD%B2%E5%BC%80%E6%BA%90xiaojusurvey%E9%97%AE%E5%8D%B7%E7%B3%BB%E7%BB%9F/","title":"[Linux]部署开源XIAOJUSURVEY问卷系统"},{"content":"安装前置 nvm安装包 nvm历史版本:nvm-download 我这里选择的是最新版本的tar.gz包，复制其下载地址\n1 https://github.com/nvm-sh/nvm/archive/refs/tags/v0.40.3.tar.gz 安装nvm 下载nvm安装包 进入/opt目录 1 cd /opt 下载nvm安装包 1 wget https://github.com/nvm-sh/nvm/archive/refs/tags/v0.40.3.tar.gz 问题：显示拒绝连接 打开ipaddress.com网址，搜索github.com网址的ip 编辑/etc/hosts文件 1 vim /etc/hosts 将以下内容复制到文件底部并保存 1 140.82.112.4 github.com 重新下载测试 下载成功\n解压压缩包，并将文件放在/usr/local目录下 解压压缩包(解压后的名字叫nvm-0.40.3) 1 tar -zxvf v0.40.3.tar.gz 将文件移动到/usr/local目录下并命名为nvm 1 mv nvm-0.40.3/ /usr/local/nvm 配置环境变量 编辑配置文件 1 vim /etc/profile 在文件底部写入配置，并保存文件 1 2 3 export NVM_DIR=\u0026#34;/usr/local/nvm\u0026#34; [ -s \u0026#34;$NVM_DIR/nvm.sh\u0026#34; ] \u0026amp;\u0026amp; \\. \u0026#34;$NVM_DIR/nvm.sh\u0026#34; # This loads nvm [ -s \u0026#34;$NVM_DIR/bash_completion\u0026#34; ] \u0026amp;\u0026amp; \\. \u0026#34;$NVM_DIR/bash_completion\u0026#34; # This loads nvm bash_completion 重新加载配置文件 1 source /etc/profile 验证是否配置成功 1 nvm -v 安装node 查看可用node版本 1 nvm ls-remote 下载最新node版本 1 nvm install node (或者)下载指定版本的node 1 nvm install 22.20.0 查看已安装node版本 1 nvm ls 使用指定版本的node 1 nvm use 22.20.0 设定特定的版本为默认版本 1 nvm alias default 22.20.0 验证是否安装node 1 2 node -v npm -v 问题一：GLIBC版本过低 原因: node18 开始，都需要 2.27以上的版本支持，但是 centos7.6 老系统默认没有那么高的版本，因此接下来我们去安装 glibc_2.28 安装glibc_2.28 glibc下载地址：glibc-download\n找到我们所需的版本，并复制其地址\n1 http://ftp.gnu.org/gnu/glibc/glibc-2.28.tar.gz 进入/opt目录 1 cd /opt 下载安装包 1 wget http://ftp.gnu.org/gnu/glibc/glibc-2.28.tar.gz 问题二：下载速度过慢 使用阿里云镜像站下载 1 wget https://mirrors.aliyun.com/gnu/glibc/glibc-2.28.tar.gz 解压安装包 1 tar -zxvf glibc-2.28.tar.gz 移动文件到/usr/local目录下 1 mv glibc-2.28 /usr/local 进入glibc目录下下 1 cd /usr/local/glibc-2.28 创建build文件夹并进入 1 mkdir build \u0026amp;\u0026amp; cd build 执行./configure配置 1 ../configure --prefix=/usr --disable-profile --enable-add-ons --with-headers=/usr/include --with-binutils=/usr/bin 问题三：gcc编译器版本过低 解决方法：安装gcc-8的依赖环境\n安装gcc8 安装所需工具 1 2 3 yum groupinstall -y \u0026#39;Development Tools\u0026#39; yum install -y texinfo bison flex gcc-gnat glibc-devel.i686 libgcc.i686 下载gcc-8 1 2 cd /opt wget http://ftp.tsukuba.wide.ad.jp/software/gcc/releases/gcc-8.2.0/gcc-8.2.0.tar.gz 解压gcc包 1 tar -zxvf gcc-8.2.0.tar.gz 将gcc移动到/usr/local目录下 1 mv gcc-8.2.0 /usr/local/ 进入gcc目录 1 cd /usr/local/gcc-8.2.0 下载GCC所需的依赖：gmp、mpfr、mpc、isl 1 ./contrib/download_prerequisites ./contrib/download_prerequisites太慢 1 2 3 vim contrib/download_prerequisites # ftp://gcc.gnu.org/pub/gcc/infrastructure/ #修改为 http://www.mirrorservice.org/sites/sourceware.org/pub/gcc/infrastructure/ 修改为\n下载依赖时报错 移除mpfr-3.1.4.tar.bz2 1 rm -rf mpfr-3.1.4.tar.bz2 修改回原路径重新下载 1 ./contrib/download_prerequisites 下载完成\n执行 configure 生成Makefile 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 mkdir build \u0026amp;\u0026amp; cd build ../configure --prefix=/storage/app/gnu/gcc-8.2.0 \\ --enable-bootstrap \\ --enable-shared \\ --enable-threads=posix \\ --enable-checking=release \\ --with-system-zlib \\ --enable-__cxa_atexit \\ --disable-libunwind-exceptions \\ --enable-gnu-unique-object \\ --enable-linker-build-id \\ --with-linker-hash-style=gnu \\ --enable-languages=c,c++,objc,obj-c++,fortran,ada,go,lto \\ --enable-plugin \\ --enable-initfini-array \\ --disable-libgcj \\ --enable-gnu-indirect-function \\ --with-tune=generic \\ --with-arch_32=x86-64 \\ --build=x86_64-redhat-linux 执行编译 -j 参数根据CPU核数设置。 编译时间根据机器配置决定，GCC编译过程一般都需要很长时间，慢慢等待。 1 make -j48 问题：编译出现报错 往上翻看到\n安装zlib 1 yum install zlib-devel.x86_64 再次编译 1 make -j48 安装 1 make install 配置环境变量 编辑~/.bashrc文件 1 vim ~/.bashrc 文件内部输入以下配置 1 2 3 4 5 6 7 8 9 ### gnu gcc export GCC_HOME=/storage/app/gnu/gcc-8.2.0 export PATH=$GCC_HOME/bin:$PATH export MANPATH=$GCC_HOME/share/man export CPATH=$GCC_HOME/include export LD_LIBRARY_PATH=$GCC_HOME/lib:$GCC_HOME/lib64 export LIBRARY_PATH=$GCC_HOME/lib:$GCC_HOME/lib64 再次开始安装glic-2.28 安装 1 make \u0026amp;\u0026amp; make install 查看系统中可用的glibc版本 1 strings /lib64/libc.so.6 |grep GLIBC_ ","date":"2025-10-15T23:34:40+08:00","permalink":"https://YLine-hub.github.io/p/centos7.6nvm%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/","title":"[CentOS7.6]nvm安装配置"},{"content":"环境准备 操作系统：CentOS7.6 MongoDB安装包：MongoDB-Download 1 https://fastdl.mongodb.org/linux/mongodb-linux-x86_64-rhel70-7.0.25.tgz mongodb shell: MongoDB-Shell 1 https://downloads.mongodb.com/compass/mongosh-2.5.8-linux-x64.tgz 软件安装和启动 下载解压安装包 进入/opt目录下 1 cd /opt 下载安装包 1 wget https://fastdl.mongodb.org/linux/mongodb-linux-x86_64-rhel70-7.0.25.tgz 解压安装包 1 tar -zxvf mongodb-linux-x86_64-rhel70-7.0.25.tgz 将文件夹移动到/usr/local下，并改名为mongodb 1 mv mongodb-linux-x86_64-rhel70-7.0.25 /usr/local/mongodb 配置mongodb 创建mongodb的配置、数据和日志目录 1 mkdir /usr/local/mongodb/{etc,data,logs} 在mongodb/etc目录下新建配置文件mongodb.conf(可选，但建议配置) 1 vim /usr/local/mongodb/etc/mongod.conf mongodb.conf 1 2 3 4 5 6 7 8 9 10 11 12 systemLog: destination: file path: \u0026#34;/usr/local/mongodb/logs/mongod.log\u0026#34; logAppend: true storage: dbPath: \u0026#34;/usr/local/mongodb/data\u0026#34; processManagement: fork: true pidFilePath: \u0026#34;/usr/local/mongodb/mongod.pid\u0026#34; net: bindIp: 0.0.0.0 port: 27017 配置环境变量 编辑/etc/profile文件 1 vim /etc/profile 在文件底部添加配置信息 1 2 export MONGODB_HOME=/usr/local/mongodb export PATH=$PATH:$MONGODB_HOME/bin 重新加载配置文件 1 source /etc/profile 创建服务启动文件，并启动服务 创建mongodb.service文件 1 vim /etc/systemd/system/mongodb.service mongodb.service 1 2 3 4 5 6 7 8 9 10 11 12 [Unit] Description=MongoDB Server After=network.target [Service] Type=forking ExecStart=/usr/local/mongodb/bin/mongod -f /usr/local/mongodb/etc/mongod.conf ExecStop=/usr/local/mongodb/bin/mongod --shutdown -f /usr/local/mongodb/etc/mongod.conf ExecReload=/bin/kill -s HUP $MAINPID [Install] WantedBy=multi-user.target 启动服务 1 2 systemctl daemon-reload systemctl start mongodb 设置开机自启动 1 systemctl enable mongodb 安装MongDB Shell客户端 到/opt目录下 1 cd /opt 下载安装包 1 wget https://downloads.mongodb.com/compass/mongosh-2.4.2-linux-x64.tgz 解压安装包 1 tar -zxvf mongosh-2.4.2-linux-x64.tgz 移动安装包到mongodb目录下 1 mv mongosh-2.4.2-linux-x64 /usr/local/mongodb/mongosh 配置环境变量 编辑/etc/profile文件 1 vim /etc/profile 将以下内容加入到文件底部 1 2 export MONGOSH_HOME=/usr/local/mongodb/mongosh export PATH=$PATH:$MONGOSH_HOME/bin 重新加载配置文件 1 source /etc/profile 连接测试 1 mongosh 创建管理员用户 连接mongodb 1 mongosh 查看数据库 1 show dbs; 切换到 admin 数据库 1 use admin; 查看用户 1 show users; 创建一个管理员用户(密码为123456) 1 db.createUser({user: \u0026#34;admin\u0026#34;, pwd: \u0026#34;123456\u0026#34;, roles: [{ role: \u0026#34;userAdminAnyDatabase\u0026#34;, db: \u0026#34;admin\u0026#34;}]}); 再次查看用户 1 show users; 修改密码 注意先切换到相应的库 1 use admin; 修改密码 1 db.changeUserPassword(\u0026#34;admin\u0026#34;, \u0026#34;a123456\u0026#34;); 开启MongoDB Server登录认证 修改 mongod.conf 文件 1 vim /usr/local/mongodb/etc/mongod.conf 添加登录认证 1 2 3 #在最后面添加以下内容： security: authorization: enabled 重启mongodb服务 1 systemctl restart mongodb 连接测试 1 mongosh -u admin -p a123456 创建库与用户 使用管理员登录数据库 1 mongosh -u root -p a123456 创建库与用户 创建一个数据库mydb 1 use mydb; 创建mydb数据库的用户（读写权限） 1 db.createUser({ user: \u0026#34;myuser\u0026#34;, pwd: \u0026#34;m123456\u0026#34;, roles: [{ role: \u0026#34;readWrite\u0026#34;, db: \u0026#34;mydb\u0026#34;}]}); 查看用户 1 show users; 校验用户及密码 1 db.auth(\u0026#34;myuser\u0026#34;,\u0026#34;m123456\u0026#34;) 获取当前连接用户 1 db.runCommand({connectionStatus: 1}) 创建一个表并插入一条数据 创建表并插入测试数据，不然连接后使用show dbs不显示库名 1 db.test_collection.insertOne({name:\u0026#34;init\u0026#34;}); 查看表 1 show tables; 查看库 1 show dbs ","date":"2025-10-15T22:52:27+08:00","permalink":"https://YLine-hub.github.io/p/centos7.6mongodb7%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/","title":"[CentOS7.6]MongoDB7安装配置"},{"content":"安装前置 找到所需安装包 nodejs-download 选择指定的版本 选择有glibc的版本，因为centos7的glibc版本低 复制链接 1 https://unofficial-builds.nodejs.org/download/release/v21.6.2/node-v21.6.2-linux-x64-glibc-217.tar.gz 安装node 进入/opt目录下 1 cd /opt 下载安装包 1 wget https://unofficial-builds.nodejs.org/download/release/v21.6.2/node-v21.6.2-linux-x64-glibc-217.tar.gz 等待下载 解压安装包并移动到/usr/local目录下 解压安装包 1 tar -zxvf node-v21.6.2-linux-x64-glibc-217.tar.gz 移动安装包到/usr/local目录下，并改名为node 1 mv node-v21.6.2-linux-x64-glibc-217 /usr/local/node 配置环境变量 编辑/etc/profile 1 vim /etc/profile 添加以下内容到文件末尾 1 2 export NODE_HOME=/usr/local/node export PATH=$NODE_HOME/bin:$PATH 退出并保存文件\n重新加载配置文件\n1 source /etc/profile 查看安装 1 node -v ","date":"2025-10-15T22:50:18+08:00","permalink":"https://YLine-hub.github.io/p/centos7.6node%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/","title":"[CentOS7.6]node安装配置"},{"content":"搭建nginx 根据这个教程进行搭建: [CentOS7.6]nginx安装配置 搭建项目 上传文档到服务器 /tmp 目录权限是777，可以直接上传到文件夹 将文件移动到nginx/html目录下并解压 分别移动文件到html目录下 1 2 mv public.rar /usr/local/nginx/html mv war.rar /usr/local/nginx/html 移动到html目录下 1 cd /usr/local/nginx/html 解压文件 1 2 unar public.rar unar war.rar 配置nginx.conf 编辑nginx文件 1 vim /usr/local/nginx/conf/nginx.conf 配置nginx：不同端口 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 server { listen 80; server_name localhost; location / { root html/war; index circuitjs.html; } } server { listen 8080; server localhost; location / { root html/public; index index.html; } } 配置nginx：不同域名 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 server { listen 80; server_name a.server.com; location / { root html/war; index circuitjs.html; } } server { listen 80; server b.server.com; location / { root html/public; index index.html; } } ","date":"2025-10-15T22:48:08+08:00","permalink":"https://YLine-hub.github.io/p/linux%E6%90%AD%E5%BB%BAnginx%E5%B9%B6%E9%83%A8%E7%BD%B2%E4%B8%A4%E4%B8%AA%E9%A1%B9%E7%9B%AE/","title":"[Linux]搭建nginx，并部署两个项目"},{"content":"创建ssh用户，并用ssh用户登录 创建ssh组 新建ssh组 1 groupadd ssh_user 创建ssh用户 1 useradd -m -d /home/username -g ssh_user -s /bin/bash username 创建ssh用户用户名为lin 1 useradd -m -d /home/lin -g ssh_user -s /bin/bash lin 添加sudo权限 编辑/etc/sudoers文件 1 vim /etc/sudoers 找到root ALL=(ALL) ALL这行 添加以下四行其中一个 第一行:允许用户youuser执行sudo命令(需要输入密码). 第二行:允许用户组youuser里面的用户执行sudo命令(需要输入密码). 第三行:允许用户youuser执行sudo命令,并且在执行的时候不输入密码. 第四行:允许用户组youuser里面的用户执行sudo命令,并且在执行的时候不输入密码. 1 2 3 4 youuser ALL=(ALL) ALL %youuser ALL=(ALL) ALL youuser ALL=(ALL) NOPASSWD: ALL %youuser ALL=(ALL) NOPASSWD: ALL 允许ssh_user用户组执行sudo命令（需要输入密码） 1 %ssh_user ALL=(ALL) ALL 设置密码 1 passwd lin 使用:wq!强制保存 切换用户重新登录，并测试sudo权限 修改成lin用户 登录 测试sudo权限 1 ls /root 使用sudo再次访问 1 sudo ls /root 上传文件 上传文件到/opt时显示没有权限\n设置文件夹权限\n1 sudo chmod 777 /opt 没有source命令 问题是source是一个bash build-in命令(不是程序 – 如ls或grep)。 切换root账号使用 切换root用户 1 sudo -s 更新配置 1 source /etc/profile 退出root账号 1 exit ","date":"2025-10-15T22:45:27+08:00","permalink":"https://YLine-hub.github.io/p/centos7.6%E5%88%9B%E5%BB%BAssh%E7%94%A8%E6%88%B7%E5%B9%B6%E7%94%A8ssh%E7%94%A8%E6%88%B7%E7%99%BB%E9%99%86/","title":"[CentOS7.6]创建SSH用户，并用SSH用户登陆"},{"content":"打开文件夹 点击File-\u0026gt;Open folder 选择一个文件夹并打开 添加另一个文件夹 这时候用File-\u0026gt;Add Folder to Workspace... 选择其他项目 弹出是否信任该文件夹时点击信任即可\n这时候，就会自动生成工作区，然后所有项目都在工作区内\n","date":"2025-10-15T22:38:32+08:00","permalink":"https://YLine-hub.github.io/p/vscode%E4%BD%BF%E7%94%A8%E5%B7%A5%E4%BD%9C%E5%8C%BA%E5%90%8C%E6%97%B6%E6%89%93%E5%BC%80%E5%A4%9A%E4%B8%AA%E9%A1%B9%E7%9B%AE/","title":"VSCode使用工作区同时打开多个项目"},{"content":"前置环境 nodejs:nodejs-download nativefier插件\n网站链接\n打包过程 安装nodejs 运行安装程序 一直点击next，可以改一下安装路径，其他不用修改\n测试是否安装\n打开cmd，输入命令查看版本\n1 npm -v 安装插件 用npm安装插件 1 npm install nativefier -g 等待安装完成 打包 1 nativefier --name \u0026#34;ciruitjs1\u0026#34; \u0026#34;http://www.haoji.cc/\u0026#34; 报错一：connect ECONNREFUSED 127.0.0.1:443 1 2 3 4 5 6 Error during build. Run with --verbose for details. RequestError: connect ECONNREFUSED 127.0.0.1:443 at ClientRequest.\u0026lt;anonymous\u0026gt; (C:\\Users\\yline\\AppData\\Roaming\\npm\\node_modules\\nativefier\\node_modules\\got\\dist\\source\\core\\index.js:970:111) at Object.onceWrapper (node:events:634:26) at ClientRequest.emit (node:events:531:35) at ClientRequest.emit (node:domain:489:12) ... 在ipaddress.com网站中，分别查询github.com和fastly.net的ip地址 我查询到的github.com ip为140.82.112.4，fastly.net为151.101.1.6\n如下面，将这几行加入到C:\\Windows\\System32\\drivers\\etc目录下hosts文件夹中最后面\n1 2 3 140.82.112.4 github.com 151.101.1.6 github.global.ssl.fastly.net 151.101.65.6 github.global.ssl.fastly.net 问题二：修改hosts文件没有权限 给hosts文件添加写入权限\n右键hosts文件，选择属性\n点击安全 点击编辑 选择Users，点击最上面的选项给予全部权限，再点击应用 修改完权限以后，修改hosts文件 重新打包 再次执行打包命令 1 nativefier --name \u0026#34;ciruitjs1\u0026#34; \u0026#34;http://www.haoji.cc/\u0026#34; 等待打包完成 打包完成，位置在打包的目录下 进入目录后，可以看到打包后的程序 双击运行 带图片打包 要求：图片格式必须为.ico，图片在运行命令的文件夹下\n打包命令\n1 nativefier --name \u0026#34;ciruitjs1\u0026#34; --icon \u0026#34;xxxx.ico\u0026#34; \u0026#34;http://xxxxxxx\u0026#34; ","date":"2025-10-14T20:15:28+08:00","permalink":"https://YLine-hub.github.io/p/%E7%AE%80%E5%8D%95%E7%9A%84web%E7%BD%91%E7%AB%99%E6%89%93%E5%8C%85%E6%88%90exe/","title":"简单的web网站打包成exe"},{"content":"安装前置 【注】：必须已经有Java环境才能正常运行\n安装jdk，安装详情可以查看【CentOS7.6】jdk8安装配置\n官网下载tomcat：Tomcat9-Download\n安装Tomcat9 运行tomcat 上传tomcat压缩包到/opt目录下 解压文件 1 tar -zxvf apache-tomcat-9.0.110.tar.gz 将文件夹移动到/usr/local目录下并重命名为tomcat（确保/usr/local下没有tomcat文件，如果有的话要先删除） 1 mv apache-tomcat-9.0.110 /usr/local/tomcat 进入tomcat/bin目录下 1 cd /usr/local/tomcat/bin 运行tomcat 1 2 3 4 5 # 启动tomcat ./startup.sh # 关闭tomcat ./shutdown.sh 浏览器查看：http://192.168.172.100:8080 开启8080端口 查看系统中的所有开放的端口 1 firewall-cmd --list-ports\t或者\n查看8080端口是否开启 1 firewall-cmd --query-port=8080/tcp 开启8080端口 1 firewall-cmd --zone=public --add-port=8080/tcp --permanent 重启防火墙 1 firewall-cmd --reload 浏览器查看：http://192.168.172.100:8080 开启自动解压/webapps目录下的war文件 进入tomcat/conf 1 cd /usr/local/tomcat/conf 编辑server.xml文件 1 vim server.xml 搜索关键词unpackWARs ","date":"2025-10-13T22:52:40+08:00","permalink":"https://YLine-hub.github.io/p/centos7.6tomcat9%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/","title":"[CentOS7.6]Tomcat9安装配置"},{"content":"下载tomcat9解压包 配置jdk1.8环境 方案三 双击startup.bat启动 闪退原因：jdk环境不适用或者没有安装jdk 双击shutdown.bat停止 乱码解决 双击startup.bat后弹出的命令行窗口显示乱码 进入...\\apache-tomcat-9.0.110\\conf目录下\n用记事本打开logging.properties\n1 2 3 # java.util.logging.ConsoleHandler.encoding = utf-8 # 更改为 java.util.logging.ConsoleHandler.encoding = GBK ","date":"2025-10-13T20:34:00+08:00","permalink":"https://YLine-hub.github.io/p/win11tomcat9%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/","title":"[Win11]tomcat9安装配置"},{"content":"环境准备 git：git-download elcipse：eclipse IDE-download GWT plugin：GWT plugin for Eclipse Tomcat9-download\nTomcat 9：Tomcat9-download circuitjs1的git链接：https://github.com/pfalstad/circuitjs1.git 本地部署 将circuitjs1克隆到本地 创建文件夹circuitjs\n进入文件夹\n在文件夹上面的路径栏中输入cmd并回车\n就会自动打开当前目录下的cmd命令行 在命令行中输入以下命令 1 git clone https://github.com/pfalstad/circuitjs1.git 引入gwt插件到eclipse 方法一： 使用按钮安装gwt到eclipse 将gwt页面的install拖到eclipse里面 弹出当前页面后，选择上面两个，然后点击confirm 下载完成后点击接受-\u0026gt;Finish\n等待软件安装\n弹出该窗口后选择上面的site然后点击下面的信任 又有窗口弹出，继续全选后点击信任 安装完成后点击重启 方法二：从Eclipse Marketplace安装插件 点击 Help -\u0026gt; Eclipse Marketplace 搜索gwt并安装 使用eclipse打开circuitjs1 点击导入项目 选择下载的文件的根目录 打开build.gradle可以看到java的版本是1.8 然后报错显示的是没有发现java 1.8.301的路径 下载jdk 1.8.0_301 下载jdk 1.8.0_301：java-download 注意：Oracle需要登陆才能下载\n选择Java SE 8 (8u211 and later) 找到jdk-8u301的安装包，点击下载 配置 jdk 1.8.301 安装jdk后记下jdk的安装路径 1 C:\\Program Files\\Java\\jdk1.8.0_301 添加本地jdk1.8 点击Window-\u0026gt;Perferences... 选择Java-\u0026gt;Installed JREs，点击add 选择Standard VM，点击Next 选择jdk1.8的路径，点击完成 勾选jdk1.8.0_301然后点击Apply and Close 设置项目环境 右击项目根目录，点击Properties 其中有两个未绑定的内容分别是JRE System Library和GWT SDK unbound： 未绑定\n移除未绑定的内容 添加jre到项目环境 选择Workspace default JRE，然后点击Finish workspace default jre后面写了jdk1.8.0_301这个正是我们刚刚配置的jdk\n添加gwt到项目环境 选择默认的即可 都添加以后点击Order and Export中，把jre和gwt都勾选起来，再点击Apply and Close 然后项目的报错都没了 设置Tomcat（不需要，GWT项目不需要Tomcat运行） 确保tomcat服务器处于关闭状态\n点击Windows-\u0026gt;Perferences...\n点击server中的Runtime Environments，然后点击add 发现 Eclipse 没有 Apache 的选项 完成下面的操作后再次进入，发现已经有Tomcat了 根据自己的情况选择Tomcat版本，我这里选择的是Tomcat9 选择自己Tomcat的安装路径，然后点击Finish 点击Apply and Close 解决Eclipse没有Apache的选项 点击Help-\u0026gt;Install New Software 在Work with中输入 http://download.eclipse.org/releases/版本号，然后回车 版本号查询，点击Help-\u0026gt;About Eclipse IDE，我的版本号为 2025-09\n然后勾选Web,XML,Java EE and ODG Enterprise Development 或者 JST Server Adapters Extension或者JST Server Adapters，这两个都可以。 JST Server Adapters Extension 和 JST Server Adapters 在 Web,XML,Java EE and ODG Enterprise Development 里面 然后点击Next等待安装 配置过程会有弹窗弹出，一直点next即可 还会有要求信任的Authority，全部勾选以后点击信任即可 设置Servers（同样不需要，使用Tomcat的项目需要） 红框内如果没有Servers窗口则需要自己添加 点击Window-\u0026gt;Show View-\u0026gt;Other 选择Server下的Servers 然后下方框内出现了Servers窗口 点击No servers are available. Click this link to create a new server… 找到自己Tomcat的版本，然后点击Finish 然后Servers栏会出现如下图内容 在Server Locations处选中Use Tomcat installation…\u0026mdash;-\u0026gt;将wtpwebapps改为webapps\u0026mdash;-\u0026gt;保存此设置（叉掉后点击Save） 右键点击start 浏览器输入： http://localhost:8080 出现该页面就表示配置tomcat成功\n运行项目 右键项目run as-\u0026gt;GWT Development Mode 控制台发生报错 1 java.lang.UnsupportedClassVersionError: org/eclipse/jdt/internal/compiler/classfmt/ClassFormatException has been compiled by a more recent version of the Java Runtime (class file version 55.0), this version of the Java Runtime only recognizes class file versions up to 52.0 报错信息显示：当前项目已经被55.0版本(jdk 11)的Java Runtime编译，当前Java Runtime 的版本是52.0版本(jdk 8)\n解决方案：切换jdk11\n切换jdk 11 后重新运行\n打开浏览器：http://127.0.0.1:9876 但是我们需要启动的主程序不是这个页面 启动主程序 右键项目run as-\u0026gt;GWT Development Mode with jetty 在弹窗中选择circuitjs.html然后点击ok 成功运行，然后双击开发模式窗口中的链接 打开程序 部署到Linux服务器 环境要求 centos7.6 tomcat9 ，安装tomcat可以参考：[CentOS7.6]Tomcat9安装配置 部署流程 编译circuitjs1项目 右键circuitjs1根目录，选择Run as-\u0026gt;GWT Compiler 等待编译完成 上传war目录 打包war目录，右键war文件夹并将其打包 使用mobaxterm上传到/usr/local/tomcat/webapps目录下 使用 unar 解压war.rar（如果没有就用yum安装） 1 unar war.rar 赋予war目录权限 1 chmod -R 775 war 浏览器输入：http://192.168.172.100:8080/war/circuitjs.html ","date":"2025-10-13T16:19:04+08:00","permalink":"https://YLine-hub.github.io/p/%E6%9C%AC%E5%9C%B0%E7%BC%96%E8%AF%91%E8%BF%90%E8%A1%8Cciruitjs1%E5%B9%B6%E9%83%A8%E7%BD%B2%E5%88%B0linux%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%B8%8A/","title":"本地编译运行ciruitjs1，并部署到Linux服务器上"},{"content":"MySQL基础-SQL SQL通用语法 SQL语句可以单行或多行书写，以分号结尾。 SQL语句可以使用空格/缩进来增强语句的可读性。 MySQL数据库的SQL语句不区分大小写，关键词建议使用大写。 注释： 单行注释： \u0026ndash; 注释内容 或 # 注释内容 （MySQL特有） 多行注释：/* 注释内容 */ SQL分类 分类 全称 说明 DDL Data Definition Language 数据定义语言，用来定义数据库对象（数据库，表，字段） DML Data Manipulation Language 数据操作语言，用来对数据库表中的数据进行增删该 DQL Data Query Language 数据查询语言，用来查询数据库中表的记录 DCL Data Control Language 数据控制语言，用来创建数据库用户、控制数据库的访问权限 DDL-数据库操作 查询 1 2 3 4 # 查询所有数据库 SHOW DATABASES; # 查询当前数据库 SELECT DATABASE(); 查询所有数据库 查询当前的数据库 创建 1 2 # [如果不存在则]创建数据库 CREATE DATABASE [IF NOT EXISTS] 数据库名 [DEFAULT CHARSET 字符集] [COLLATE 排序规则]; 创建数据库itcast： 1 create database itcast; 再次创建数据库itcast： 报错：ERROR 1007 (HY000): Can\u0026rsquo;t create database \u0026lsquo;itcast\u0026rsquo;; database exists\n表示：数据库已经存在，无法再创建\n使用if not exists再次创建itcast: 1 create database if not exists itcast; 语句执行成功，但是没有新增数据库\n创建数据库itfost并设置字符集utf8mb4 不推荐使用utf8，因为utf8存储的长度为3个字节；推荐使用utf8mb4，它支持4个字节。\n1 create database itfox default charset utf8mb4; 删除 1 2 # [如果存在则]删除数据库 DROP DATABASE [IF EXISTS] 数据库名； 删除数据库itfox 1 drop database itfox; 再次删除数据库itfox 报错：数据库不存在\n如果不想报错，可以在数据库前加上if exists 1 drop database if exists itfox; 使用 1 USE 数据库名; 使用itcast数据库 1 use itcast; DDL-表操作 查询 查询当前数据库所有表 1 SHOW TABLES; 查询itcast数据库所有表 切换成sys数据库 1 use sys; 查询sys数据库的所有表 查询表结构 1 DESC 表名; 查询itcast中tb_user表结构 1 desc tb_user; 查询指定表的建表语句 1 SHOW CREATE TABLE 表名; 查询itcast数据库中tb_user的建表语句 1 show create table tb_user; 创建 创建表 1 2 3 4 5 6 7 CREATE TABLE 表名( 字段1 字段1类型[COMMENT 字段1注释], 字段2 字段2类型[COMMENT 字段2注释], 字段3 字段3类型[COMMENT 字段3注释], ... 字段n 字段n类型[COMMENT 字段n注释] )[COMMENT 表注释] 注意：[\u0026hellip;]为可选参数，最后一个字段后面没有逗号\n根据该表格在itcast数据库中相应表 id name age gender 1 令狐冲 28 男 2 风清扬 68 男 3 东方不败 32 男 1 2 3 4 5 6 create table tb_user( id int comment \u0026#39;编号\u0026#39;, name varchar(50) comment \u0026#39;姓名\u0026#39;, age int comment \u0026#39;年龄\u0026#39;, gender varchar(1) comment \u0026#39;性别\u0026#39; )comment \u0026#39;用户表\u0026#39;; 验证表是否被创建 1 show tables; DDL-表操作 数据类型 分类 类型 大小 有符号(SIGNED)范围 无符号(UNSIGNED)范围 描述 数值类型 TINYINT 1 bytes (-128,127) (0,255) 小整数值 SMALLINT 2 bytes (-32768,32767) (0,65535) 大整数值 MEDIUMINT 3 bytes (-8388608,8388607) (0,16777215) 大整数值 INT或INTEGER 4 bytes (-2147483648,2147483647) (0,4294967295) 大整数值 BIGINT 8 bytes (-^63,2^63-1) (0,2^64-1) 极大整数值 FLOAT 4 bytes (-3.402823466 E+38,3c402823466351 E+38) 0和(1.175494351E-38,3.402823466 E+38) 单精度浮点数值 DOUBLE 8bytes (-1.7976931348623157 E+308,1.7976931348623157 E+308) 0和(2.2250738585072014 E-308,1.7976931348623157 E+308) 双精度浮点数值 DECIMAL 依赖与M(精度)和D(标度)的值 依赖于M(精度)和D(标度)的值 小数值(精确定点数) 字符串类型 CHAR 0-255 bytes 定长字符串 VARCHAR 0-65535 bytes 变长字符串 TINYBLOB 0-255 bytes 不超过255个字符的二进制数据 TINYEXT 0-255 bytes 短文本字符串 BLOB 0-65535 bytes 二进制形式的长文本数据 TEXT 0-65535 bytes 长文本数据 MEDIUMBLOB 0-1677215 bytes 二进制形式的中等长文本数据 MEDIUMTEXT 0-16777215 bytes 中等长度文本数据 LONGBLOB 0-4294967295 bytes 二进制形式的极大文本数据 LONGTEXT 0-4294967295 bytes 极大文本数据 分类 类型 大小 范围 格式 描述 日期类型 DATE 3 1000-01-01 至 9999-12-31 YYYY-MM-DD 日期值 TIME 3 -838:59:59 至 838:59:59 HH:MM:SS 时间值或持续值 YEAR 1 1901 至 2155 YYYY 年份值 DATETIME 8 1000-01-01 00:00:00 至 9999-12-31 23:59:59 YYYY-MM-DD HH:MM:SS 混合日期和时间值 TIMESTAMP 4 1970-01-01 00:00:01 至 2038-01-19 03:14:07 YYYY-MM-DD HH:MM:SS 混合日期和时间值，时间戳 数值类型\n（1）M（精度）和D（标度）说明\n比如123.45，其精度为5，也就是所有数个数。标度为2，即小数点后面数的个数。\n（2）判断数据的类型。\n年龄：age 年龄不会出现负数。所以选择无符号范围UNSIGNED。 年龄最大值为100岁左右，基本不会超过200岁。可以选择无符号中的0-255。也就是tinyint。 age tinyint unsigned\n分数：score 分数不会出现负数。 分数一般介于0-100之间，目前还有成绩在0-160之间。 分数允许出现小数。 比如：87.5，100.0，121.5\nscore double(4,1) unsigned\n4表示整体长度（包含1个小数），1表示小数点后的位数\n字符串类型\n定长字符串（char）和变长字符串（varchar） 案例 根据需求创建表（设计合理的数据类型、长度） 设计一张员工信息表，要求如下：\n编号（纯数字） 员工工号（字符串类型，长度不超过10位） 员工姓名（字符串类型，长度不超过10位） 性别（男/女，存储一个汉字） 年龄（正常人年龄，不可能存储负数） 身份证号（二代身份证号均为18位，身份证中有X这样的字符） 入职时间（取值年月日即可） 员工信息表\n1 2 3 4 5 6 7 8 9 create table emp_info ( id int comment \u0026#39;编号\u0026#39;, emp_no varchar(10) comment \u0026#39;工号\u0026#39;, name varchar(10) comment \u0026#39;姓名\u0026#39;, gender char(1) comment \u0026#39;性别\u0026#39;, age tinyint unsigned comment \u0026#39;年龄\u0026#39;, idcard char(18) comment \u0026#39;身份证\u0026#39;, entrydate date comment \u0026#39;入职时间\u0026#39; ) comment \u0026#39;员工信息表\u0026#39;; DDL-表操作 修改 添加字段 1 ALTER TABLE 表名 ADD 字段名 类型(长度) [COMMENT 注释] [约束]; 案例：为emp_info表增加一个新的字段\u0026quot;昵称\u0026quot;为nickname，类型为varchar(20) 1 alter table emp_info add nickname varchar(20) comment \u0026#39;昵称\u0026#39;； 修改数据类型 1 ALTER TABLE 表名 MODIFY 字段名 新数据类型(长度); 修改字段名和字段类型 1 ALTER TABLE 表名 CHANGE 旧字段名 新字段名 类型(长度) [COMMENT 注释] [约束]; 案例：将emp_info表的nickname字段修改为username，类型为varchar(30) 1 alter table emp_info change nickname username varchar(30) comment \u0026#39;用户名\u0026#39;; 删除字段 1 ALTER TABLE 表名 DROP 字段名; 案例：将emp_info表的字段username删除 1 alter table emp_info drop username; 修改表名 1 ALTER TABLE 表名 RENAME TO 新表名; 案例：将emp_info的表名修改为employee 1 alter table emp_info rename to employee; 删除 删除表 1 DROP TABLE [IF EXISTS] 表名; 删除tb_user表 删除指定表，并创建该表 1 TRUNCATE TABLE 表名; 删除并重新创建表employee 注意：在删除表时，表中的全部数据也会被删除。\nDataGrip 破解教程：DataGrip 2025.1 安装与永久激活全流程教程 项目默认目录 C:\\Users\\Administrator\\DataGripProjects 常用工具 Sqlyog\nNavicat\nDataGrip\nDML 介绍 DML(Data Manipulation Language)，用来对数据库中表的数据记录进行增删改操作 关键字 作用 INSERT 添加数据 UPDATE 修改数据 DELETE 删除数据 插入 添加数据 给指定字段添加数据 1 INSERT INTO 表名(字段名1,字段名2,...) VALUES(值1,值2,...); 给全部字段添加数据 1 INSERT INTO 表名 VALUES(值1,值2,...) 批量添加数据 1 INSERT INTO 表名(字段名1,字段名2,...) VALUES(值1,值2,...),(值1,值2,...),(值1,值2,...); 1 INSERT INTO 表名 VALUES(值1,值2,...),(值1,值2,...),(值1,值2,...); 注意:\n插入数据时，指定的字段顺序需要与值的顺序是一一对应的。 字符串和日期型数据应该包含在引号中。 插入的数据大小，应该在字段的规定范围内。 案例 指定字段插入数据到employee 1 insert into employee(id,emp_no,name,gender,age,idcard,entrydate) values(1,\u0026#39;1\u0026#39;,\u0026#39;itcast\u0026#39;,\u0026#39;男\u0026#39;,10,\u0026#39;123456789012345678\u0026#39;,\u0026#39;2000-01-01\u0026#39;); 查询表\n双击employee表 输入查询语句 1 select * from employee; 给全部字段添加数据插入到employee\n1 insert into employee values(2,\u0026#39;2\u0026#39;,\u0026#39;张无忌\u0026#39;,\u0026#39;男\u0026#39;,18,\u0026#39;123456789012345678\u0026#39;,\u0026#39;2005-01-01\u0026#39;); 给employee插入多条数据 1 insert into employee values(3,\u0026#39;3\u0026#39;,\u0026#39;韦一笑\u0026#39;,\u0026#39;男\u0026#39;,38,\u0026#39;123456789012345678\u0026#39;,\u0026#39;2005-01-01\u0026#39;),(4,\u0026#39;4\u0026#39;,\u0026#39;赵敏\u0026#39;,\u0026#39;女\u0026#39;,18,\u0026#39;123456789012345678\u0026#39;,\u0026#39;2005-01-01\u0026#39;); 修改 修改数据 1 UPDATE 表名 SET 字段名1=值1,字段名2=值2,... [WHERE 条件]; 注意：修改语句的条件可以有，也可以没有，如果没有条件，则会修改整张表的所有数据。\n案例 修改id为1的数据，将name修改为itheima 1 update employee set name = \u0026#39;itheima\u0026#39; where id = 1; 修改id为1的数据，将name修改为小昭，gender修改为女 1 update employee set name = \u0026#39;小昭\u0026#39;,gender = \u0026#39;女\u0026#39; where id = 1; 将所有员工入职日期修改为2008-01-01 1 update employee set entrydate=\u0026#39;2008-01-01\u0026#39;; 删除 删除数据 1 DELETE FROM 表名 [WHERE 条件]; 注意：\nDELETE语句的条件可以有，也可以没有，如果没有条件，则会删除整张表的所有数据。 DELETE语句不能删除某个字段的值(可以使用UPDATE) 案例 删除gender为女的员工 1 delete from employee where gender = \u0026#39;女\u0026#39;; 删除所有员工 1 delete from employee; DQL 介绍 DQL(Data Query Language)，用来查询数据库中表的记录 关键字 作用 SELECT 查询数据 语法 1 2 3 4 5 6 7 8 9 10 11 12 13 14 SELECT 字段列表 FROM 表名列表 WHERE 条件列表 GROUP BY 分组字段列表 HAVING 分组后条件列表 ORDER BY 排序字段列表 LIMIT 分页参数 数据准备 emp表 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 drop table if exists emp; create table emp( id int comment \u0026#39;编号\u0026#39;, workno varchar(10) comment \u0026#39;工号\u0026#39;, name varchar(10) comment \u0026#39;姓名\u0026#39;, gender char comment \u0026#39;性别\u0026#39;, age tinyint unsigned comment \u0026#39;年龄\u0026#39;, idcard char(18) comment \u0026#39;身份证号\u0026#39;, workaddress varchar(50) comment \u0026#39;工作地址\u0026#39;, entrydate date comment \u0026#39;入职时间\u0026#39; ) comment \u0026#39;员工表\u0026#39;; insert into emp (id, workno, name, gender, age, idcard, workaddress, entrydate) values (1,\u0026#39;1\u0026#39;,\u0026#39;柳岩\u0026#39;,\u0026#39;女\u0026#39;,20,\u0026#39;123456789012345678\u0026#39;,\u0026#39;北京\u0026#39;,\u0026#39;2000-01-01\u0026#39;), (2,\u0026#39;2\u0026#39;,\u0026#39;张无忌\u0026#39;,\u0026#39;男\u0026#39;,18,\u0026#39;123456789012345678\u0026#39;,\u0026#39;北京\u0026#39;,\u0026#39;2005-09-01\u0026#39;), (3,\u0026#39;3\u0026#39;,\u0026#39;韦一笑\u0026#39;,\u0026#39;男\u0026#39;,38,\u0026#39;123456789012345678\u0026#39;,\u0026#39;上海\u0026#39;,\u0026#39;2005-08-01\u0026#39;), (4,\u0026#39;4\u0026#39;,\u0026#39;赵敏\u0026#39;,\u0026#39;女\u0026#39;,18,\u0026#39;123456789012345678\u0026#39;,\u0026#39;北京\u0026#39;,\u0026#39;2009-12-01\u0026#39;), (5,\u0026#39;5\u0026#39;,\u0026#39;小昭\u0026#39;,\u0026#39;女\u0026#39;,16,\u0026#39;123456789012345678\u0026#39;,\u0026#39;上海\u0026#39;,\u0026#39;2007-07-01\u0026#39;), (6,\u0026#39;6\u0026#39;,\u0026#39;杨逍\u0026#39;,\u0026#39;男\u0026#39;,28,\u0026#39;123456789012345678\u0026#39;,\u0026#39;北京\u0026#39;,\u0026#39;2006-01-01\u0026#39;), (7,\u0026#39;7\u0026#39;,\u0026#39;范瑶\u0026#39;,\u0026#39;男\u0026#39;,40,\u0026#39;123456789012345678\u0026#39;,\u0026#39;北京\u0026#39;,\u0026#39;2005-05-01\u0026#39;), (8,\u0026#39;8\u0026#39;,\u0026#39;黛绮丝\u0026#39;,\u0026#39;女\u0026#39;,38,\u0026#39;123456789012345678\u0026#39;,\u0026#39;天津\u0026#39;,\u0026#39;2015-05-01\u0026#39;), (9,\u0026#39;9\u0026#39;,\u0026#39;范凉凉\u0026#39;,\u0026#39;女\u0026#39;,45,\u0026#39;123456789012345678\u0026#39;,\u0026#39;北京\u0026#39;,\u0026#39;2010-04-01\u0026#39;), (10,\u0026#39;10\u0026#39;,\u0026#39;陈友谅\u0026#39;,\u0026#39;男\u0026#39;,53,\u0026#39;123456789012345678\u0026#39;,\u0026#39;上海\u0026#39;,\u0026#39;2011-01-01\u0026#39;), (11,\u0026#39;11\u0026#39;,\u0026#39;张志成\u0026#39;,\u0026#39;男\u0026#39;,55,\u0026#39;123456789012345678\u0026#39;,\u0026#39;江苏\u0026#39;,\u0026#39;2015-05-01\u0026#39;), (12,\u0026#39;12\u0026#39;,\u0026#39;常遇春\u0026#39;,\u0026#39;男\u0026#39;,32,\u0026#39;123456789012345678\u0026#39;,\u0026#39;北京\u0026#39;,\u0026#39;2004-02-01\u0026#39;), (13,\u0026#39;13\u0026#39;,\u0026#39;张三丰\u0026#39;,\u0026#39;男\u0026#39;,88,\u0026#39;123456789012345678\u0026#39;,\u0026#39;江苏\u0026#39;,\u0026#39;2020-11-01\u0026#39;), (14,\u0026#39;14\u0026#39;,\u0026#39;灭绝\u0026#39;,\u0026#39;女\u0026#39;,65,\u0026#39;123456789012345678\u0026#39;,\u0026#39;西安\u0026#39;,\u0026#39;2019-05-01\u0026#39;), (15,\u0026#39;15\u0026#39;,\u0026#39;胡青牛\u0026#39;,\u0026#39;男\u0026#39;,70,\u0026#39;123456789012345678\u0026#39;,\u0026#39;西安\u0026#39;,\u0026#39;2018-04-01\u0026#39;), (16,\u0026#39;16\u0026#39;,\u0026#39;周芷若\u0026#39;,\u0026#39;女\u0026#39;,18,null,\u0026#39;北京\u0026#39;,\u0026#39;2012-06-01\u0026#39;); 基本查询 查询多个字段 查询指定多个字段 1 SELECT 字段1,字段2,字段3... FROM 表名; 查询所有字段 1 SELECT * FROM 表名; 设置别名 1 SELECT 字段1 [AS 别名1],字段2 [AS 别名2],... FROM 表名; 去除重复记录 1 SELECT DISTINCT 字段列表 FROM 表名; 案例 查询指定字段 name，work，age 返回 1 select name,workno,age from emp; 查询所有字段返回 1 select * from emp; 查询所有员工的工作地址，起别名 1 2 3 select workaddress as \u0026#39;工作地址\u0026#39; from emp; # as 可以省略 select workaddress \u0026#39;工作地址\u0026#39; from emp; 查询公司员工的上班地址(不要重复) 1 select distinct workaddress from emp; 条件查询 语法 1 SELECT 字段列表 FROM 表名 WHERE 条件列表; 条件 比较运算符 功能 \u0026gt; 大于 \u0026gt;= 大于等于 \u0026lt; 小于 \u0026lt;= 小于等于 = 等于 \u0026lt;\u0026gt; 或 != 不等于 BETWEEN \u0026hellip; AND \u0026hellip; 在某个范围之内(含最小、最大值) IN(\u0026hellip;) 在in之后的列表中的值，多选一 LIKE 占位符 模糊匹配(_匹配单个字符，%匹配任意个字符) IS NULL 是NULL 逻辑运算符 功能 AND 或 \u0026amp;\u0026amp; 并且（多个条件同时成立） OR 或 || 或者（多个条件任意一个成立） NOT 或 ! 非，不是 案例 查询年龄等于 88 的员工 1 select * from emp where age = 88; 查询年龄小于 20 的员工信息 1 select * from emp where age \u0026lt; 20; 查询年龄小于等于 20 的员工信息 1 select * from emp where age \u0026lt;= 20; 查询没有身份证号的员工信息 1 select * from emp where idcard is null; 查询有身份证号的员工信息 1 select * from emp where idcard is not null; 查询年龄不等于 88 的员工信息 1 2 select * from emp where age \u0026lt;\u0026gt; 88; select * from emp where age != 88; 查询年龄在15岁（包含）到20岁（包含）之间的员工信息 1 2 3 select * from emp where age \u0026gt;= 15 \u0026amp;\u0026amp; age \u0026lt;= 20; select * from emp where age \u0026gt;= 15 and age \u0026lt;= 20; select * from emp where age between 15 and 20; 查询性别为 女 且年龄小于 25岁的员工信息 1 select * from emp where gender = \u0026#39;女\u0026#39; and age \u0026lt; 25; 查询年龄等于18 或 20 或 40 的员工信息 1 2 3 select * from emp where age = 18 || age = 20 || age = 40; select * from emp where age = 18 or age = 20 or age = 40; select * from emp where age in(18,20,40) 查询姓名为两个字的员工信息 1 select * from emp where name like \u0026#39;__\u0026#39;; 查询身份证号最后一位是X的员工信息 1 select * from emp where idcard like \u0026#39;%X\u0026#39; 聚合函数 介绍\n将一列数据作为一个整体，进行纵向计算。 常见聚合函数\n函数 功能 count 统计数量 max 最大值 mmin 最小值 avg 平均值 sum 求和 语法 1 SELECT 聚合函数(字段列表) FROM 表名; 案例 统计该企业员工数量 1 select count(*) from emp; # 16 1 select count(idcard) from emp; # 15 注意：null不参与统计\n统计该企业员工的平均年龄 1 select avg(age) from emp; 统计该企业员工的最大年龄 1 select max(age) from emp; 统计该企业员工的最小年龄 1 select min(age) from emp; 统计该企业员工的年龄之和 1 select sum(age) from emp; 统计西安地区员工的年龄之和 1 select sum(age) from emp where workaddress = \u0026#39;西安\u0026#39;; 分组查询 语法 1 SELECT 字段列表 FROM 表名 [WHERE 条件] GROUP BY 分组字段名 [HAVING 分组后过滤条件]; where 和having的区别\n执行时机不同：where是分组之前进行过滤，不满足where条件，不参与分组；而having是分组之后对结果进行过滤 判断条件不同：where不能对聚合函数进行判断，而having可以。 案例 根据性别分组，统计男性员工和女性员工的数量 1 select gender, count(*) from emp group by gender; 根据性别分组，统计男性员工和女性员工的平局年龄 1 select gender, avg(age) from emp group by gender; 查询年龄小于45的员工，并根据工作地址分组。获取员工数量大于等于3的工作地址 1 2 3 select workaddress, count(*) from emp where age \u0026lt; 45 group by workaddress having count(*) \u0026gt; 3; select workaddress, count(*) emp_count from emp where age \u0026lt; 45 group by workaddress having emp_count \u0026gt; 3; 注意：\n执行顺序：where \u0026gt; 聚合函数 \u0026gt; having 分组之后，查询的字段一般为聚合函数和分组字段，查询其他字段无任何意义。 排序查询 语法 1 SELECT 字段列表 FROM 表名 ORDER BY 字段1 排序方式1,字段2 排序方式2; 排序方式 ASC : 升序 （默认值） DESC ：降序 注意：如果是多字段排序，当第一个字段值相同时，才会根据第二个字段进行排序\n案例 根据年龄对公司的员工进行升序排序 1 2 select * from emp order by age; select * from emp order by age asc; 根据入职时间，对员工进行降序排序 1 select * from emp order by entrydate desc; 根据年龄对公司的员工进行升序排序，年龄相同，再按照入职时间进行降序排序 1 select * from emp order by age asc,entrydate desc; 分页查询 语法 1 SELECT 字段列表 FROM 表名 LIMIT 起始索引,查询记录数; 注意\n起始索引从0开始，起始索引=（查询页码-1）* 每页显示记录数 分页查询时数据库的方言，不同数据库有不同的实现，MySQL中时LIMIT 如果查询的是第一页数据，起始索引可以省略，直接简写为limit 10 案例 查询第1页员工数据，每页显示10条记录 1 2 3 select * from emp limit 0,10; # 或者 select * from emp limit 10; 查询第2页员工数据，每页显示10条记录 1 select * from emp limit 10,10; 案例练习 查询年龄为20,21,22,23岁的女性员工信息 1 select * from emp where gender=\u0026#39;女\u0026#39; and age in(20,21,22,23); 查询性别为男，并且年龄在20~40岁(含)以内的姓名为三个字的员工 1 select * from emp where gender = \u0026#39;男\u0026#39; and age between 20 and 40 and name like \u0026#39;___\u0026#39;; 统计员工表中，年龄小于60岁，男性员工和女性员工的人数 1 select gender,count(*) from emp where age \u0026lt; 60 group by gender; 查询所有年龄小于等于35岁员工的姓名和年龄，并对查询结果按年龄升序排序，如果年龄相同按入职时间降序排序 1 select name,age from emp where age \u0026lt;= 35 order by age,entrydate desc; 查询性别为男，且年龄在20~40岁(含)以内的前5个员工信息，对查询的结果按年龄升序排序，年龄相同按入职时间升序排序 1 select * from emp where gender=\u0026#39;男\u0026#39; and age \u0026gt; 20 and age \u0026lt;= 40 order by age,entrydate desc limit 5; 执行顺序 编写顺序 1 2 3 4 5 6 7 8 9 10 11 12 13 14 SELECT 字段列表 FROM 表名列表 WHERE 条件列表 GROUP BY 分组字段列表 HAVING 分组后条件列表 ORDER BY 排序字段列表 LIMIT 分页参数 执行顺序 1 2 3 4 5 6 7 8 9 10 11 12 13 14 FROM 表名列表 WHERE 条件列表 GROUP BY 分组字段列表 HAVING 分组后条件列表 SELECT 字段列表 ORDER BY 排序字段列表 LIMIT 分页参数 验证 查询年龄大于15的员工姓名、年龄，并根据年龄进行升序排序 1 select name,age from emp e where e.age \u0026gt; 15 order by age asc; 先执行from，就会创建emp的别名e，才能执行where\n1 select e.name,e.age from emp e where e.age \u0026gt; 15 order by age asc; 先执行from，才会创建emp的别名e，才能执行select\n1 select e.name ename,e.age eage from emp e where eage \u0026gt; 15 order by age asc; 报错：Unknown column \u0026rsquo;eage\u0026rsquo; in \u0026lsquo;where clause\u0026rsquo;\n原因；因为select是where之后执行的，所以where不能使用select声明的别名\n1 select e.name ename,e.age eage from emp e where e.age \u0026gt; 15 order by eage asc; order by可以使用select的声明，所以select在order by之前执行。\nDCL 介绍 Data Control Language(数据控制语言)，用来管理数据库用户、控制数据库的访问权限。 管理用户 查询用户 1 2 USE mysql; SELECT * FROM user; 创建用户 1 CREATE USER \u0026#39;用户名\u0026#39;@\u0026#39;主机名\u0026#39; IDENTIFIED BY \u0026#39;密码\u0026#39;; 修改用户密码 1 ALTER USER \u0026#39;用户名\u0026#39;@\u0026#39;主机名\u0026#39; IDENTIFIED WITH mysql_native_password BY \u0026#39;新密码\u0026#39;; 删除用户 1 DROP USER \u0026#39;用户名\u0026#39;@\u0026#39;主机名\u0026#39;; 案例 创建用户itcast，只能够在当前主机localhost访问，密码123456; 1 create user \u0026#39;itcast\u0026#39;@\u0026#39;localhost\u0026#39; identified by \u0026#39;123456\u0026#39;; 创建用户itfox，可以在任意主机访问该数据库，密码123456; 1 create itfox \u0026#39;itfox\u0026#39;@\u0026#39;%\u0026#39; identified by \u0026#39;123456\u0026#39; 修改用户itfox的访问密码为1234; 1 alter user \u0026#39;itfox\u0026#39;@\u0026#39;localhost\u0026#39; identified with mysql_native_password by \u0026#39;1234\u0026#39;; 删除itcast@localhost用户 1 drop user \u0026#39;itcast\u0026#39;@\u0026#39;localhost\u0026#39;; 注意：\n主机名可以使用%通配符 这类SQL开发人员操作的比较少，主要是DBA（Database Administrator 数据库管理员）使用。 权限控制 常用权限 权限 说明 ALL,ALL PRIBILEGES 所有权限 SELECT 查询数据 INSERT 插入数据 UPDATE 修改数据 DELETE 删除数据 ALTER 修改表 DROP 删除数据库/表/视图 CREATE 创建数据库/表 查询权限 1 SHOW GRANTS FOR \u0026#39;用户名\u0026#39;@\u0026#39;主机名\u0026#39;; 授予权限 1 GRANT 权限列表 ON 数据库名.表名 TO \u0026#39;用户名\u0026#39;@\u0026#39;主机名\u0026#39;; 撤销权限 1 REVOKE 权限列表 ON 数据库名.表名 FROM \u0026#39;用户名\u0026#39;@\u0026#39;主机名\u0026#39;; 案例 查询itfox的权限 1 show grants for \u0026#39;itfox\u0026#39;@\u0026#39;%\u0026#39;; 授予itfox用户，关于itcast数据库的所有权限 1 grant all on itcast.* to \u0026#39;itfox\u0026#39;@\u0026#39;%\u0026#39;; 撤销itfox用户，关于itcast数据库的所有权限 1 revoke all on itcast.* from \u0026#39;itfox\u0026#39;@\u0026#39;%\u0026#39;; 注意：\n多个权限之间，使用逗号分隔 授权时，数据库名和表名可以使用*进行通配，代表所有 生词 identify / aɪˈdentɪfaɪ / v、认出，识别；查明，确认；发现 identified / aɪˈdentɪfaɪd / adj、被识别的；经鉴定的；被认同的；v、鉴定；辨认 ","date":"2025-10-13T00:13:16+08:00","permalink":"https://YLine-hub.github.io/p/mysqlmysql%E5%9F%BA%E7%A1%80-sql/","title":"[MySQL]MySQL基础-SQL"},{"content":"问题：解压nginx压缩包后，解压的文件不属于当前用户 查看当前用户 1 id 这里能看到当前用户是root\n解压nginx压缩包 1 tar -zxvf nginx-1.22.1.tar.gz 可以看到nginx文件夹属于1001用户，mysql组\n检查系统中1001和mysql的信息 1 2 grep 1001 /etc/passwd grep mysql /etc/group 原因 其实根源在于你解压的时候没有明确指定 属主和属组的情况下。 解压时使用的是压缩文件中保存的属主和属组信息。\n通过-tvf参数组合来查看压缩包中的文件信息 1 tar -tvf nginx-1.22.1.tar.gz 可以看到这里展示的用户和用户组是mdounin/mdounin，主机中肯定没有这个用户，而且也不是root\n可以在后面添加一个参数--numeric-owner 1 tar -tvf nginx-1.22.1.tar.gz --numeric-owner 看到这里显示的属主和属组是1001/1001，正是对应当前主机上对应的mysql组。\n解压之后的属主和属组不影响实际使用。\n可以解压后修改属主和属组 1 2 # -R 参数是递归所有子目录与文件 chown -R 属主:属组 文件夹 例如这里可以用\n1 chown -R root:root nginx-1.22.1 ","date":"2025-10-12T21:25:31+08:00","permalink":"https://YLine-hub.github.io/p/linux%E5%B0%8F%E7%9F%A5%E8%AF%86%E5%AD%A6%E4%B9%A0-%E5%8E%8B%E7%BC%A9%E5%8C%85%E8%A7%A3%E5%8E%8B%E5%90%8E%E5%B1%9E%E4%B8%BB%E5%92%8C%E5%B1%9E%E7%BB%84%E4%B8%8D%E6%98%AF%E5%BD%93%E5%89%8D%E7%94%A8%E6%88%B7%E9%97%AE%E9%A2%98/","title":"[Linux]小知识学习-压缩包解压后属主和属组不是当前用户问题"},{"content":"nginx安装配置 卸载nginx 安装前查看系统内是否有nginx 1 ps -ef | grep nginx 上图可以看出没有nginx服务启动\n关闭nginx服务（若有nginx） 1 kill 进程ID 查看是否有nginx相关文件 1 find / -name nginx 删除nginx有关文件（若有nginx相关文件） 1 rm -rf 文件名 安装nginx 安装nginx所需环境 安装nginx需要下载官网源码编译，编译依赖 gcc 环境 (gcc-c++) nginx的http模块使用pcre来解析正则表达式，所以需要pcre库 (pcre pcre-devel) nginx使用zlib对http包进行gzip，所以需要zlib库 (zlib zlib-devel) nginx不仅支持http协议，还支持https协议（即在ssl协议上传输http），所以需要OpenSSL库 (openssl openssl-devel) 1 yum -y install gcc-c++ pcre pcre-devel zlib zlib-devel openssl openssl-devel 在/usr/local目录下创建nginx目录 1 mkdir /usr/local/nginx 下载nginx解压包到/opt目录下 nginx下载地址：nginx download\n选择其中自己需要的版本，我这里选择1.22.1版本 1 2 3 4 # 到 /opt目录下 cd /opt # 下载nginx wget https://nginx.org/download/nginx-1.22.1.tar.gz 解压安装包，并配置编译安装nginx 解压安装包 1 tar -zxvf nginx-1.22.1.tar.gz 进入nginx-1.22.1目录中 1 cd nginx-1.22.1 配置 1 ./configure --prefix=/usr/local/nginx --with-http_stub_status_module --with-http_ssl_module 编译和安装 1 2 3 4 # 编译 make # 安装 make install 注意：nginx配置的目标目录和配置编译安装的目录不能是同一个。比如这里配置的目标目录是/usr/local/nginx，用来配置编译安装的目录是/opt/nginx-1.22.1\n配置环境变量（方便快速启动nginx） 1 2 echo \u0026#34;export PATH=$PATH:/usr/local/nginx/sbin\u0026#34; \u0026gt;\u0026gt; /etc/profile source /etc/profile 启动关闭nginx服务 1 2 3 4 5 6 # 启动nginx服务 ./nginx # 修改配置后，重新加载配置 ./nginx -s reload # 关闭nginx服务 ./nginx -s stop 查询是否正在运行 用netstat查询是否正在运行 1 netstat -ntlp 没有netstat命令\n查询netstat命令在哪个包内 1 yum search netstat 下载net-tools包 1 yum -y install net-tools 再次查询 1 netstat -ntlp 说明启动成功\n打开80端口 nginx默认使用80端口，如果修改了，就需要开放相应的端口 1 2 3 4 5 6 # 查看80端口是否开启 firewall-cmd --query-port=80/tcp # 开启80端口 firewall-cmd --zone=public --add-port=80/tcp --permanent # 重启防火墙 firewall-cmd --reload 用浏览器访问 访问：http://192.168.172.136 ","date":"2025-10-12T20:46:14+08:00","permalink":"https://YLine-hub.github.io/p/centos7.6nginx%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/","title":"[CentOS7.6]nginx安装配置"},{"content":"环境 环境：\nVMware 虚拟机 CentOS7.6 目标：\nMySQL 5.7 准备资源 MySQL下载地址： MySQL Community Server\n查找所需mysql版本，我需要下载的是mysql5.7 这里我准备下载的是第一个tar.gz包，右键上图中的红框部分，复制下载链接，也可以直接下载下来上传到Linux服务器 复制的链接：\n1 https://downloads.mysql.com/archives/get/p/23/file/mysql-5.7.44-linux-glibc2.12-x86_64.tar.gz 安装 创建mysql所属组、用户 即使mysql服务被黑掉，得到了mysql用户权限，也不会影响整个系统的安全 1 2 3 4 # 创建新组mysql groupadd mysql # 创建用户mysql，指定属组为mysql，禁止其登陆 useradd -r -g mysql mysql -s /sbin/nologin 下载mysql安装、解压，并放到/usr/local目录下 进入/opt目录下 1 cd /opt 下载mysql的tar.gz包 1 wget https://downloads.mysql.com/archives/get/p/23/file/mysql-5.7.44-linux-glibc2.12-x86_64.tar.gz 解压下载好的压缩包 1 tar -zxvf mysql-5.7.44-linux-glibc2.12-x86_64.tar.gz 解压完成后将其移动到/usr/local目录下并改文件夹名为mysql（规范） 1 mv mysql-5.7.44-linux-glibc2.12-x86_64 /usr/local/mysql 配置mysql 创建所需目录 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 # 创建存储数据目录 mkdir /usr/local/mysql/data # 创建数据日志目录 mkdir /usr/local/mysql/log # 创建临时文件目录 mkdir /usr/local/mysql/tmp # 创建运行文件目录 mkdir /usr/local/mysql/run # 创建启动错误日志 touch /usr/local/mysql/log/mysqld_safe_error.log # 创建默认的错误日志目的地 touch /usr/local/mysql/log/alert.log # 创建慢查询日志文件 touch /usr/local/mysql/log/slow.log # 创建通用查询日志文件 touch /usr/local/mysql/log/general.log 编辑配置文件 1 vim /etc/my.cnf 使用:1,$d清空文件内容 my.cnf 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 # mysqld_safe脚本启动时读取的配置 [mysqld_safe] # 存放MySQL后台程序pid的文件位置 pid-file=/usr/local/mysql/run/mysqld.pid # 启动错误日志 log-error=/usr/local/mysql/log/mysqld_safe_error.log # 本地mysql客户端程序的配置 [mysql] # 本地mysql客户端连接的端口 port=3306 # 本地mysql客户端命令提示信息 prompt=\\\\u@\\\\d \\\\r:\\\\m:\\\\s\u0026gt; # 本地mysql客户端字符集 default-character-set=utf8mb4 # 开启命令补全 no-auto-rehash # 所有mysql客户端程序读取的配置块 [client] # 连接端口 port=3306 # mysql的主机和客户机在同一host上的时候，使用unix domain socket作为通讯协议的载体文件 socket=/usr/local/mysql/run/mysql.sock # mysql服务端程序mysqld、mysqld_safe和mysqld_multi的配置文件 [mysqld] # 进程崩溃时生成core file dump文件，便于程序调试和问题排查 core-file # 该参数指定了安装mysql的安装路径（mysql安装目录），填写全路径可以解决相对路径所造成的问题。 basedir=/usr/local/mysql # 启动bin_log log-bin=mysql-bin server-id=1 binlog_format=ROW # 该参数指定了mysql的数据文件的存放目录，数据库文件即我们常说的mysql data文件。 datadir=/usr/local/mysql/data # 临时目录 tmpdir=/usr/local/mysql/tmp # 用于错误消息的区域设置。默认值时en_US。服务器将参数转换为语言名，并将其与lc_messages_dir的值结合，以生成错误消息文件的位置。 lc_messages=en_US # 错误消息所在目录。服务器使用该值和lc_messages的值来生成错误消息文件的位置。 lc_messages_dir=/usr/local/mysql/share # 默认的错误日志目的地。如果目标是控制台，则值为stderr。否则，目标是一个文件，log_error值时文件名。 log-error=/usr/local/mysql/log/alert.log # 慢查询日志文件名。默认值是host_name-slow.log，但可以通过slow_query_log_file选项更改初始值。 slow_query_log_file=/usr/local/mysql/log/slow.log # 通用查询日志文件的名称。默认值是host_name.log，但初始值可以通过general_log_file选项更改。 general_log_file=/usr/local/mysql/log/general.log # mysql的主机和客户机在同一host上的时候，使用unix domain socket作为通讯协议的载体文件 socket=/usr/local/mysql/run/mysql.sock # 服务端字符集 character-set-server=utf8mb4 # 此变量控制写入错误日志的消息中的时间戳的时区，以及写入文件的一般查询日志和慢查询日志消息中的时间戳的时区。 log_timestamps=SYSTEM # 操作系统中可用于mysqld的文件描述符的数量 open_files_limit=61535 # 同时允许的最大客户连接数 max_connections=1000 # mysql_stmt_send_long_data() C API函数发送的一个包或任何生成/中间字符串的最大大小，或任何参数的最大大小。默认是64MB。 max_allowed_packet=1G # 如果设置为0，表名将按指定的方式存储，并且比较区分大小写。如果设置为1，表名将以小写形式存储在磁盘上，比较不区分大小写。如果设置为2，则表名按给定值存储，但以小写进行比较。此选项也适用于数据库名称和表别名。 lower_case_table_names=1 # 慢查询日志是否开启。取值为0（或OFF）表示关闭日志，取值为1（或ON）表示打开日志。默认值取决于是否给出--slow_query_log选项。日志输出的目标由log_output系统变量控制；如果该值为NONE，则即使启用了日志，也不会写入任何日志项。 slow_query_log=1 # validate_password插件的加载方法 plugin-load-add=validate_password.so # validate-password在服务器启动时使用该选项来控制插件的激活 validate-password=FORCE_PLUS_PERMANENT 初始化数据库 设置环境变量 1 2 3 4 5 6 # 将mysql/bin路径添加到配置文件（根据自己的路径修改） # 记住必须要用 \u0026gt;\u0026gt; 而不是 \u0026gt; # 如果当心文件被覆盖可以打开/etc/profile文件，将下面这句写到文件最后面 echo \u0026#34;export PATH=$PATH:/usr/local/mysql/bin\u0026#34; \u0026gt;\u0026gt; /etc/profile # 生效配置文件 source /etc/profile 将安装目录的所有权授予用户、属组 mysql:mysql 1 chown -R mysql:mysql /usr/local/mysql 初始化数据库 1 mysqld --initialize --user=mysql --basedir=/usr/local/mysql/ --datadir=/usr/local/mysql/data/ 查询mysql初始密码 1 grep -e \u0026#39;temporary\u0026#39; /usr/local/mysql/log/alert.log 可以看到初始密码：kv?kghe.C5:x\n再次将安装目录的所有全授予用户、属组 mysql:mysql 1 chown -R mysql:mysql /usr/local/mysql 将安装目录的 rwx 授予其所属用户mysql 1 chmod -R 755 /usr/local/mysql 复制启动文件到/etc/init.d目录下 1 cp -ar /usr/local/mysql/support-files/mysql.server /etc/init.d/mysqld 启动mysql服务 \u0026amp;\u0026amp; 设置开机自启动 启动mysql服务 1 /etc/init.d/mysqld start 其他命令:\n1 2 3 /etc/init.d/mysqld stop # 停止mysql /etc/init.d/mysqld restart # 重启mysql /etc/init.d/mysqld status # 查看mysql状态 设置开机自启动 1 2 3 4 // 添加服务 chkconfig --add mysqld // 显示服务列表 chkconfig --list 开机自启设置成功\n登陆mysql \u0026amp;\u0026amp; 修改mysql密码 1 mysql -uroot -p 输入密码（在这里输入密码是看不到的） 降低密码验证等级 1 2 3 4 # 设置密码验证安全级别 set global validate_password_policy=LOW; # 设置密码验证最小长度 set global validate_password_length=6; 修改登陆密码（修改为123456） 1 set password for root@localhost = password(\u0026#39;123456\u0026#39;); 查看密码验证规则 1 SHOW VARIABLES LIKE \u0026#39;validate_password%\u0026#39;; 开放远程登陆 \u0026amp;\u0026amp; 放行3306端口 开放远程登陆 1 2 3 4 5 6 # 登录进来之后，切换到mysql库 use mysql; # 修改用户权限 update user set user.Host=\u0026#39;%\u0026#39; where user.User=\u0026#39;root\u0026#39;; # 刷新权限 flush privileges; 退出mysql 1 2 3 exit; # 或者 ctrl+d 放行3306端口 1 2 3 4 5 6 # 检查3306端口是否放行 firewall-cmd --query-port=3306/tcp # 打开3306端口 firewall-cmd --zone=public --add-port=3306/tcp --permanent # 重新加载防火墙 firewall-cmd --reload 测试连接 Navicat破解：Navicat Cracker ","date":"2025-10-12T17:33:04+08:00","permalink":"https://YLine-hub.github.io/p/centos7.6%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEmysql5.7%E4%BC%98%E5%8C%96/","title":"【CentOS7.6】安装配置mysql5.7(优化)"},{"content":"二进制包/源码安装方式的mysql卸载 检查mysql服务并关闭进程 查看mysql进程 1 ps -ef | grep mysql 查看mysql状态 1 /etc/init.d/mysqld status 关闭mysql 1 /etc/init.d/mysqld stop 再次查看mysql的状态和有关mysql的进程 1 2 /etc/init.d/mysqld status ps -ef | grep mysql 关闭mysql用户的进程 其实上图是，我用roo su mysql后进入mysql用户的命令行，之后又su root用mysql打开root账号，所以只需要exit两边即可\n1 2 3 4 $ exit exit $ exit exit 再次查看进程 1 ps -ef | grep mysql 查找mysql的安装目录并彻底删除 查找mysql有关的目录 1 2 whereis mysql find / -name mysql 全部删除 1 2 3 4 rm -rf /usr/lib64/mysql/ rm -rf /usr/local/mysql/ rm -rf /run/sudo/ts/mysql rm -rf /etc/selinux/targeted/active/modules/100/mysql 删除一些配置文件 /etc/my.cnf /etc/init.d/mysqld 1 2 rm -rf /etc/my.cnf rm -rf /etc/init.d/mysqld 删除mysql用户以及用户组 1 2 userdel -r mysql groupdel mysql 查询mysql是否还存在 1 id mysql ","date":"2025-10-12T15:43:16+08:00","permalink":"https://YLine-hub.github.io/p/centos7.6%E5%BD%BB%E5%BA%95%E5%8D%B8%E8%BD%BDmysqltar.gz/","title":"【CentOS7.6】彻底卸载mysql(tar.gz)"},{"content":"MySQL安装配置 环境 环境：\nVMware 虚拟机 CentOS7.6 目标：\nMySQL 5.7 准备资源 MySQL下载地址： MySQL Community Server\n查找所需mysql版本，我需要下载的是mysql5.7 这里我准备下载的是第一个tar.gz包，右键上图中的红框部分，复制下载链接，也可以直接下载下来上传到Linux服务器 复制的链接：\n1 https://downloads.mysql.com/archives/get/p/23/file/mysql-5.7.44-linux-glibc2.12-x86_64.tar.gz 安装 安装前检测 检查服务器是否安装过mysql，以及是否有自带的mariadb 1 2 rpm -qa | grep mysql rpm -qa | grep mariadb mariadb 其实就是 mysql，只不过是 mysql 的另一种拉出来的开源分支，也可以正常使用，如果不想卸载也是可以的。\n卸载相应的服务（若没有则跳过该阶段） 卸载mysql 1 2 3 4 5 6 7 8 9 10 11 # 卸载mysql yum -y remove MySQL* # 查找mysql目录并统一删除 find / -name mysql # 删除mysql配置文件 rm -rf /etc/my.cnf # 删除mysql默认密码（若不删除，以后安装mysql后这个sercret中的默认密码不会变，使用其中的默认密码就可能会报类似Access denied for user \u0026#39;root@localhost\u0026#39; (using password:yes)的错误。） rm -rf /root/.mysql_sercret 卸载mariadb 1 rpm -e --nodeps mariadb-libs-5.5.68-1.el7.x86_64 查看my.cnf和.mysql_sercret是否存在，有的话需要删除 1 2 cat /etc/my.cnf cat /root/.mysql_sercret 将mysql5.7的tar.gz包下载到/opt目录下 1 2 cd /opt wget https://downloads.mysql.com/archives/get/p/23/file/mysql-5.7.44-linux-glibc2.12-x86_64.tar.gz 等待下载完成 解压下载好的压缩包 1 tar -zxvf mysql-5.7.44-linux-glibc2.12-x86_64.tar.gz 解压完成后将其移动到/usr/local下并改文件名为mysql（规范） 1 mv mysql-5.7.44-linux-glibc2.12-x86_64 /usr/local/mysql 检查是否创建了mysql组和用户，没有的话需要创建 1 2 3 4 # mysql组 cat /ect/group | grep mysql # mysql用户 cat /etc/passwd | grep mysql 创建一个mysql组和用户 1 2 groupadd mysql useradd -r -g mysql mysql # -r 指的是创建一个系统账户 创建完检查 1 2 cat /etc/group | grep mysql cat /etc/passwd | grep mysql 更改mysql目录下所有文件夹所属的用户组、用户以及文件权限 切换到/usr/local目录下 1 cd /usr/local 更改mysql目录及其所有子目录和文件的用户组和用户为mysql 1 chown -R mysql:mysql mysql 给mysql目录下所有文件加执行权限 1 chmod -R 775 mysql 修改完可以使用ll查看一下 设置环境变量 1 2 3 4 5 6 # 将mysql/bin路径添加到配置文件（根据自己的路径修改） # 记住必须要用 \u0026gt;\u0026gt; 而不是 \u0026gt; # 如果当心文件被覆盖可以打开/etc/profile文件，将下面这句写到文件最后面 echo \u0026#34;export PATH=$PATH:/usr/local/mysql/bin\u0026#34; \u0026gt;\u0026gt; /etc/profile # 生效配置文件 source /etc/profile 检查是否生效 1 mysql --version 生成mysql临时密码 1 2 # 执行命令。生成临时数据库密码（还是注意路径看看是不是和你的一样） mysqld --user=mysql --initialize --datadir=/usr/local/mysql/data 生成的临时密码是： u\u0026lt;kW;59g?Ut% 千万要把临时密码记住，到后面修改完密码之后，就可以不用了；\n复制启动文件到/etc/init.d/目录 把启动脚本mysql.server放到目录/etc/init.d/，同时改名为mysqld。 1 cp -ar /usr/local/mysql/support-files/mysql.server /etc/init.d/mysqld 1 2 # 编辑文件 vim /etc/init.d/mysqld 检查以下这几个路径是否正确 创建所需目录 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 # 创建存储数据目录 mkdir /usr/local/mysql/data # 创建数据日志目录 mkdir /usr/local/mysql/log # 创建临时文件目录 mkdir /usr/local/mysql/tmp # 创建运行文件目录 mkdir /usr/local/mysql/run # 创建启动错误日志 touch /usr/local/mysql/log/mysqld_safe_error.log # 创建默认的错误日志目的地 touch /usr/local/mysql/log/alert.log # 创建慢查询日志文件 touch /usr/local/mysql/log/slow.log # 创建通用查询日志文件 touch /usr/local/mysql/log/general.log 添加my.cnf配置文件 切换到/etc/目录下 1 cd /etc/ 创建一个mysql的配置文件my.cnf 1 touch my.cnf MySQL5.7的my.cnf详细说明可以参考官方解释：\nUsing Option Files Using Options to Set Program Variables centos7 mysql5.7开启binlog：centos7 mysql5.7开启binlog\nmy.cnf配置示例\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 # mysqld_safe脚本启动时读取的配置 [mysqld_safe] # 存放MySQL后台程序pid的文件位置 pid-file=/usr/local/mysql/run/mysqld.pid # 启动错误日志 log-error=/usr/local/mysql/log/mysqld_safe_error.log # 本地mysql客户端程序的配置 [mysql] # 本地mysql客户端连接的端口 port=3306 # 本地mysql客户端命令提示信息 prompt=\\\\u@\\\\d \\\\r:\\\\m:\\\\s\u0026gt; # 本地mysql客户端字符集 default-character-set=utf8mb4 # 开启命令补全 no-auto-rehash # 所有mysql客户端程序读取的配置块 [client] # 连接端口 port=3306 # mysql的主机和客户机在同一host上的时候，使用unix domain socket作为通讯协议的载体文件 socket=/usr/local/mysql/run/mysql.sock # mysql服务端程序mysqld、mysqld_safe和mysqld_multi的配置文件 [mysqld] # 进程崩溃时生成core file dump文件，便于程序调试和问题排查 core-file # 该参数指定了安装mysql的安装路径（mysql安装目录），填写全路径可以解决相对路径所造成的问题。 basedir=/usr/local/mysql # 启动bin_log log-bin=mysql-bin server-id=1 binlog_format=ROW # 该参数指定了mysql的数据文件的存放目录，数据库文件即我们常说的mysql data文件。 datadir=/usr/local/mysql/data # 临时目录 tmpdir=/usr/local/mysql/tmp # 用于错误消息的区域设置。默认值时en_US。服务器将参数转换为语言名，并将其与lc_messages_dir的值结合，以生成错误消息文件的位置。 lc_messages=en_US # 错误消息所在目录。服务器使用该值和lc_messages的值来生成错误消息文件的位置。 lc_messages_dir=/usr/local/mysql/share # 默认的错误日志目的地。如果目标是控制台，则值为stderr。否则，目标是一个文件，log_error值时文件名。 log-error=/usr/local/mysql/log/alert.log # 慢查询日志文件名。默认值是host_name-slow.log，但可以通过slow_query_log_file选项更改初始值。 slow_query_log_file=/usr/local/mysql/log/slow.log # 通用查询日志文件的名称。默认值是host_name.log，但初始值可以通过general_log_file选项更改。 general_log_file=/usr/local/mysql/log/general.log # mysql的主机和客户机在同一host上的时候，使用unix domain socket作为通讯协议的载体文件 socket=/usr/local/mysql/run/mysql.sock # 服务端字符集 character-set-server=utf8mb4 # 此变量控制写入错误日志的消息中的时间戳的时区，以及写入文件的一般查询日志和慢查询日志消息中的时间戳的时区。 log_timestamps=SYSTEM # 操作系统中可用于mysqld的文件描述符的数量 open_files_limit=61535 # 同时允许的最大客户连接数 max_connections=1000 # mysql_stmt_send_long_data() C API函数发送的一个包或任何生成/中间字符串的最大大小，或任何参数的最大大小。默认是64MB。 max_allowed_packet=1G # 如果设置为0，表名将按指定的方式存储，并且比较区分大小写。如果设置为1，表名将以小写形式存储在磁盘上，比较不区分大小写。如果设置为2，则表名按给定值存储，但以小写进行比较。此选项也适用于数据库名称和表别名。 lower_case_table_names=1 # 慢查询日志是否开启。取值为0（或OFF）表示关闭日志，取值为1（或ON）表示打开日志。默认值取决于是否给出--slow_query_log选项。日志输出的目标由log_output系统变量控制；如果该值为NONE，则即使启用了日志，也不会写入任何日志项。 slow_query_log=1 # validate_password插件的加载方法 plugin-load-add=validate_password.so # validate-password在服务器启动时使用该选项来控制插件的激活 validate-password=FORCE_PLUS_PERMANENT 给mysql的配置文件添加执行权限 1 chmod -R 775 /etc/my.cnf 启动mysql服务 \u0026amp;\u0026amp; 设置开机自启 启动前先查询是否启动过 1 2 ps -ef|grep -v grep |grep mysql ps -ef|grep -v grep |grep mysqld 启动mysql服务 1 /etc/init.d/mysqld start 启动失败 1 Starting MySQL.. ERROR! The server quit without updating PID file (/usr/local/mysql/data/localhost.yline.pid). 替换配置文件 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 [client] default-character-set = utf8mb4 [mysql] default-character-set = utf8mb4 [mysqld] port = 3306 basedir = /usr/local/mysql datadir = /usr/local/mysql/data socket = /usr/local/mysql/run/mysql.sock symbolic-links = 0 log-error = /usr/local/mysql/log/alert.log pid-file = /usr/local/mysql/run/mysqld.pid # 禁用主机名解析 skip-name-resolve # 默认的数据库引擎 default-storage-engine = InnoDB innodb-file-per-table = 1 innodb_force_recovery = 1 group_concat_max_len = 10240 sql_mode = NO_ENGINE_SUBSTITUTION,STRICT_TRANS_TABLES expire_logs_days = 7 memlock # 字符集配置 character-set-client-handshake = FALSE character-set-server = utf8mb4 collation-server = utf8mb4_unicode_ci init_connect = \u0026#39;SET NAMES utf8mb4\u0026#39; # GTID 配置 server_id = 330759 binlog_format = row gtid_mode = on enforce-gtid-consistency = true log_bin = mysql57-bin log-slave-updates = on skip_slave_start = 1 # 慢查询日志 slow_query_log = 1 long_query_time = 2 log_queries_not_using_indexes = 0 slow_query_log_file = /usr/local/mysql/log/slow.log # 自动修复 relay_log_info_repository = TABLE master_info_repository = TABLE relay_log_recovery = on relay_log_purge = 1 # 数据安全性配置 log_bin_trust_function_creators = on sync_binlog = 1 explicit_defaults_for_timestamp = true # 优化配置 ft_min_word_len = 1 lower_case_table_names = 1 max_allowed_packet = 256M query_cache_size = 64M query_cache_limit = 1M join_buffer_size = 16M thread_cache_size = 64 # InnoDB 优化 innodb_buffer_pool_size = 2G innodb_log_file_size = 256M innodb_log_buffer_size = 4M innodb_flush_log_at_trx_commit = 1 innodb_log_files_in_group = 3 innodb_file_per_table = 1 innodb_write_io_threads = 8 innodb_read_io_threads = 8 innodb_purge_threads = 1 innodb_max_dirty_pages_pct = 90 innodb_lock_wait_timeout = 120 innodb_strict_mode = 1 innodb_large_prefix = on [mysqldump] quick default-character-set = utf8mb4 max_allowed_packet = 256M 还是如下报错： 1 Starting MySQL.. ERROR! The server quit without updating PID file (/usr/local/mysql/data/mysqld.pid). 找到原因：一般是root用户执行导致，如果是root以外的用户执行不会报错\n解决方法：修改/usr/local/mysql/support-files/mysql.server和/etc/init.d/mysqld文件\n编辑/usr/local/mysql/support-files/mysql.server和/etc/init.d/mysqld文件 1 2 3 4 5 # 编辑/usr/local/mysql/support-files/mysql.server vim /usr/local/mysql/support-files/mysql.server # 编辑/etc/init.d/mysqld vim /etc/init.d/mysqld 使用/+关键字找到$bindir/mysqld_safe 在后面添加 --user=root 按esc，然后用:wq保存文件 重新启动 1 /etc/init.d/mysqld start 启动成功\n设置开机自启 1 2 3 4 // 添加服务 chkconfig --add mysqld // 显示服务列表 chkconfig --list 开机自启设置成功\n登陆mysql \u0026amp;\u0026amp; 修改mysql密码 1 mysql -uroot -p 输入密码（在这里输入密码是看不到的） 出现报错 1 ERROR 2002 (HY000): Can\u0026#39;t connect to local MySQL server through socket \u0026#39;/tmp/mysql.sock\u0026#39; (2) 解决方法：在/tmp下做一个mysql.sock的软链接 1 ln -s /usr/local/mysql/run/mysql.sock /tmp/mysql.sock 重新登陆 1 mysql -uroot -p 登陆进来后修改密码（修改为123456） 1 set password for root@localhost = password(\u0026#39;123456\u0026#39;); 修改成功\n按ctrl+d退出重新试一下 再次登陆 1 mysql -uroot -p123456 开放远程登陆 \u0026amp;\u0026amp; 测试本地客户端连接 开放远程登陆 1 2 3 4 5 6 #登录进来之后，切换到mysql库 use mysql; #修改用户权限 update user set user.Host=\u0026#39;%\u0026#39; where user.User=\u0026#39;root\u0026#39;; #刷新权限 flush privileges; 防火墙放行3306端口 1 2 3 4 5 6 # 检查3306端口是否放行 firewall-cmd --query-port=3306/tcp # 打开3306端口 firewall-cmd --zone=public --add-port=3306/tcp --permanent # 重新加载防火墙 firewall-cmd --reload 连接测试 准备工具：Navicat Cracker 或者 navicat-keygen-16 ","date":"2025-10-11T18:34:30+08:00","permalink":"https://YLine-hub.github.io/p/centos7.6mysql%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/","title":"【CentOS7.6】MySQL安装配置"},{"content":"jdk8安装配置 环境：\nCentOS7.6 64位系统 查询系统位数\n64位系统：x686或x86_64 32位系统：i686或i386 1 uname -m 可以看到我的系统是64位的\n方法一（推荐） 手动下载安装包 Java SE 8 - Oracle 通过MobaXterm上传到/opt目录下 MobaXterm选中内容将会自动复制 注意：上传文件的路径建议用英文。如果用中文的话可能会导致文件无法上传。\n解压安装包 1 2 cd /opt tar -zxvf jdk-8u202-linux-x64.tar.gz 将解压的文件夹移动到/usr/local下并改为java 解压完成后，当前目录会有一个jdk1.8.0_202的文件夹。将文件夹移动到/usr/local/java下（一般安装的软件都会放到/usr/local/目录下）。 1 2 # 将文件移动到/usr/local目录下，并将文件名改为java mv jdk1.8.0_202/ /usr/local/java 设置环境变量 编辑profile文件 1 vim /etc/profile 配置环境变量 1 2 3 export JAVA_HOME=/usr/local/java export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar export PATH=$PATH:$JAVA_HOME/bin 使环境变量生效 1 source /etc/profile 验证是否完成安装 1 java -version 方法二 查询系统是否有jdk 1 2 3 java -version rpm -qa | grep java 批量卸载系统自带 1 2 3 rpm -qa | grep java | xargs rpm -e --nodeps # 或者 rpm -e --nodeps java* 检查yum中是否有java安装包 1 yum list java* 找到自己需要的jdk8 使用yum安装jdk8 1 yum install -y java-1.8.0-openjdk 验证 1 java -version ","date":"2025-10-10T15:27:53+08:00","permalink":"https://YLine-hub.github.io/p/centos7.6jdk8%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/","title":"【CentOS7.6】jdk8安装配置"},{"content":"Shell文件包含 介绍 和其他语言一样，Shell 也可以包含外部脚本。 可以很方便的封装一些公用的代码作为一个独立的文件。 基本语法 1 2 3 4 5 . filename # 注意点号(.)和文件名中间有一空格 或 source filename 示例 创建脚本1：include1.sh 1 2 3 #!/bin/bash url=\u0026#34;www.baidu.com\u0026#34; 创建脚本2：include2.sh 1 2 3 4 5 6 7 8 9 #!/bin/bash # 使用.号来引用include1.sh文件 . ./include1.sh # 或者使用以下包含文件代码 # source ./include1.sh echo \u0026#34;百度地址：$url\u0026#34; 为include2.sh添加执行权限并执行 1 2 chmod +x include2.sh ./include2.sh 注：被包含的文件 test1.sh 不需要可执行权限。\n","date":"2025-10-10T15:06:21+08:00","permalink":"https://YLine-hub.github.io/p/shell%E6%96%87%E4%BB%B6%E5%8C%85%E5%90%AB/","title":"Shell文件包含"},{"content":"Shell 输入/输出重定向 重定向命令列表\n命令 说明 command \u0026gt; file 将输出重定向到file command \u0026lt; file 将输入重定向到file command \u0026raquo; file 将输出以追加的方式重定向到file n \u0026gt; file 将文件描述符为n的文件重定向到file n \u0026raquo; file 将文件描述符为n的文件以追加的方式重定向到file n \u0026gt;\u0026amp; m 将输出文件m和n合并 n \u0026lt;\u0026amp; m 将输入文件m和n合并 \u0026laquo; tag 将开始标记tag和结束标记tag之间的内容作为输入 需要注意的是文件描述符 0 通常是标准输入（STDIN），1 是标准输出（STDOUT），2 是标准错误输出（STDERR）。\nShell输出重定向 基本语法 1 command1 \u0026gt; file1 示例 将命令的完整的输出重定向在用户文件中(users)，没有users文件会自动创建 1 who \u0026gt; users 查看文件内容 1 cat users 输出重定向会覆盖文件内容 1 echo \u0026#34;www.baidu.com\u0026#34; \u0026gt; users 如果不希望文件内容被覆盖，可以使用\u0026raquo;追加到文件末尾 1 echo \u0026#34;www.google.com\u0026#34; \u0026gt;\u0026gt; users Shell输入重定向 基本语法 1 command1 \u0026lt; file1 示例 统计users文件的行数 1 wc -l users 也可也将输入重定向到users文件 1 wc -l \u0026lt; users 注意：上述两个例子结果不同：第一个例子会输出文件名，第二个不会，因为他仅仅知道从标准输入读取内容。\n同时替换输入和输出，执行命令command1，从文件infile读取内容，然后将输出写入到outfile 1 command1 \u0026lt; infile \u0026gt; outfile 统计users文件的行数，并输出到linefile文件内 重定向深入讲解 一般情况下，每个 Unix/Linux 命令运行时都会打开三个文件：\n标准输入文件(stdin)：stdin的文件描述符为0，Unix程序默认从stdin读取数据。 标准输出文件(stdout)：stdout 的文件描述符为1，Unix程序默认向stdout输出数据。 标准错误文件(stderr)：stderr的文件描述符为2，Unix程序会向stderr流中写入错误信息。 基本语法 如果希望stderr重定向到file 1 command 2\u0026gt;file 如果希望 stderr 追加到 file 文件末尾 1 command 2\u0026gt;\u0026gt;file 2 表示标准错误文件(stderr)。\n如果希望将 stdout 和 stderr 合并后重定向到 file 1 2 3 4 5 command \u0026gt; file 2\u0026gt;\u0026amp;1 # 或者 command \u0026gt;\u0026gt; file 2\u0026gt;\u0026amp;1 如果希望对 stdin 和 stdout 都重定向 1 command \u0026lt; file1 \u0026gt;file2 Here Document 介绍 Shell 中的一种特殊的重定向方式，用来将输入重定向到一个交互式 Shell 脚本或程序。 基本语法 将两个 delimiter 之间的内容(document) 作为输入传递给 command。 1 2 3 command \u0026lt;\u0026lt; delimiter document delimiter 注意：\n结尾的delimiter 一定要顶格写，前面不能有任何字符，后面也不能有任何字符，包括空格和 tab 缩进。 开始的delimiter前后的空格会被忽略掉。 示例 在命令行中通过wc -l命令计算Here Document的行数 1 2 3 4 5 $ wc -l \u0026lt;\u0026lt; EOF \u0026gt; www.baidu.com \u0026gt; www.google.com \u0026gt; EOF 2 # 输出结果为2行 也可也将Here Document用在脚本中 1 2 3 4 5 6 #!/bin/bash cat \u0026lt;\u0026lt; EOF www.baidu.com www.google.com EOF /dev/null 文件 介绍 如果希望执行某个命令，但又不希望在屏幕上显示输出结果，那么可以将输出重定向到 /dev/null 1 command \u0026gt; /dev/null /dev/null /dev/null 是一个特殊的文件，写入到它的内容都会被丢弃。 如果尝试从该文件读取内容，那么什么也读不到。 但是 /dev/null 文件非常有用，将命令的输出重定向到它，会起到\u0026quot;禁止输出\u0026quot;的效果。 如果希望屏蔽 stdout 和 stderr\n1 command \u0026gt; /dev/null 2\u0026gt;\u0026amp;1 注意：0 是标准输入（STDIN），1 是标准输出（STDOUT），2 是标准错误输出（STDERR）。 这里的 2 和 \u0026gt; 之间不可以有空格，2\u0026gt; 是一体的时候才表示错误输出。 ","date":"2025-10-10T14:18:27+08:00","permalink":"https://YLine-hub.github.io/p/shell%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA%E9%87%8D%E5%AE%9A%E5%90%91/","title":"Shell输入输出重定向"},{"content":"Shell 函数 介绍 用户定义函数，然后在shell脚本中可以随便调用。 基本语法 1 2 3 4 5 6 [ function ] funname [()] { action; [return int;] } 说明：\n1、可以带function fun()定义，也可也直接fun()定义，不带任何参数 2、参数返回，可以显示加：return 返回，如果不加，将以最后一条命令运行结果，作为返回值。return 后跟数值n(0-255) 示例 第一个函数 1 2 3 4 5 6 7 8 #!/bin/bash demoFun(){ echo \u0026#34;这是我的第一个 shell 函数！\u0026#34; } echo \u0026#34;-----函数开始执行-----\u0026#34; demoFun echo \u0026#34;-----函数执行完毕-----\u0026#34; 输出：\n1 2 3 -----函数开始执行----- 这是我的第一个 shell 函数! -----函数执行完毕----- 定义带有return语句的函数 1 2 3 4 5 6 7 8 9 10 11 12 13 #!/bin/bash funWithReturn(){ echo \u0026#34;这个函数会对输入的两个数进行相加运算...\u0026#34; echo \u0026#34;输入第一个数字：\u0026#34; read aNum echo \u0026#34;输入第二个数字：\u0026#34; read bNum echo \u0026#34;两个数字分别为 $aNum 和 $bNum !\u0026#34; return $(($aNum+$bNum)) } funWithReturn echo \u0026#34;输入的两个数字之和为 $? !\u0026#34; 函数返回值在调用该函数后通过$?来获得\n注意： return 语句只能返回一个介于0到255之间的整数，而两个数字的和可能超过这个范围，要解决这个问题，您可以修改return语句，直接使用echo输出而不是使用return：\n1 2 3 4 5 6 7 8 9 10 11 12 13 #!/bin/bash funWithReturn(){ echo \u0026#34;这个函数会对输入的两个数进行相加运算...\u0026#34; echo \u0026#34;输入第一个数字：\u0026#34; read aNum echo \u0026#34;输入第二个数字：\u0026#34; read bNum echo \u0026#34;两个数字分别为 $aNum 和 $bNum !\u0026#34; sum=$(($aNum + $bNum)) echo \u0026#34;两个数字之和为 $sum\u0026#34; } funWithReturn 函数参数 介绍 在Shell中，调用函数时可以向其传递参数。在函数体内部，通过 $n 的形式来获取参数的值，例如，$1表示第一个参数，$2表示第二个参数\u0026hellip; 示例 1 2 3 4 5 6 7 8 9 10 11 12 #!/bin/bash funWithParam(){ echo \u0026#34;第一个参数为 $1 !\u0026#34; echo \u0026#34;第二个参数为 $2 !\u0026#34; echo \u0026#34;第十个参数为 $10 !\u0026#34; echo \u0026#34;第十个参数为 ${10} !\u0026#34; echo \u0026#34;第十一个参数为 ${11} !\u0026#34; echo \u0026#34;参数总数有 $# 个!\u0026#34; echo \u0026#34;作为一个字符串输出所有参数 $* !\u0026#34; } funWithParam 1 2 3 4 5 6 7 8 9 34 73 注意： $10 不能获取第十个参数，获取第十个参数需要${10}。当n\u0026gt;=10时，需要使用${n}来获取参数。\n特殊参数： 参数处理 说明 $# 传递到脚本或函数的参数个数 $* 以一个单字符串显示所有向脚本传递的参数 $$ 脚本运行的当前进程ID号 $! 后台运行的最后一个进程的ID号 $@ 与$*相同，但是使用时加引号，并在引号中返回每个参数。 $- 显示Shell使用的当前选项，与set命令功能相同 $? 显示最后命令的退出状态。0表示没有错误，其他任何值表明有错误。 ","date":"2025-10-10T13:02:15+08:00","permalink":"https://YLine-hub.github.io/p/shell%E5%87%BD%E6%95%B0/","title":"Shell函数"},{"content":"echo 介绍 用于在标准输出（通常是终端）显示一行文本或变量的值。 语法格式 1 echo [options] string 基本用法 简单文本输出 1 echo \u0026#34;Hello, World!\u0026#34; 输出：\n1 Hello, World! 输出变量 1 2 name=\u0026#34;Linux User\u0026#34; echo \u0026#34;Welcome, $name\u0026#34; 输出：\n1 Welcome, Linux User! 不带引号的输出（不建议） 1 echo This is a test 输出：\n1 This is a test printf 介绍 用于格式化输出的 Shell 命令，它源自 C 语言的 printf() 函数。 基本语法 1 printf format-string [arguments...] 参数说明：\nformat-string: 包含普通字符和格式说明符的字符串 arguments\u0026hellip;: 与格式说明符对应的变量或值 常用格式说明符：\n%s: 字符串 %d: 十进制整数 %f: 浮点数 %c: 字符 %x: 十六进制数 %o: 八进制数 %b: 二进制数 %e: 科学计数法表示的浮点数 示例 基本使用 1 2 3 4 5 6 7 8 #!/bin/bash # 简单字符串输出 printf \u0026#34;Hello, World!\\n\u0026#34; # 带变量的输出 name=\u0026#34;Alice\u0026#34; printf \u0026#34;Hello, %s\\n\u0026#34; \u0026#34;$name\u0026#34; 输出：\n1 2 Hello, World! Hello, Alice 常用格式说明符 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 #!/bin/bash # 整数 # decimal adj、十进制的，小数的；n、十进制，小数 # hex n、十六进制 # octal adj、八进制的 prinf \u0026#34;Decimal: %d\\nHex: %x\\nOctal: %o\\n\u0026#34; 255 255 255 # 浮点数 # scientific adj、科学的；细致严谨的 printf \u0026#34;Float: %f\\nScientific: %e\\n\u0026#34; 3.14159 3.14159 # 字符串 printf \u0026#34;Name: %s\\n\u0026#34; \u0026#34;Bob\u0026#34; # 字符 printf \u0026#34;First letter: %c\\n\u0026#34; \u0026#34;A\u0026#34; 输出：\n1 2 3 4 5 6 7 Decimal: 255 Hex: ff Octal: 377 Float: 3.141590 Scientific: 3.141590e+00 Name: Bob First letter: A 格式化控制 1 2 3 4 5 6 7 8 9 10 #!/bin/bash # 字段宽度和对齐 printf \u0026#34;|%10s|\\n|%-10s|\\n\u0026#34; \u0026#34;right\u0026#34; \u0026#34;left\u0026#34; # 数字前导零 printf \u0026#34;Year: %04d\\n\u0026#34; 23 # 浮点数精度 printf \u0026#34;Pi: %.2f\\n\u0026#34; 3.14159 输出：\n1 2 3 4 | right| |left | Year: 0023 Pi: 3.14 多参数处理 1 2 3 #!/bin/bash printf \u0026#34;%-10s %5d %8.2f\\n\u0026#34; \u0026#34;Apple\u0026#34; 5 2.5 \u0026#34;Orange\u0026#34; 3 1.75 输出：\n1 2 Apple 5 2.50 Orange 3 1.75 扩展应用 创建表格输出 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 #!/bin/bash # 表头 # quantity n、数量 printf \u0026#34;%-15s %10s %10s %10s\\n\u0026#34; \u0026#34;Item\u0026#34; \u0026#34;Quantity\u0026#34; \u0026#34;Price\u0026#34; \u0026#34;Total\u0026#34; # 分割线 printf \u0026#34;%-15s %10s %10s %10s\\n\u0026#34; \u0026#34;---------------\u0026#34; \u0026#34;----------\u0026#34; \u0026#34;----------\u0026#34; \u0026#34;----------\u0026#34; # 数据行 printf \u0026#34;%-15s %10s %10s %10s\\n\u0026#34; \u0026#34;Notebook\u0026#34; 3 2.50 7.50 printf \u0026#34;%-15s %10s %10s %10s\\n\u0026#34; \u0026#34;Pen\u0026#34; 5 1.20 6.00 printf \u0026#34;%-15s %10s %10s %10s\\n\u0026#34; \u0026#34;Eraser\u0026#34; 2 0.50 1.00 # 总计行 printf \u0026#34;%-15s %10s %10s %10.2f\\n\u0026#34; \u0026#34;\u0026#34; \u0026#34;\u0026#34; \u0026#34;Total:\u0026#34; \u0026#34;14.50\u0026#34; 输出：\n1 2 3 4 5 6 Item Quantity Price Total --------------- ---------- ---------- ---------- Notebook 3 2.50 7.50 Pen 5 1.20 6.00 Eraser 2 0.50 1.00 Total: 14.50 进度条实现 1 2 3 4 5 6 7 #!/bin/bash for i in {1..20};do printf \u0026#34;\\rProgress: [%-20s] %d%%\u0026#34; $(printf \u0026#34;%${i}s\u0026#34; | tr \u0026#39; \u0026#39; \u0026#39;#\u0026#39;) $((i*5)) sleep 0.1 done printf \u0026#34;\\n\u0026#34; 颜色输出 1 2 3 4 5 6 7 #!/bin/bash RED=\u0026#39;\\033[0;31m\u0026#39; GREEN=\u0026#39;\\033[0;32m\u0026#39; NC=\u0026#39;\\033[0m\u0026#39; # No color printf \u0026#34;${RED}Error:${NC} Something went wrong\\n\u0026#34; printf \u0026#34;${GREEN}Success:${NC} Operation completed\\n\u0026#34; 格式输出： 1 2 3 4 5 6 #!/bin/bash printf \u0026#34;%-10s %-8s %-4s\\n\u0026#34; 姓名 性别 体重kg printf \u0026#34;%-10s %-8s %-4.2f\\n\u0026#34; 郭靖 男 66.1234 printf \u0026#34;%-10s %-8s %-4.2f\\n\u0026#34; 杨过 男 48.6543 printf \u0026#34;%-10s %-8s %-4.2f\\n\u0026#34; 郭芙 女 47.9876 输出：\n1 2 3 4 姓名 性别 体重kg 郭靖 男 66.12 杨过 男 48.65 郭芙 女 47.99 test 介绍 条件判断工具，用于评估表达式并返回布尔值（真/假），它通常与 if 语句结合使用。 语法格式 1 2 test expression 或 [ expression ] # 注意方括号内必须有空格 文件测试操作 常用文件测试选项 操作符 描述 示例 -e 文件是否存在 [ -e file.txt ] -f 是普通文件 [ -f /path/to/file ] -d 是目录 [ -d /path/to/dir ] -r 可读 [ -r file.txt ] -w 可写 [ -w file.txt ] -x 可执行 [ -x script.sh ] -s 文件大小\u0026gt;0 [ -s logfile ] -L 是符号链接 [ -L symlink ] 示例 1 2 3 4 5 6 7 8 9 10 11 #!/bin/bash file=\u0026#34;/etc/passwd\u0026#34; if [ -e \u0026#34;$file\u0026#34; ];then echo \u0026#34;$file 存在\u0026#34; if [ -r \u0026#34;$file\u0026#34; ];then echo \u0026#34;并且可读\u0026#34; fi else echo \u0026#34;$file 不存在\u0026#34; fi 输出：\n1 2 /etc/passwd 存在 /etc/passwd 可读 字符串比较 操作符 描述 示例 -z string 字符串为空 [ -z \u0026ldquo;$var\u0026rdquo; ] -n string 字符串非空 [ -n \u0026ldquo;$var\u0026rdquo; ] string1 = string2 字符串相等 [ \u0026ldquo;$var1\u0026rdquo; = \u0026ldquo;$var2\u0026rdquo; ] string1 != string2 字符串不等 [ \u0026ldquo;$var1\u0026rdquo; != \u0026ldquo;$var2\u0026rdquo; ] 示例 1 2 3 4 5 6 7 8 9 10 11 12 #!/bin/bash read -p \u0026#34;输入用户名：\u0026#34; username if [ -z \u0026#34;$username\u0026#34; ];then echo \u0026#34;错误：用户名不能为空\u0026#34; exit 1 elif [ \u0026#34;$username\u0026#34; = \u0026#34;root\u0026#34; ];then echo \u0026#34;警告：不建议使用root账号\u0026#34; else echo \u0026#34;欢迎，$username\u0026#34; fi 输出：\n1 2 输入用户名: yline 欢迎, yline 数值比较 操作符 描述 示例 -eq 等于 [ \u0026ldquo;$a\u0026rdquo; -eq \u0026ldquo;$b\u0026rdquo; ] -ne 不等于 [ \u0026ldquo;$a\u0026rdquo; -ne \u0026ldquo;$b\u0026rdquo; ] -gt 大于 [ \u0026ldquo;$a\u0026rdquo; -gt \u0026ldquo;$b\u0026rdquo; ] -ge 大于或等于 [ \u0026ldquo;$a\u0026rdquo; -ge \u0026ldquo;$b\u0026rdquo; ] -lt 小于 [ \u0026ldquo;$a\u0026rdquo; -lt \u0026ldquo;$b\u0026rdquo; ] -le 小于或等于 [ \u0026ldquo;$a\u0026rdquo; -le \u0026ldquo;$b\u0026rdquo; ] 示例 1 2 3 4 5 6 7 8 9 10 11 12 13 #!/bin/bash read -p \u0026#34;输入年龄：\u0026#34; age if [ \u0026#34;$age\u0026#34; -lt 0 ];then echo \u0026#34;年龄不能为负数\u0026#34; elif [ \u0026#34;$age\u0026#34; -lt 18 ];then echo \u0026#34;未成年人\u0026#34; elif [ \u0026#34;$age\u0026#34; -ge 18 ] \u0026amp;\u0026amp; [ \u0026#34;$age\u0026#34; -lt 60 ];then echo \u0026#34;成年人\u0026#34; else echo \u0026#34;老年人\u0026#34; fi 输出：\n1 2 输入年龄: 12 未成年人 逻辑操作符 操作符 描述 示例 ! 逻辑非 [ ! -f \u0026ldquo;$file\u0026rdquo; ] -a 逻辑与 [ \u0026ldquo;$a\u0026rdquo; -eq 1 -a \u0026ldquo;$b\u0026rdquo; -eq 2 ] -o 逻辑或 [ \u0026ldquo;$a\u0026rdquo; -eq 1 -o \u0026ldquo;$b\u0026rdquo; -eq 2 ] **现代推荐写法：**使用\u0026amp;\u0026amp;和 替代-a和-o,更符合POSIX标准 高级用法：[[]] 和 （（）） 双括号[[]]\n支持模式匹配：[[ \u0026ldquo;$var\u0026rdquo; == *.txt ]] 支持正则表达式：[[ \u0026ldquo;$var\u0026rdquo; =~ ^[0-9]+$ ]] 更安全的字符串处理 算术比较(())\n专为数值比较设计：(( a \u0026gt; b )) 支持更复杂的算数表达式 示例\n1 2 3 4 5 6 7 8 9 #!/bin/bash if [[ \u0026#34;$file\u0026#34; == *.log ]];then echo \u0026#34;这是日志文件\u0026#34; fi if (( $count \u0026gt; 10 ));then echo \u0026#34;数量超过10\u0026#34; fi 实际应用示例 检查服务是否运行 1 2 3 4 5 6 7 8 9 10 11 12 13 #!/bin/bash read -p \u0026#34;请输入要查询的服务：\u0026#34; service if [ -z \u0026#34;$service\u0026#34; ];then echo \u0026#34;服务名不能为空\u0026#34; exit 1 elif systemctyl is-active --quiet \u0026#34;$service\u0026#34;; then echo \u0026#34;$service 正在运行\u0026#34; else echo \u0026#34;$service 未运行\u0026#34; # 可以添加启动服务的命令 fi 备份文件检查 1 2 3 4 5 6 7 8 9 10 11 12 #!/bin/bash backup_file=\u0026#34;/backups/data_$(date + %Y%m%d).tar.gz\u0026#34; if [ ! -f \u0026#34;$backup_file\u0026#34; ];then echo \u0026#34;错误：备份文件 $backup_file 不存在\u0026#34; exit 1 elif [ ! -s \u0026#34;$backup_file\u0026#34; ];then echo \u0026#34;警告：备份文件为空\u0026#34; else echo \u0026#34;备份验证成功\u0026#34; fi ","date":"2025-10-09T17:33:47+08:00","permalink":"https://YLine-hub.github.io/p/shell%E5%AE%9E%E7%94%A8%E6%8C%87%E4%BB%A4/","title":"Shell实用指令"},{"content":"基础元字符 元字符 作用 * 前一个字符匹配0次或任意多次 . 匹配除换行符外的任意一个字符 + 匹配前面的模式一次或多次 ? 匹配前面的模式0次或一次 ^ 匹配首行。例如，^hello会匹配以hello开头的行 $ 匹配行尾。例如，hello$会匹配以hello结尾的行 [] 匹配中括号中指定的任意一个字符，而且只匹配一个字符。例如，[aeiu]匹配任意一个元音字母，[0-9]匹配任意一位数字，[a-z][0-9]匹配由小写字母和一位数字构成的两位字符 [^] 匹配除中括号中字符外的任意一个字符。例如，[^0-9]匹配一位非数字字符，[^a-z]匹配任意一位非小写字母 \\ 转义符，用于取消特殊符号的含义 \\{n\\} 表示其前面的字符恰好出现n次。例如，[0-9]\\{4\\}匹配4位数字，[1][3-8][0-9]\\{9\\}匹配手机号码 \\{n,\\} 表示其前面的字符出现不少于n次。例如，[0-9]\\{2,\\}匹配两位以上的数字 \\{n,m\\} 表示其前面的字符至少出现n次，最多出现m次。例如，[a-z]\\{6,8\\}匹配6至8位的小写字母 示例 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 # 示例1：使用.匹配任意字符 echo \u0026#34;cat dog pig\u0026#34; | grep \u0026#34;d.g\u0026#34; # 输出：dog # 示例2：使用*匹配零次或多次 echo \u0026#34;color colour\u0026#34; | grep \u0026#34;colou*r\u0026#34; # 输出：color colour # 示例3：使用^和$匹配行的开始和结束 echo -e \u0026#34;start\\nend\\nstart end\u0026#34; | grep \u0026#34;^start\u0026#34; # 输出：start start end # 示例4：使用字符集[] echo \u0026#34;bag big bog bug\u0026#34; | grep \u0026#34;b[aeiou]g\u0026#34; # 输出：bag big bog bug # 示例5：使用否定字符集[^] echo \u0026#34;bag big bog bug\u0026#34; | grep \u0026#34;b[^i]g\u0026#34; # 输出：bag bog bug Shell中使用正则表达式的工具 grep命令 语法格式 1 grep [options] pattern [file...] options: -E:使用扩展正则表达式 -i:忽略大小写 -v:反向匹配，显示不匹配的行 -n:显示匹配行的行号 -r:递归搜索目录 示例 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 # 示例1：基本搜索 echo -e \u0026#34;apple\\nbanana\\ncherry\u0026#34; | grep \u0026#34;an\u0026#34; # 输出：banana # 示例2：使用-i忽略大小写 echo -e \u0026#34;Apple\\nbanana\\Cherry\u0026#34; | grep -i \u0026#34;a\u0026#34; # 输出：Apple # banana # 示例3：使用-v反向匹配 echo -e \u0026#34;apple\\nbanana\\ncherry\u0026#34; | grep -v \u0026#34;an\u0026#34; # 输出：apple # cheery # 示例4：使用-n显示行号 echo -e \u0026#34;apple\\nbanana\\ncheery\u0026#34; | grep -n \u0026#34;e\u0026#34; # 输出：1:apple # 3:cheery # 示例5：使用-E启用扩展正则表达式 echo -e \u0026#34;color\\ncolour\u0026#34; | grep -E \u0026#34;colou?r\u0026#34; # 输出：color # colour sed命令 语法格式 1 sed [opions] \u0026#39;command\u0026#39; [file...] 常用命令：\ns/pattern/replacement/：替换 /pattern/d：删除 /pattern/p：打印 options:\n-E：使用正则表达式 -i：直接修改文件内容 -n：抑制自动打印模式空间 示例 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 # 示例1：基本替换 echo \u0026#34;Hello，World\u0026#34; | sed \u0026#39;s/World/Universe/\u0026#39; # 输出：Hello，Universe # 示例2：全局替换 echo \u0026#34;color color\u0026#34; | sed \u0026#39;s/color/colour/g\u0026#39; # 输出：colour colour # 示例3：删除匹配行 echo -e \u0026#34;apple\\nbanana\\ncherry\u0026#34; | sed \u0026#39;/banana/d\u0026#39; # 输出：apple # cherry # 示例4：只打印匹配行 echo -e \u0026#34;apple\\nbanana\\ncherry\u0026#34; | sed -n \u0026#39;/a/p\u0026#39; # 输出：apple # banana # 示例5：使用-E启用扩展正则表达式 echo \u0026#34;123-456-7890\u0026#34; | sed -E \u0026#39;s/([0-9]{3})-([0-9]{3})-([0-9]{4})/(\\1)\\2-\\3/\u0026#39; # 输出：(123)456-7890 # 其中\\1，\\2，\\3分别是第一个、第二个、第三个匹配的内容 awk命令 语法格式 1 awk [options] \u0026#39;pattern {action}\u0026#39; [file...] 常用内置变量： $0：整行内容 $1，$2，\u0026hellip;：第一个字段，第二个字段，以此类推 NF：字段数量 NR：当前处理的行号 示例 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 # 示例1：打印特定列 echo -e \u0026#34;John 25\\nJane 30\\nBob 35\u0026#34; | awk \u0026#39;{print $1}\u0026#39; # 输出：John # Jane # Bob # 示例2：使用正则表达式匹配 echo -e \u0026#34;apple 5\\nbanana 3\\ncherry 8\u0026#34; | awk \u0026#39;/a/ {print $0}\u0026#39; # 输出：apple 5 # banana 3 # 示例3：计算总和 echo -e \u0026#34;apple 5\\nbanana 3\\ncherry 8\u0026#34; | awk \u0026#39;{sum += $2} END {print \u0026#34;Total:\u0026#34;, sum}\u0026#39; # 输出：Total: 16 # 示例4：自定义字段分隔符 echo \u0026#34;2023-05-15,John,Doe\u0026#34; | awk -F\u0026#39;,\u0026#39; \u0026#39;{print $2}\u0026#39; # 输出：John # 示例5：条件处理 echo -e \u0026#34;John 25\\nJane 30\\nBob 35\u0026#34; | awk \u0026#39;$2 \u0026gt; 28 {print $1 \u0026#34; is over 28\u0026#34;}\u0026#39; # 输出：Jane is over 28 # Bob is over 28 Shell正则表达式示例 正则表达式(Regular Expression) 简称regex\n=~: 进行正则表达式匹配\n匹配手机号 1 2 3 4 5 6 7 8 9 #!/bin/bash read -p \u0026#34;请输入手机号：\u0026#34; phone_number if [[ phone_number =~ ^1[3456789][0-9]\\{9\\} ]];then echo \u0026#34;您输入的手机号 $phone_number 符合要求\u0026#34; else echo \u0026#34;您输入的手机号 $phone_number 不符合要求\u0026#34; fi 手机号正确，但是返回不符合要求 进行调试\n1 2 3 4 # 调试语法 bash -x regex1.sh # 或者 sh -x regex1.sh 原因：这里能看到这个参数并没有变成我们需要的值 修正：在参数phone_number前加上$使值传入 修改如下：\n1 2 3 4 5 6 7 8 9 #!/bin/bash read -p \u0026#34;请输入手机号：\u0026#34; phone_number if [[ $phone_number =~ ^1[3456789][0-9]\\{9\\} ]];then echo \u0026#34;您输入的手机号 $phone_number 符合要求\u0026#34; else echo \u0026#34;您输入的手机号 $phone_number 不符合要求\u0026#34; fi 可以看到还是不符合要求，其中红框内变成了\\{9} 修正：将\\{9\\}替换为{9} 修改如下：\n1 2 3 4 5 6 7 8 9 #!/bin/bash read -p \u0026#34;请输入手机号：\u0026#34; phone_number if [[ $phone_number =~ ^1[3456789][0-9]{9} ]];then echo \u0026#34;您输入的手机号 $phone_number 符合要求\u0026#34; else echo \u0026#34;您输入的手机号 $phone_number 不符合要求\u0026#34; fi 上述代码利用了=~运算符来进行正则表达式匹配，其中^1[3456789][0-9]{9}表示以1为开头，第二位为3/4/5/6/7/8/9重任意一个，后面跟着9位数字的字符串。\n查询目录下的所有.sh文件 1 2 3 4 5 #!/bin/bash for file in ./*.sh; do echo \u0026#34;$file\u0026#34; done 替换字符串中的数字 1 2 3 4 5 6 7 8 9 10 11 #!/bin/bash string=\u0026#34;\u0026#34;abcd1234\u0026#34; echo \u0026#34;替换前：$string\u0026#34; # 将字符串中的所有数字替换为 # new_string=(echo \u0026#34;$string\u0026#34; | sed \u0026#39;s/[0-9]/#/g\u0026#39;) echo \u0026#34;替换后：$new_string\u0026#34; # 修正：使用 $() 而不是 () 1 2 3 4 5 6 7 8 9 10 11 #!/bin/bash string=\u0026#34;\u0026#34;abcd1234\u0026#34; echo \u0026#34;替换前：$string\u0026#34; # 将字符串中的所有数字替换为 # # 修正：使用 $() 而不是 () new_string=$(echo \u0026#34;$string\u0026#34; | sed \u0026#39;s/[0-9]/#/g\u0026#39;) echo \u0026#34;替换后：$new_string\u0026#34; 匹配URL地址 1 2 3 4 5 6 7 8 #!/bin/bash read -p \u0026#34;请输入 URL 地址：\u0026#34; url if [[ $url =~ ^(http|https)://[a-z0-9]+(\\.[a-z0-9]+){1,3}.* ]]; then echo \u0026#34;您输入的 URL 地址 $url 符合要求\u0026#34; else echo \u0026#34;您输入的 URL 地址 $url 不符合要求\u0026#34; fi ^(http|https)://[a-z0-9]+(\\.[a-z0-9]+){1,3}.* (http|https)表示http或https开头 [a-z0-9]+(\\.[a-z0-9]+){1,3}表示后面跟着1到3段类似于.xxx的字符串 .*表示.后面还可以跟着任意字符 其他技巧 grep 查找文件的指定内容的行 1 grep pattern file 查找文件test.txt中包含单词hello的行： 1 grep hello test.txt awk 对文本进行分割、筛选、统计等操作 1 awk \u0026#39;/pattern/ { action }\u0026#39; file 查找文件test.txt中长度大于10的行 1 awk \u0026#39;length \u0026gt; 10\u0026#39; test.txt sed 匹配和替换操作 1 sed \u0026#39;s/pattern/replacement/\u0026#39; file 将文件test.txt中的所有空格替换为下划线 1 sed \u0026#39;s/ /_/g\u0026#39; test.txt ","date":"2025-10-08T21:04:44+08:00","permalink":"https://YLine-hub.github.io/p/shell%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/","title":"Shell正则表达式"},{"content":"流程控制 条件判断 判断条件 （1）关系运算符 运算符 说明 -eq 相等 -ne 不相等 -gt 大于 -lt 小于 -ge 大于等于 -le 小于等于 示例 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 #!/bin/bash a=10 b=20 if [ $a -eq $b ] then echo \u0026#34;$a -eq $b : a 等于 b\u0026#34; else echo \u0026#34;$a -eq $b : a 不等于 b\u0026#34; fi if [ $a -ne $b ] then echo \u0026#34;$a -ne $b : a 不等于 b\u0026#34; else echo \u0026#34;$a -ne $b : a 等于 b\u0026#34; fi if [ $a -gt $b ] then echo \u0026#34;$a -gt $b : a 大于 b\u0026#34; else echo \u0026#34;$a -gt $b : a 不大于 b\u0026#34; fi if [ $a -lt $b ] then echo \u0026#34;$a -lt $b : a 小于 b\u0026#34; else echo \u0026#34;$a -lt $b : a 不小于 b\u0026#34; fi if [ $a -ge $b ] then echo \u0026#34;$a -ge $b : a 大于或等于 b\u0026#34; else echo \u0026#34;$a -ge $b : a 小于 b\u0026#34; fi if [ $a -le $b ] then echo \u0026#34;$a -le $b : a 小于或等于 b\u0026#34; else echo \u0026#34;$a -le $b : a 大于 b\u0026#34; fi （2）布尔运算符 运算符 说明 ! 非运算，表达式为true则返回false -o 或运算，有一个表达式为true则返回true -a 与运算，两个表达式都为true才返回true 示例 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 #!/bin/bash a=10 b=20 if [ $a != $b ] then echo \u0026#34;$a != $b : a 不等于 b\u0026#34; else echo \u0026#34;$a == $b : a 等于 b\u0026#34; fi if [ $a -lt 100 -a $b -gt 15 ] then echo \u0026#34;$a 小于 100 且 $b 大于 15 : 返回 true\u0026#34; else echo \u0026#34;$a 小于 100 且 $b 大于 15 : 返回 false\u0026#34; fi if [ $a -lt 100 -o $b -gt 100 ] then echo \u0026#34;$a 小于 100 或 $b 大于 100 : 返回 true\u0026#34; else echo \u0026#34;$a 小于 100 或 $b 大于 100 : 返回 false\u0026#34; fi if [ $a -lt 5 -o $b -gt 100 ] then echo \u0026#34;$a 小于 5 或 $b 大于 100 : 返回 true\u0026#34; else echo \u0026#34;$a 小于 5 或 $b 大于 100 : 返回 false\u0026#34; fi （3）逻辑运算符 1 2 \u0026amp;\u0026amp; 逻辑AND || 逻辑OR 示例 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 #!/bin/bash a=10 b=20 if [[ $a -lt 100 \u0026amp;\u0026amp; $b -gt 100 ]] then echo \u0026#34;$a 小于 100 AND $b 大于 100 : 返回 true\u0026#34; else echo \u0026#34;$a 小于 100 AND $b 大于 100 : 返回 false\u0026#34; fi if [[ $a -lt 100 || $b -gt 100 ]] then echo \u0026#34;$a 小于 100 OR $b 大于 100 : 返回 true\u0026#34; else echo \u0026#34;$a 小于 100 OR $b 大于 100 : 返回 false\u0026#34; fi （4）字符串运算符 运算符 说明 = 检测两个字符是否相等，相等返回true != 检测两个字符是否不相等，不相等返回true -z 检测字符串长度是否为0，为0返回true -n 检测字符串长度是否不为0，不为0返回true $ 检测字符串是否不为空，不为空返回true 示例 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 #!/bin/bash a=\u0026#34;abc\u0026#34; b=\u0026#34;efg\u0026#34; if [ $a = $b ] then echo \u0026#34;$a = $b : a 等于 b\u0026#34; else echo \u0026#34;$a = $b : a 不等于 b\u0026#34; fi if [ $a != $b ] then echo \u0026#34;$a != $b : a 不等于 b\u0026#34; else echo \u0026#34;$a != $b : a 等于 b\u0026#34; fi if [ -z $a ] then echo \u0026#34;-z $a : 字符串长度为 0\u0026#34; else echo \u0026#34;-z $a : 字符串长度不为 0\u0026#34; fi if [ -n $a ] then echo \u0026#34;-n $a : 字符串长度不为 0\u0026#34; else echo \u0026#34;-n $a : 字符串长度为 0\u0026#34; fi if [ $a ] then echo \u0026#34;$a : 字符串不为空\u0026#34; else echo \u0026#34;$a : 字符串为空\u0026#34; fi if语句 方式一 1 2 3 4 5 6 7 if [ 判断条件 ]; then 代码逻辑 else 代码逻辑 fi # 注意：[]中的内容左右两边要有空格，[]结尾用带有; 方法二 1 2 3 4 5 6 7 if [ 判断条件 ] then 代码逻辑 else 代码逻辑 fi # 注意：跟上面基本一致，少了个分号\u0026#39;;\u0026#39; 多重判断 1 2 3 4 5 6 7 8 9 10 if [ 判断条件 ] then 代码逻辑 elif [ 判断逻辑 ] then 代码逻辑 else 代码逻辑 fi # 注意：就是用elif来拼接，用上面两种写法都可以 示例 示例：传参判断成绩等级 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 # 0 =\u0026lt; D \u0026lt;= 50 # 50 \u0026lt; C \u0026lt;= 70 # 70 \u0026lt; B \u0026lt;= 90 # 90 \u0026lt; A \u0026lt;= 100 #!/bin/bash if [ $1 -ge 0 -a $1 -lt 50 ] then echo \u0026#34;成绩为：$1，评分为：D\u0026#34; elif [ $1 -gt 50 -a $1 -le 70 ] then echo \u0026#34;成绩为：$1，评分为：C\u0026#34; elif [ $1 -gt 70 -a $1 -le 90 ] then echo \u0026#34;成绩为：$1，评分为：B\u0026#34; elif [ $1 -gt 90 -a $1 -le 100 ] then echo \u0026#34;成绩为：$1，评分为：A\u0026#34; else echo \u0026#34;成绩不合法\u0026#34; fi 报错： 原因：变量的值为空值，这个空值没有范围\n解决办法，加一个前提条件，输入非数字就直接退出 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 # 0 =\u0026lt; D \u0026lt;= 50 # 50 \u0026lt; C \u0026lt;= 70 # 70 \u0026lt; B \u0026lt;= 90 # 90 \u0026lt; A \u0026lt;= 100 #!/bin/bash if [[ ! $1 =~ ^[0-9]+$ ]] then echo \u0026#34;输入非数字，退出\u0026#34; exit elif [ $1 -ge 0 -a $1 -lt 50 ] then echo \u0026#34;成绩为：$1，评分为：D\u0026#34; elif [ $1 -gt 50 -a $1 -le 70 ] then echo \u0026#34;成绩为：$1，评分为：C\u0026#34; elif [ $1 -gt 70 -a $1 -le 90 ] then echo \u0026#34;成绩为：$1，评分为：B\u0026#34; elif [ $1 -gt 90 -a $1 -le 100 ] then echo \u0026#34;成绩为：$1，评分为：A\u0026#34; else echo \u0026#34;成绩不合法\u0026#34; fi 分支控制 语法格式 1 2 3 4 5 6 7 8 9 10 11 12 case 变量 in \u0026#34;变量值1\u0026#34;) 逻辑代码1 ;; \u0026#34;变量值2\u0026#34;) 逻辑代码2 ;; ... *) 默认逻辑 ;; esac 示例 示例：根据传参判断星期 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 #!/bin/bash echo -e \u0026#34;今天是星期几？\\n\u0026#34; case $1 in 1) echo \u0026#34;月曜日\u0026#34; ;; 2) echo \u0026#34;火曜日\u0026#34; ;; 3) echo \u0026#34;水曜日\u0026#34; ;; 4) echo \u0026#34;木曜日\u0026#34; ;; 5) echo \u0026#34;金曜日\u0026#34; ;; 6) echo \u0026#34;土曜日\u0026#34; ;; 7) echo \u0026#34;日曜日\u0026#34; ;; *) echo \u0026#34;输入错误\u0026#34; ;; esac 循环语句 for循环 方式一 1 2 3 4 5 for 暂时变量 in 变量1 变量2 变量3 ... do 代码逻辑 done # 注意：遍历时将变量1,2,3...分别赋值给暂时变量 方式二 1 2 3 4 5 for ((初始值; 循环控制条件; 变量变化)) do 代码逻辑 done # 注意：跟java语法遍历类似，只是用了两个()进行括起 示例 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 #!/bin/bash if [ -z \u0026#34;$1\u0026#34; ] then echo \u0026#34;参数不能为空\u0026#34; exit fi for item in $* do echo \u0026#34;item is $item\u0026#34; done echo \u0026#34;-------------------\u0026#34; for ((i=0; i\u0026lt;$#;i++)) do echo \u0026#34;num is $i\u0026#34; done while循环 语法格式 1 2 3 4 while 条件 do 代码逻辑 done 示例 1 2 3 4 5 #!/bin/bash if [[ ! $1 =~ ^[0-9]+$ ]] then echo \u0026#34;输入非数字，退出\u0026#34; ","date":"2025-10-08T15:39:07+08:00","permalink":"https://YLine-hub.github.io/p/shell%E6%B5%81%E7%A8%8B%E6%8E%A7%E5%88%B6/","title":"Shell流程控制"},{"content":"流程 1️⃣ 先写命令（快速验证核心逻辑） 1 2 # 直接硬编码执行（不要想任何变量） grep \u0026#34;ERROR\u0026#34; /var/log/app.log | awk \u0026#39;{print $3}\u0026#39; \u0026gt; error_codes.txt 2️⃣ 结构化升级（按顺序添加） 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 # 加入变量（路径/参数抽象化） log_dir=\u0026#34;/var/log\u0026#34; output_file=\u0026#34;error_codes_$(date +%F).txt\u0026#34; # 加入循环（处理多个文件） for log_file in \u0026#34;$log_dir\u0026#34;/*.log; do grep \u0026#34;ERROR\u0026#34; \u0026#34;$log_file\u0026#34; done \u0026gt; temp_errors.txt # 加入判断（条件处理） if [[ -s temp_errors.txt ]]; then awk \u0026#39;{print $3}\u0026#39; temp_errors.txt \u0026gt; \u0026#34;$output_file\u0026#34; else echo \u0026#34;未发现错误日志\u0026#34; \u0026gt; \u0026#34;$output_file\u0026#34; fi # 加入函数（复杂操作封装） extract_errors() { grep \u0026#34;ERROR\u0026#34; \u0026#34;$1\u0026#34; | cut -d\u0026#39;:\u0026#39; -f2 } extract_errors \u0026#34;$log_file\u0026#34; \u0026gt;\u0026gt; temp_errors.txt 3️⃣ 防御武装（输入合规+防崩溃） 1 2 3 4 5 6 7 8 9 10 11 12 # 输入合规检查（放在脚本开头） if [[ $# -eq 0 ]]; then echo \u0026#34;用法: $0 [日志目录]\u0026#34; exit 1 elif [[ ! -d \u0026#34;$1\u0026#34; ]]; then echo \u0026#34;错误：目录 $1 不存在\u0026#34; \u0026gt;\u0026amp;2 exit 2 fi # 防崩溃装甲（紧接合规检查后） set -euo pipefail trap \u0026#39;rm -f temp_errors.txt\u0026#39; EXIT 4️⃣ 安全收尾（说明+清理） 1 2 3 4 5 6 7 8 9 10 # 资源清理（通过trap已实现） # 脚本自文档（结尾注释块） : \u0026lt;\u0026lt;\u0026#39;EOF\u0026#39; === 脚本说明 === 功能: 提取应用错误码 输入: 日志目录路径 输出: error_codes_日期.txt 依赖: grep, awk, cut EOF 🛠 万能模板（直接填空使用） 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 #!/bin/bash # ===== 1.裸写命令区 ===== # [在此处写下你的原始命令] # grep \u0026#34;pattern\u0026#34; /path/file # ===== 2.结构化升级 ===== input_path=${1:-\u0026#34;/default/path\u0026#34;} # 变量 for item in \u0026#34;$input_path\u0026#34;/*; do # 循环 if [[ -f \u0026#34;$item\u0026#34; ]]; then # 判断 process_item \u0026#34;$item\u0026#34; # 函数 fi done process_item() { # [你的处理逻辑] } # ===== 3.防御武装 ===== [ $# -gt 1 ] \u0026amp;\u0026amp; { echo \u0026#34;参数过多\u0026#34;; exit 1; } # 输入合规 set -euo pipefail # 防崩溃 trap \u0026#39;cleanup\u0026#39; EXIT # 清理挂钩 cleanup() { rm -f tmp_*; } # 清理函数 # ===== 4.安全收尾 ===== :\u0026lt;\u0026lt;\u0026#34;NOTE\u0026#34; === 使用须知 === 1. 本脚本用于... 2. 输入要求... 3. 输出文件... NOTE ✅ 每个步骤的检查清单 步骤 必做事项 检查问题 1 核心命令能直接运行成功 去掉变量能否执行？ 2 所有路径参数都变量化 硬编码路径是否已消除？ 重复操作使用循环 同样操作是否出现3次以上？ 复杂逻辑封装为函数 主流程是否超过20行？ 3 检查关键输入是否存在 如果输入不存在会崩溃吗？ 设置set -euo pipefail 命令失败会继续执行吗？ 定义trap清理资源 脚本崩溃会留下垃圾文件吗？ 4 添加基本用法注释 三个月后还能看懂用法吗？ ","date":"2025-10-08T14:46:39+08:00","permalink":"https://YLine-hub.github.io/p/linux%E5%86%99%E8%84%9A%E6%9C%AC%E7%9A%84%E6%B5%81%E7%A8%8B/","title":"Linux写脚本的流程"},{"content":"Shell编程 介绍 Shell 是一个命令行解释器，它为用户提供了一个向Linux内核发送请求以便运行程序的界面系统级程序，用户可以用Shell来启动、挂起、停止甚至是编写一些程序。 Shell入门 使用vim新建文件text.sh 1 vim test.sh 输入脚本解析器和脚本执行内容 1 2 #!/bin/bash echo \u0026#34;Hello World!\u0026#34; 按Esc，并输入:wq进行保存\n运行脚本\n1 ./test.sh -bash: ./test.sh: 权限不够\n添加执行权限 1 chmod u+x test.sh 重新运行脚本 Shell变量 介绍 Shell变量：系统变量 和 用户自定义变量 系统变量：$HOME，$PWD，$SHELL，$USER set指令可查看所有系统变量 自定义变量：变量=值 撤销变量：unset 变量 声明静态变量：readonly 变量（不能unset） 变量定义规则 只包含字母、数字和下划线，不能以数字开头 避免使用 Shell 关键字，如if、then、else、fi、for、while等 使用大写字母表示常量 避免使用特殊符号和空格 变量的使用 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # 赋值 变量=值 # 使用一 $变量 # 使用二（推荐） ${变量} # 赋值一（命令） 变量=`命令` # 赋值二（命令） 变量=$(命令) 示例 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 #!/bin/bash echo \u0026#34;-------------------\u0026#34; A=100 echo \u0026#34;A=${A}\u0026#34; echo \u0026#34;A=$A\u0026#34; echo \u0026#34;-------------------\u0026#34; unset A echo \u0026#34;A=${A}\u0026#34; echo \u0026#34;A=$A\u0026#34; echo \u0026#34;-------------------\u0026#34; NOW=`date` echo \u0026#34;${NOW}\u0026#34; echo \u0026#34;$NOW\u0026#34; echo \u0026#34;-------------------\u0026#34; NOW_TIME=$(date) echo \u0026#34;${NOW_TIME}\u0026#34; echo \u0026#34;$NOW_TIME\u0026#34; 运行脚本 设置环境变量 介绍 linux上所有的环境变量都配置在/etc/profile中 export 变量=值来配置环境变量 配置完毕后，通过source /etc/profile，重新加载配置文件来使用 示例 添加环境变量 1 export LINUX_OWNER=yline 重新加载配置文件（如果没这一步将不会生效） 1 source /etc/profile 输出测试 1 echo \u0026#34;${LINUX_OWNER}\u0026#34; 位置参数变量 介绍 在我们执行shell脚本的时候，可以在后面拼接参数，进行传参，例：./test.sh hello world。\nshell脚本有对应的参数变量来接收这些参数。\n$n （n为数字）\n以空格来切分命令，将上面命令变成[./test.sh, hello, world]，通过$0, $1, $2来获取参数 如果个数达到10位数以上，需要用大括号括住数字${10} $*\n以一个单字符串显示所有向脚本传递的参数。 如\u0026quot;$*\u0026ldquo;用「\u0026quot;」括起来的情况、以\u0026rdquo;$1 $2 … $n\u0026quot;的形式输出所有参数。 获取全部参数，会将传入的参数hello world视为一个整体 $@\n与$*相同，但是使用时加引号，并在引号中返回每个参数。 如\u0026quot;$@\u0026ldquo;用「\u0026quot;」括起来的情况、以\u0026rdquo;$1\u0026quot; \u0026ldquo;$2\u0026rdquo; … \u0026ldquo;$n\u0026rdquo; 的形式输出所有参数。 获取全部参数，与$*不同，会将hello和world区分为个体 $#\n统计传入参数的个数 示例 1 2 3 4 5 6 7 8 9 10 11 12 13 #!/bin/bash echo \u0026#34;---------------\u0026#34; echo \u0026#34;$0,$1,$2\u0026#34; echo \u0026#34;---------------\u0026#34; echo \u0026#34;$*\u0026#34; echo \u0026#34;---------------\u0026#34; echo \u0026#34;$@\u0026#34; echo \u0026#34;---------------\u0026#34; echo \u0026#34;$#\u0026#34; 带参运行test3.sh 预定义变量 介绍 shell本身有定义好的变量提供用户使用。\n$$\n获取当前进行的PID $!\n获取后台运行的最后一个进程的进程号 $?\n最后一次执行的命令的返回状态（0=正常，非0=异常） 示例 1 2 3 4 5 6 7 8 9 10 11 12 13 #!/bin/bash echo \u0026#34;---------------\u0026#34; echo \u0026#34;current_PID = $$\u0026#34; ../test.sh \u0026amp; echo \u0026#34;---------------\u0026#34; echo \u0026#34;last_PID = $!\u0026#34; echo \u0026#34;---------------\u0026#34; echo \u0026#34;status = $?\u0026#34; 运行脚本 1 ./test4.sh 字符串 介绍 shell编程中最常用最有用的数据类型，可以用单引号，也可以用双引号，也可也不用引号。 示例 单引号 单引号里的任何字符都会原样输出，单引号字符串中的变量是无效的； 单引号字符串中不能出现单独一个的单引号（对单引号使用转义符后也不行），但可成对出现，作为字符串拼接使用。 1 2 3 4 #!/bin/bash str=\u0026#39;this is a string\u0026#39; echo \u0026#34;$str\u0026#34; 双引号 双引号里可以有变量 双引号里可以出现转义字符 echo -e 关键词 其中 -e 表示启用转义字符 1 2 3 4 5 #!/bin/bash your_name=\u0026#34;yline\u0026#34; str=\u0026#34;Hello,I know you are \\\u0026#34;$your_name\\\u0026#34;!\\n\u0026#34; echo -e $str 拼接字符串 1 2 3 4 5 6 7 8 9 10 11 12 #!/bin/bash your_name=\u0026#34;yline\u0026#34; # 使用双引号拼接 greeting=\u0026#34;hello, \u0026#34;$your_name\u0026#34; !\u0026#34; greeting_1=\u0026#34;hello, ${your_name} !\u0026#34; echo $greeting $greeting_1 # 使用单引号拼接 greeting_2=\u0026#39;hello, \u0026#39;$your_name\u0026#39; !\u0026#39; greeting_3=\u0026#39;hello, ${your_name} !\u0026#39; echo $greeting_2 $greeting_3 获取字符串长度 1 2 3 string=\u0026#34;abcd\u0026#34; echo ${#string} # 输出4 echo ${#string[0]} # 输出4 变量为字符串时，${#string}等价于${#string[0]} 提取子字符串 从字符串第2个字符开始截取4个字符 1 2 3 4 #!/bin/bash string=\u0026#34;Hello World!\u0026#34; echo ${string:1:4} 第一个字符串索引为0 查找字符串 查找字符o或r的位置（哪个先出现就计算哪个） 1 2 3 4 #!/bin/bash string=\u0026#34;Hello World!\u0026#34; echo `expr index \u0026#34;$string\u0026#34; or` # 输出为5 数组 介绍 Bash Shell只支持一维数组，初始化不需要定义数组大小 数组元素小标由0开始 语法格式 1 array_name=(value1 value2 ... valuen) 定义数组 格式 1 array_name=(value0 value1 value2 value3) 或者\n1 2 3 4 5 6 array_name=( value0 value1 value2 value3 ) 单独定义数组的各个分量\n1 2 3 array_name[0]=value0 array_name[1]=value1 array_name[n]=valuen 示例 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 #!/bin/bash array1=(A B \u0026#34;C\u0026#34; D) array2[0]=A array2[1]=B array2[2]=\u0026#34;C\u0026#34; array3[3]=D echo \u0026#34;----------------------------\u0026#34; echo \u0026#34;array1[0]=${array1[0]}\u0026#34; echo \u0026#34;array1[1]=${array1[1]}\u0026#34; echo \u0026#34;array1[2]=${array1[2]}\u0026#34; echo \u0026#34;array1[3]=${array1[3]}\u0026#34; echo \u0026#34;----------------------------\u0026#34; echo \u0026#34;array2[0]=${array2[0]}\u0026#34; echo \u0026#34;array2[1]=${array2[1]}\u0026#34; echo \u0026#34;array2[2]=${array2[2]}\u0026#34; echo \u0026#34;array2[3]=${array2[3]}\u0026#34; echo \u0026#34;----------------------------\u0026#34; 读取数组 格式 1 ${array_name[index]} 示例 1 2 3 4 5 6 7 #!/bin/bash my_array=(A B \u0026#34;C\u0026#34; D) echo \u0026#34;第一个元素为: ${my_array[0]}\u0026#34; echo \u0026#34;第二个元素为: ${my_array[1]}\u0026#34; echo \u0026#34;第三个元素为: ${my_array[2]}\u0026#34; echo \u0026#34;第四个元素为: ${my_array[3]}\u0026#34; 关联数组 Bash 支持关联数组，可以使用任意的字符串、或者整数作为下标来访问数组元素。\n格式 -A 选项就是用于声明一个关联数组 关联数组的键是唯一的。 1 declare -A array_name 示例 1 2 3 4 5 6 7 8 9 10 #!/bin/bash declare -A site site[\u0026#34;baidu\u0026#34;]=\u0026#34;www.baidu.com\u0026#34; site[\u0026#34;google\u0026#34;]=\u0026#34;www.google.com\u0026#34; site[\u0026#34;taobao\u0026#34;]=\u0026#34;www.taobao.com\u0026#34; echo ${site[\u0026#34;baidu\u0026#34;]} echo ${site[\u0026#34;google\u0026#34;]} echo ${site[\u0026#34;taobao\u0026#34;]} 获取数组中的所有元素 使用@或*可以获取数组中的所有元素\n1 2 3 4 5 6 7 8 9 #!/bin/bash my_array[0]=A my_array[1]=B my_array[2]=C my_array[3]=D echo \u0026#34;数组的元素为：${my_array[*]}\u0026#34; echo \u0026#34;数组的元素为：${my_array[@]}\u0026#34; 1 2 3 4 5 6 7 8 9 #!/bin/bash declare -A site site[\u0026#34;baidu\u0026#34;]=\u0026#34;www.baidu.com\u0026#34; site[\u0026#34;google\u0026#34;]=\u0026#34;www.google.com\u0026#34; site[\u0026#34;taobao\u0026#34;]=\u0026#34;www.taobao.com\u0026#34; echo \u0026#34;数组的元素为：${site[*]}\u0026#34; echo \u0026#34;数组的元素为：${site[@]}\u0026#34; 在数组前加一个感叹号！可以获取数组的所有键 1 2 3 4 5 6 7 8 9 #!/bin/bash declare -A site site[\u0026#34;baidu\u0026#34;]=\u0026#34;www.baidu.com\u0026#34; site[\u0026#34;google\u0026#34;]=\u0026#34;www.google.com\u0026#34; site[\u0026#34;taobao\u0026#34;]=\u0026#34;www.taobao.com\u0026#34; echo \u0026#34;数组的键为：${!site[*]}\u0026#34; echo \u0026#34;数组的键为：${!site[@]}\u0026#34; 获取数组的长度 获取数组的长度方法与获取字符串长度的方法相同 1 2 3 4 5 6 7 8 9 #!/bin/bash my_array[0]=A my_array[1]=B my_array[2]=\u0026#34;C\u0026#34; my_array[3]=D echo \u0026#34;数组元素个数为：${#my_array[*]}\u0026#34; echo \u0026#34;数组元素个数为：${#my_array[@]}\u0026#34; 运算符 算数运算符 使用方式 1 2 3 4 5 (1)$((运算表达式)) (2)$[运算表达式] (3)expr 运算表达式 示例 1 2 3 4 5 6 7 8 9 10 11 #!/bin/bash echo \u0026#34;----------------------\u0026#34; echo \u0026#34;(2+3)*4 = $(((2+3)*4))\u0026#34; echo \u0026#34;----------------------\u0026#34; echo \u0026#34;(2+3)*4 = $[(2+3)*4]\u0026#34; echo \u0026#34;----------------------\u0026#34; TEMP=`expr 2 + 3` echo \u0026#34;(2+3)*4 = `expr $TEMP \\* 4`\u0026#34; ","date":"2025-10-05T17:05:56+08:00","permalink":"https://YLine-hub.github.io/p/shell%E7%BC%96%E7%A8%8B/","title":"Shell编程"},{"content":"端口管理 lsof 介绍 lsof（list open files）\n一个列出当前系统打开文件的工具。\n基本语法 1 lsof -i:端口号 示例 查看服务器80端口占用情况 1 2 3 4 5 6 7 8 9 COMMAND：进程名称 PID：进程标识符 USER：进程所有者 FD：文件描述符，应用程序通过描述符识别该文件。如cwd、txt等 TYPE：文件类型，如DIR、REG等 DEVICE：指定磁盘的名称 SIZE：文件大小 NODE：索引节点（文件在磁盘上的标识） NAME：代开文件的确切名称 查看所有端口使用情况 更多lsof命令：\n1 2 3 4 5 6 7 8 9 lsof -i:8080：查看8080端口占用 lsof abc.txt：显示开启文件abc.txt的进程 lsof -c abc：显示abc进程现在打开的文件 lsof -c -p 1234：列出进程号为1234的进程所打开的文件 lsof -g gid：显示归属gid的进程情况 lsof +d /usr/local/：显示目录下被进程开启的文件 lsof +D /usr/local/：同上，但是会搜索目录下的目录，时间较长 lsof -d 4：显示使用fd为4的进程 lsof -i -U：显示所有打开的端口和UNIX domain文件 netstat 介绍 用于显示 tcp，udp 的端口和进程等相关情况。 基本语法 1 2 # 查看端口占用语法格式 netstat -tunlp | grep 端口号 options: -t (tcp) 仅显示tcp相关选项 -u (udp)仅显示udp相关选项 -n 拒绝显示别名，能显示数字的全部转化为数字 -l 仅列出在Listen(监听)的服务状态 -p 显示建立相关链接的程序名 示例 查看80端口情况 更多命令：\n1 2 3 netstat -ntlp //查看当前所有tcp端口 netstat -ntulp | grep 80 //查看所有80端口使用情况 netstat -ntulp | grep 3306 //查看所有3306端口使用情况 ","date":"2025-10-05T03:06:03+08:00","permalink":"https://YLine-hub.github.io/p/linux%E7%AB%AF%E5%8F%A3%E7%AE%A1%E7%90%86/","title":"Linux端口管理"},{"content":"服务管理 介绍 服务的本质就是进程，但是是运行在后台的，通常会监听某个端口，等待其他进程的请求，因此我们又称为守护进程。\n查看服务 centos7以下：文件夹下 /etc/init.d/ 下的文件名就是已启动的服务名。 centos7以上：指令 systemctl list-units --type=service查看已启动服务 1 systemctl list-units --type=service 管理指令 CentOS7以前\n1 2 3 4 5 service (服务名) start : 启动服务 service (服务名) stop : 关闭服务 service (服务名) restart : 重启服务 service (服务名) reload : 重载服务 service (服务名) status : 服务状态 CentOS7以后，service替换成systemctl，但仍然能够使用service\n1 2 3 4 5 systemctl start (服务名): 启动服务 systemctl stop (服务名): 关闭服务 systemctl restart (服务名): 重启服务 systemctl reload (服务名): 重载服务 systemctl status (服务名): 服务状态 查看防火墙状态 1 systemctl status firewalld 关闭防火墙，并再次查看防火墙状态 1 2 systemctl stop firewalld systemctl status firewalld 重启防火墙 1 2 systemctl start firewalld systemctl status firewalld 自启动设置 CentOS7以前\n1 2 3 chkconfig : 查看服务在各运行级别的自启动情况 chkconfig (服务名) : 查看指定服务在各运行级别的启动情况 chkconfig --level (级别) (服务名) on/off : 指定某个服务在指定运行级别是否自启动 CentOS7以后\n1 2 systemctl list-unit-files : 查看服务自启动情况 systemctl enable/disable (服务名) : 服务自启动/关闭自启动 查看sshd自启动情况 1 systemctl list-unit-files | grep sshd 关闭sshd自启动 1 2 systemctl disable sshd systemctl list-unit-files | grep sshd 重启sshd自启动 1 2 systemctl enable sshd systemctl list-unit-files | grep sshd 端口测试 介绍 window自带的一个指令 telnet 来测试某服务的端口是否处于监听状态（启动状态） 格式：telnet ip地址 端口号 开启方法 测试 测试sshd端口22 1 telnet 192.168.172.100 22 没有报错并显示以下界面，即端口22处于监听状态 测试192.168.172.100服务器80端口 1 telnet 192.168.172.100 80 Connecting To 192.168.172.100\u0026hellip;Could not open connection to the host, on port 80: Connect failed\n表示该80端口未处于监听状态\n打开192.168.172.100服务器80端口 1 2 3 4 5 6 # 查看80端口开放状态 firewall-cmd --query-port=80/tcp # 永久打开80端口 firewall-cmd --add-port=80/tcp --permanent # 重启防火墙 firewall-cmd --reload 发现还是无法连接\n测试192.168.172.132服务器80端口 该服务器部署了gitlab服务，80端口处于监听状态，运行了http服务\n查看132服务器80端口使用情况 1 lsof -i:80 ","date":"2025-10-05T02:02:34+08:00","permalink":"https://YLine-hub.github.io/p/linux%E6%9C%8D%E5%8A%A1%E7%AE%A1%E7%90%86/","title":"Linux服务管理"},{"content":"进程管理 介绍 Linux中，每个执行的程序（代码）都称为一个进程。每一个进程都分配一个ID号。\n每一个进程，都会有对应一个父进程，父进程可以有多个子进程。\n每个进程都有两种存在方式： 前台和后台\n前台进程：用户可以在屏幕进行操作。 后台进程：进程在运行，但无法在屏幕上看到。 进程显示 显示系统执行的进程 1 2 3 4 5 ps ps -a : 显示所有进程信息 ps -u : 以用户格式显示进程信息 ps -x : 显示后台进程运行的参数 ps -f : 显示父进程ID 查找指定进程：\n1 ps -ef | grep 关键字 PID：进程识别号 TTY：终端机号 TIME：此进程所消耗CPU时间 CMD：正在执行的命令/进程名 USER：用户名 %CPU：CPU %MEN：内存占用率 VSZ：使用虚拟内存大小 RSS：使用物理内存大小 STAT：进程状态 START：进程开始时间 COMMAND：进程执行的命令行 能看到指令运行的参数 PPID：父进程 显示进程树 1 2 3 pstree pstree -p 显示进程的PID pstree -u 显示进程所属用户 -bash: pstree: 未找到命令\n查询pstree所在包 1 yum search pstree 安装psmisc 1 yum -y install psmisc 测试 树型结构显示进程 进程终止 指令 1 2 kill (进程号：PID) kill -9 (进程号：PID) : 强制终止进程 1 2 killall (进程名，支持通配符*) killall -9 (进程名) ： 强制终止匹配的所有进程 同时登陆yline和root用户 查询进程yline 1 ps -ef | grep yline 杀死进程yline 1 kill 8913 进程监控 指令 1 2 3 4 top : 动态显示进程信息 top -d (秒数) : 设置指定秒数更新进程信息 top -i : 不显示任何闲置或僵死的进程 top -p (进程PID) : 监控指定进程信息 1 top 只显示当前正在运行的进程 1 top -i 只显示PID为682的进程 1 top -p 682 交互指令 进入进程监控界面之后可以输入一下指令，达到想要的效果。 1 2 3 4 5 6 P : 以CPU使用率进行排序（默认） M : 以内存的使用率进行排序 N : 以PID进行排序 u : 监控指定用户的进程 k : 杀死指定进程 q : 退出监控 ","date":"2025-10-04T22:13:48+08:00","permalink":"https://YLine-hub.github.io/p/linux%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/","title":"Linux进程管理"},{"content":"Linux问题记录 问题一：开机提示emergency mode（紧急模式） 问题现象：\n进入紧急模式原因：\n/etc/fstab文件配置存在错误导致挂载文件系统时失败。 文件系统存在错误。 系统更新后的脚本错误。 (1)：在下列位置输入root密码使用root账号登陆 (2)：打开/etc/fstab 1 vi /etc/fstab (3)：注释掉原先添加的部分 (4)：reboot重启 1 reboot (5)：找到原因，配置fstab文件错误 该处应该是defaults (6)：重新配置并保存重启 1 /dev/sdb1 /home/newdisk ext4 defaults 0 0 (7)：查看是否配置成功 1 lsblk -f 可以看到自动配置硬盘成功 ","date":"2025-10-04T16:28:52+08:00","permalink":"https://YLine-hub.github.io/p/linux%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/","title":"Linux问题记录"},{"content":"Linux网络配置 虚拟网络 介绍 （1）windows与虚拟网络联通\nwindow下有一个网卡为 “VMware Network Adapter VMnet8” ，是用于与虚拟机进行通讯。 window可以用ipconfig查看ip地址，linux可以用ifconfig查看ip地址。 可以看到这两个网络是同一网段。\n（2）windows与internet连接\n通过windows下的真实网卡，经历路由器网关，跟互联网进行交互。 查看默认网关 1 ip route show 网络配置 网络配置文件 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 # 查看网卡配置文件 $ cat /etc/sysconfig/network-scripts/ifcfg-ens33 TYPE=\u0026#34;Ethernet\u0026#34; # 网卡类型，Ethernet表示以太网 PROXY_METHOD=\u0026#34;none\u0026#34; # 代理方式：关闭状态 BROWSER_ONLY=\u0026#34;no\u0026#34; # 只是浏览器（yes|no） BOOTPROTO=\u0026#34;dhcp\u0026#34; # 设置网卡获得ip地址的方式（static|dhcp|none） DEFROUTE=\u0026#34;yes\u0026#34; # 设置为默认路由（yes|no） IPV4_FAILURE_FATAL=\u0026#34;no\u0026#34; # 是否开启IPV4致命错误检测（yes|no） IPV6INIT=\u0026#34;yes\u0026#34; # IPV6是否自动初始化 IPV6_AUTOCONF=\u0026#34;yes\u0026#34; # IPV6是否自动配置 IPV6_DEFROUTE=\u0026#34;yes\u0026#34; # IPV6是否可以为默认路由 IPV6_FAILURE_FATAL=\u0026#34;no\u0026#34; # 是否开启IPV6致命错误检测 IPV6_ADDR_GEN_MODE=\u0026#34;stable-privacy\u0026#34; # IPV6地址生成模型 NAME=\u0026#34;ens33\u0026#34; # 网卡物理设备名称 UUID=\u0026#34;8b1f9fd5-9d4b-46f7-ba3f-0ff3f862e0c2\u0026#34; # UUID识别码 DEVICE=\u0026#34;ens33\u0026#34; # 网卡设备名称 ONBOOT=\u0026#34;yes\u0026#34; # 开机自启 配置静态ip 打开文件ifcfg-ens33 1 vi /etc/sysconfig/network-scripts/ifcfg-ens33 配置参数 1 2 3 4 5 BOOTPROTO=\u0026#34;static\u0026#34; IPADDR=192.168.172.100 # 网关和DNS1相同即可 GATEWAY=192.168.172.2 DNS1=192.168.172.2 重启网络 1 systemctl restart network ","date":"2025-10-03T21:16:25+08:00","permalink":"https://YLine-hub.github.io/p/linux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/","title":"Linux网络配置"},{"content":"Linux磁盘管理 磁盘分区 分区原因 数据的安全性隔离：独立分开每个分区，使各区数据不会相互影响。\n系统的效率考虑：加快数据寻址的效率。\n分区方式 mbr分区 最多支持四个主分区 系统只能安装主分区 拓展分区要占一个主分区 MBR最大只支持2TB，但拥有最好的兼容性 适用场景：旧设备通常使用BIOS启动，仅支持MBR。 磁盘容量小于2TB。 需要兼容旧操作系统（如32位Windows）。\ngpt分区 支持无线多个主分区（但操作系统可能限制） 最大支持18EB的大容量（1EB = 1024PB，1PB = 1024TB） 适用场景：现代设备通常支持UEFI，推荐使用GPT。 磁盘容量大于2TB。 更高的可靠性和扩展性需求。\nLinux分区 介绍 Linux采用一种叫“载入”的处理方法，它的整个文件系统中包含了一整套的文件和目录，且将一个分区和一个目录关联起来。\n分区命名 （1）Linux的硬盘分为IDE（旧），SCSI（新）硬盘两种\n（2）IDE分区命名： 盘号标识符为：hdx~\nhd为设备类型，即指IDE硬盘 x为盘号【a为基本盘，b为基本从属盘，c为辅助主盘，d为辅助从属盘】 ~为区号，即此分区为当前盘号的第几个分区【1~4主分区，5后为逻辑分区】 例如： hda1 （3）SCSI分区命名： 基本和IDE一致，只是设备类型不同，为sdx~\n例如：sda1 分区查看 lsblk(list block) 1 lsblk -f NAME: 块设备名称，例如 sda, sda1。 FSTYPE: 文件系统类型，例如 ext4, ntfs, swap 等。 FSVER: 文件系统版本（如果适用）。 LABEL: 文件系统标签（如果有设置）。 UUID: 文件系统的唯一标识符。 MOUNTPOINT: 当前挂载点（如果设备已挂载）。 磁盘挂载 挂载案例 给虚拟机创建一个新的硬盘，并挂载到/home/newdisk下 挂载步骤 给虚拟机添加新的硬盘 ハードディスク：harddisk 硬盘\n点击编辑虚拟机的设定 点击添加 选择硬盘然后点击下一步 默认SCSI硬盘即可 填写自己需要的硬盘数量并点击下一步 点击完成后，虚拟机设定内就会新增一个硬盘 点击ok并启动虚拟机 输入lsblk -f查看是否又新的硬盘 这块sdb就是新添加的硬盘\n分区 命令行输入：fdisk 设备位置，进入分区引导程序 输入m，查看指令目录\nn ： 添加一个新的分区\nw ： 写入到磁盘并退出\n输入指令n，添加新分区\n分区类型 ： p=主分区，e=扩展分区\n分区号码 ： 默认1\n起始扇区 ： 默认2048\n最后扇区 ： 默认硬盘最后的字节\n输入指令w，写入到磁盘并退出 查看磁盘分区，其中sdb1只有分区名，没有其他信息，需要进行格式化 1 lsblk -f 格式化 将分区格式化为ext4文件系统 1 mkfs -t ext4 /dev/sdb1 查看分区，sdb1已经属于ext4文件系统，且拥有唯一标识 挂载 创建新的目录，并将新的硬盘挂载在目录下 设置自动挂载 由于重启后需要重新挂载，设置自动挂载后，重启就不需要再重新挂载 1 2 # 打开/etc/fstab vi /etc/fstab 仿照上面的格式，写入挂载信息，并保存 1 2 # 挂载设备 挂载目录 文件系统 defaults 0 0 /dev/sdb1 /home/newdisk ext4 defaults 0 0 磁盘命令 df 介绍（检查硬盘占用情况） 检查文件系统的磁盘空间占用情况。可以利用该命令来获取硬盘被占用了多少空间，目前还剩下多少空间等信息。 基本语法 1 df [options] 目录或文件名 options：\n-h：以人类可读的方式显示输出结果（例如，使用 KB、MB、GB 等单位）。\n-T：显示文件系统的类型。\n-t \u0026lt;文件系统类型\u0026gt;：只显示指定类型的文件系统。\n-i：显示 inode 使用情况。\n-H：该参数是 -h 的变体，但是使用 1000 字节作为基本单位而不是 1024 字节。这意味着它会以 SI（国际单位制）单位（例如 MB、GB）而不是二进制单位（例如 MiB、GiB）来显示磁盘使用情况。\n-k：这个选项会以 KB 作为单位显示磁盘空间使用情况。\n-a：该参数将显示所有的文件系统，包括虚拟文件系统，例如 proc、sysfs 等。如果没有使用该选项，默认情况下，df 命令不会显示虚拟文件系统。\n示例 将系统内所有文件系统列出来 1 df 将容量结果以易读的容量格式显示出来 1 df -h 将系统内所有特殊文件格式及名称都列出来 1 df -aT 将/etc地下的可用的磁盘容量以易读的容量格式显示 1 df -h /etc du 介绍（检查指定目录磁盘占用情况） 对文件和目录磁盘使用的空间的查看。 基本语法 1 du [options] 文件或目录 options:\n-a ：列出所有的文件与目录容量，因为默认仅统计目录底下的文件量而已。 -h ：以人们较易读的容量格式 (G/M) 显示； -s ：仅显示指定目录或文件的总大小，而不显示其子目录的大小。 -S ：包括子目录下的总计，与 -s 有点差别。 -k ：以 KBytes 列出容量显示； -m ：以 MBytes 列出容量显示； -c ：并统计总用量； 示例 列出当前目录下所有文件夹容量（包括子目录和隐藏文件夹） 1 du 将文件的容量也列出来 检查根目录底下每个目录所占容量 fdisk 介绍 磁盘分区表操作工具 基本语法 1 fdisk [options] 装置名称 options: -l : 输出后面接的装置所有的分区内容。若仅有 fdisk -l 时， 则系统将会把整个系统内能够搜寻到的装置的分区均列出来。 示例 列出所有分区信息 1 fdisk -l 实用指令 查询指定目录下文件个数 1 ls -l 目录 | grep \u0026#34;^-\u0026#34; | wc -l 列出指定目录中的所有文件 1 ls -l /usr/lib/python2.7/site-packages/ 列出指定目录中“-”开头的文件 1 ls -l /usr/lib/python2.7/site-packages/ | grep \u0026#34;^-\u0026#34; 统计指定目录下“-”开头文件的个数 1 2 # wc(word count)统计个数 ls -l /usr/lib/python2.7/site-packages/ | grep \u0026#34;^-\u0026#34; | wc -l 查看指定目录文件个数（包含子目录） 跟上面基本一样，只是添加-R来进行递归 1 ls -lR 目录 | grep \u0026#34;^-\u0026#34; | wc -l 树形结构显示文件 1 tree 目录 安装tree命令 1 yum -y install tree 树形结构显示目录 ","date":"2025-10-01T13:50:43+08:00","permalink":"https://YLine-hub.github.io/p/linux%E7%A3%81%E7%9B%98%E7%AE%A1%E7%90%86/","title":"Linux磁盘管理"},{"content":"Linux用户账号管理 用户登陆与注销 登陆时尽量少用root账号登陆，因为它是系统管理员，权限最大，为避免操作失误。可以利用普通用户登陆，登陆后再用“su 用户名”命令来切换程系统管理员身份。\n切换用户：su 用户名\n注销用户：logout\nuseradd添加用户 基本语法 1 useradd options username options:\n-c comment 指定一段注释性描述。 -d 目录 指定用户主目录，如果此目录不存在，则同时使用-m选项，可以创建主目录。 -g 用户组 指定用户所属的用户组。 -G 用户组，用户组 指定用户所属的附加组。 -s Shell文件 指定用户的登录Shell。 -u 用户号 指定用户的用户号，如果同时有-o选项，则可以重复使用其他用户的标识号 -m 用户目录如果不存在则自动创建。 username: 自定新账号的登录名\n示例 创建用户sam，其中-d和-m用来产生用户目录 1 useradd -d /home/sam -m sam 创建用户gem，该用户登陆Shell是/bin/sh，属于group用户组，同时又属于adm和root用户组，其中group用户组是其主组。 1 useradd -s /bin/sh -g group -G adm,root gem 以下是三个用户\n增加用户账号就是在/etc/passwd文件中为新用户增加一条记录，同时更新其他系统文件如/etc/shadow, /etc/group等。 userdel删除用户 基本语法 1 userdel options username options\n-r 用于把用户的主目录一起删除。 示例 删除用户sam在系统文件中（主要是/etc/passwd, /etc/shadow, /etc/group等）的记录，同时删除用户的主目录。 1 userdel -r sam usermod修改用户 基本语法 1 usermod options username options 包括-c, -d, -m, -g, -G, -s, -u以及-o等，这些选项的意义与useradd命令中的选项一样，可以为用户指定新的资源值。\n示例 将用户sam的登录Shell修改为ksh，主目录改为/home/z，用户组改为developer。 1 usermod -s /bin/ksh -d /home/z -g developer sam passwd用户口令管理 用户账号刚创建时没有口令，但是被系统锁定，无法使用，必须为其指定口令后才可以使用，即使是指定空口令。 基本语法 1 passwd options username options:\n-l 锁定口令，即禁用账号。 -u 口令解锁。 -d 使账号无口令。 -f 强迫用户下次登录时修改口令。 示例 如果是默认用户，修改当前用户的口令 1 2 3 4 $ passwd Old password:****** New password:******* Re-enter new password:******* 如果是超级用户，可以用下列形式修改指定任何用户的口令 1 2 3 $ passwd sam New password:******* Re-enter new password:******* 为用户指定空口令 1 $ passwd -d sam 删除sam用户口令，锁定sam，下一次sam就不再被允许登陆。 1 $ passwd -l sam 其他 用户与组的相关文件/etc/passwd 1 2 3 4 5 6 7 8 # /etc/passwd文件 # 用户 (user）的配置文件，记录用户的各种信息 cat /etc/passwd # 每行的含义: 用户名:口令:用户标识号:组标识号:注释性描述:主目录:登录Shell yline:x:1000:1000:yline:/home/yline:/bin/bash /etc/shadow文件 1 2 3 4 5 6 # 口令的配置文件 cat /etc/shadow # 每行的含义: 登录名:加密口令:最后一次修改时间:最小时间间隔:最大时间间隔:警告时间:不活动时间:失效时间:标志 root:$6$qWXOPskK$JtjIOb0PE4k.86YmO4GbNolp.4ZmD8iMZDpNogyCzMNbbLsMdV17EcrpYVB/OW7CysD2KP.2rfV/nHucGkcLY1:20358:0:99999:7::: /etc/group文件 1 2 3 4 5 # 组(group)的配置文件，记录Linux包含的组的信息 cat /etc/group # 每行含义: 组名:口令:组标识号:组内用户列表 Linux用户组管理 groupadd增加用户组 1 groupadd options group 常用选项\n-g GID 指定新用户组的组标识号（GID）。 -o 一般与-g选项同时使用，表示新用户组的GID可以与系统已有用户组的GID相同。 示例 增加用户组group1，新组标识号是在当前最大组标识号上加1 1 groupadd group1 增加用户组group2，同时指定新组标识号为101 1 groupadd -g 101 group2 groupdel删除用户组 基本语法 1 groupdel group 示例 删除用户组group1 1 groupdel group1 groupmod修改用户组 基本语法 1 groupmod options group 常用选项：\n-g GID 为用户组指定新的组标识号。 -o 与-g选项同时使用，用户组的新GID可以与系统已有用户组的GID相同。 -n新用户组 将用户组的名字改为新名字 示例 将用户组group2的组标识号修改为102 1 groupmod -g 102 group2 将group2的标识号改为10000，组名修改为group3 1 groupmod -g 10000 -n group3 group2 newgrp切换用户组 如果用户同时属于多个组，那么用户可以在用户组之间切换\n切换到root组\n1 newgrp root 批量添加用户 编辑文本用户文件 每一列按照/etc/passwd密码文件的格式书写，要注意每个用户的用户名、UID、宿主目录都不可以相同，其中密码栏可以留做空白或输入x号。\nuser.txt范例\n1 2 3 4 5 6 user001:x:1003:1000:users:/home/user001:/bin/bash user002:x:1004:1000:users:/home/user002:/bin/bash user003:x:1005:1000:users:/home/user003:/bin/bash user004:x:1006:1000:users:/home/user004:/bin/bash user005:x:1007:1000:users:/home/user005:/bin/bash user006:x:1008:1000:users:/home/user006:/bin/bash 以root身份导入用户 以root身份执行/user/sbin/newusers，从刚创建的user.txt中导入数据，创建用户 1 newusers \u0026lt; user.txt 然后执行vipw 或 vi /etc/passwd检查/etc/passwd文件中是否已经出现这些用户的数据，并且用户的宿主目录是否已经创建。 编辑每个用户的密码对照文件 1 2 # 格式 用户名：密码 passwd.txt范例 1 2 3 4 5 6 user001:123456 user002:123456 user003:123456 user004:123456 user005:123456 user006:123456 以root身份执行/usr/sbin/chpasswd 创建用户密码，chpasswd 会将经过/usr/bin/passwd命令编码过的密码写入/etc/passwd的密码栏 1 cat passwd.txt | chpasswd 注意： 一开始使用chpasswd \u0026lt; passwd.txt命令更新密码，一直显示密码错误。目前不知道原因。\n权限管理 文件的基本属性 文件类型 说明 - 普通文件 d 目录 l 软连接 c 字符设备【键盘、鼠标等】 b 块文件，硬盘 权限类型 说明 r read，读，查看文件 w write，写，修改文件，也可以删除文件 x execute，执行，执行文件 - 没有权限 权限的rwx可以用数字来表示\nr = 4 w = 2 x = 1 文件的权限修改 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 # 修改文件 / 目录权限 # 方式一 chmod u=[rwx], g=[rwx], o=[rwx] 文件/目录名 #例：chmod u=rwx, g=rx, o=r hello.txt # u --- user 所有者 # g --- group 所在组 # o --- other 其他组 # a --- all 全部 # 方式二 chmod [ugoa][+-][rwx] 文件/目录名 #例：chmod u+r hello.txt # + --- 添加权限 # - --- 移除权限 # 方式三 chmod [数字权限][数字权限][数字权限] 文件/目录名 #例：chmod 764 hello.txt # r=4 w=2 x=1 # 7=rwx 6=rw 5=rx 3=wx # 第一个为所有者，第二为所在组，第三为其他组 用方法一分别给所有者所有权限，所在组读执行权限，其他组读权限 1 chmod u=rwx,g=rx,o=r hello.txt 用方法二给所在组添加写权限 1 chmod g+w hello.txt 用方法三添加所有权限 1 chmod 777 hello.txt ","date":"2025-09-30T10:32:33+08:00","permalink":"https://YLine-hub.github.io/p/linux%E7%94%A8%E6%88%B7%E7%BB%84%E7%AE%A1%E7%90%86%E4%B8%8E%E6%9D%83%E9%99%90%E7%AE%A1%E7%90%86/","title":"Linux用户组管理与权限管理"},{"content":"用法：按f12打开浏览器开发者工具，切换到控制台，然后复制粘贴以下脚本，回车。\n1 2 3 4 5 6 7 8 var article_content=document.getElementById(\u0026#34;article_content\u0026#34;); article_content.removeAttribute(\u0026#34;style\u0026#34;); var follow_text=document.getElementsByClassName(\u0026#39;follow-text\u0026#39;)[0]; follow_text.parentElement.parentElement.removeChild(follow_text.parentElement); var hide_article_box=document.getElementsByClassName(\u0026#39; hide-article-box\u0026#39;)[0]; hide_article_box.parentElement.removeChild(hide_article_box); ","date":"2025-09-30T10:14:04+08:00","permalink":"https://YLine-hub.github.io/p/csdn%E8%B7%B3%E8%BF%87%E5%85%B3%E6%B3%A8%E5%8D%9A%E4%B8%BB%E5%8D%B3%E5%8F%AF%E9%98%85%E8%AF%BB%E5%85%A8%E6%96%87/","title":"csdn跳过[关注博主即可阅读全文]"},{"content":"Linux文本编辑器 介绍 所有的Linux系统都会默认配置vi文本编辑器 vim具有程序编辑能力，可以看做vi的增强版本，可以主动的以字体颜色辨别语法的正确性，方便程序设计，而且还有代码补完，编译以及错误跳转等功能 三种模式 命令模式 启动 vi/vim，便进入了命令模式。\n此状态下敲击键盘动作会被 Vim 识别为命令，而非输入字符。\n常见命令 /+关键字 \u0026ndash; 查找关键字 切换输入操作 i \u0026ndash; 切换到输入模式，在光标当前位置开始输入文本。 a \u0026ndash; 进入插入模式，在光标下一个位置开始输入文本。 o \u0026ndash; 在当前行的下方插入一个新行，并进入插入模式。 O \u0026ndash; 在当前行的上方插入一个新行，并进入插入模式。 光标移动操作 G \u0026ndash; 光标移动到文件最后一行的位置。 gg \u0026ndash; 光标移动到文件第一行的位置。 shift + 4 \u0026ndash; 光标移动到当前行行尾。 shift + 6 \u0026ndash; 光标移动到当前行行首。 复制粘贴操作 dd \u0026ndash; 剪切当前行。 yy \u0026ndash; 复制当前行。 p（小写） \u0026ndash; 粘贴剪贴板内容到光标下方。 P（大写）\u0026ndash; 粘贴剪贴板内容到光标上方。 删除操作 x \u0026ndash; 删除当前光标所在处的字符。 撤销回退操作 u \u0026ndash; 撤销上一次操作。 Ctrl + r \u0026ndash; 重做上一次撤销的操作。 切换底线命令模式 : \u0026ndash; 切换到底线命令模式，以在最底一行输入命令。 输入模式 在命令模式下按下 i 就进入了输入模式，使用 Esc 键可以返回到普通模式。 底线命令模式 在命令模式下按下 :（英文冒号）就进入了底线命令模式。\n按 ESC 键可随时退出底线命令模式。\n基本命令 :w ： 保存文件。 :q ： 退出 Vim 编辑器。 :wq ： 保存文件并退出 Vim 编辑器。 :q! ： 强制退出Vim编辑器，不保存修改。 :set nu或set number ： 显示行号 删除操作 :1,$d : 清空文件内容 ","date":"2025-09-29T20:57:21+08:00","permalink":"https://YLine-hub.github.io/p/linux%E7%9A%84vi%E4%B8%8Evim%E4%BD%BF%E7%94%A8/","title":"Linux的vi与vim使用"},{"content":"星期 月曜日 火曜日 水曜日 木曜日 金曜日 土曜日 日曜日 windows 常用工具 電卓（でんたく）：计算器 コントロール　パネル：control panel 控制面板 プログラム：program 节目；程序 システム：system 系统 セキュリティ：security 安全；保安；防护 ハードウェア：hardware 硬件 サウンド：sound 声音；音响 生词 機能（きのう）：机能；功能；作用 または：或者 有効（ゆうこう）：有效；生效 無効（むこう）：无效；失效 ユーザー：user 用户 アカウント：account 账号 カスタマイズ：customize 定制；个性化设置 地域（ちいき）：地区；区域 アクセシビリティ:accessibility 可访问性；可用性 制御（せいぎょ）：控制；调节；管理 許可（きょか）：许可 ","date":"2025-09-28T17:19:03+08:00","permalink":"https://YLine-hub.github.io/p/%E6%97%A5%E8%AF%AD%E7%94%9F%E8%AF%8D/","title":"日语生词"},{"content":"","date":"2025-09-28T16:28:56+08:00","permalink":"https://YLine-hub.github.io/p/java%E5%BC%80%E5%8F%91%E5%B7%A5%E7%A8%8B%E5%B8%88%E5%AD%A6%E4%B9%A0%E8%B7%AF%E7%BA%BF/","title":"Java开发工程师学习路线"},{"content":"运维工程师学习路线 初级运维工程师 中级运维工程师 高级运维工程师 学习路线 1 2 Linux基础 监控、日志、安全 ","date":"2025-09-28T16:28:33+08:00","permalink":"https://YLine-hub.github.io/p/%E8%BF%90%E7%BB%B4%E5%B7%A5%E7%A8%8B%E5%B8%88%E5%AD%A6%E4%B9%A0%E8%B7%AF%E7%BA%BF/","title":"运维工程师学习路线"},{"content":"Linux常用指令 帮助指令 介绍 用来了解不熟悉的指令 man 基本语法 1 2 # 获取帮助信息 man [选项] [节号] 命令/主题 常见选项 -f：显示与指定关键字相关的手册页面。 -k：搜索手册页中与关键字匹配的条目。 -a：显示所有匹配的手册页面。 -w：仅显示手册页的位置，而不显示其内容。 常见节号 1：用户命令 2：系统调用 3：C库函数 4：设备和特殊文件 5：文件格式和约定 6：游戏和演示 7：杂项 8：系统管理命令 示例 1 2 # 查看ls命令的手册页面 man ls 1 2 # 查看C语言标准库函数printf的手册页面 man 3 printf 1 2 # 搜索包含特定关键字ls的手册页面条目 man -k ls 常用参数 1 2 3 4 5 6 箭头上：向上移动 箭头下：向下移动 大写N：向上查找 小写n：向下查找 /或? : 查找内容 q : 退出 help 基本语法 1 2 3 4 5 6 # 方法一 help [选项] 命令 # 方法二 命令 --help 基本选项 -d 显示内建命令的简要描述。 -m 按照 man 手册的格式输出帮助信息。 -s 仅输出内建命令的命令格式。 示例 1 2 # 查看cd命令的帮助信息 help cd 1 2 # 使用简短格式显示帮助 help -s cd 1 2 # 按man手册格式显示帮助 help -m cd 1 2 # 查看ls命令手册 ls --help 目录指令 pwd 介绍（显示目录） 显示当前目录的完整路径 基本语法 1 pwd [选项] 基本选项 -L（\u0026ndash;logical）：显示逻辑路径（默认）。\n-P（\u0026ndash;physical）：显示物理路径。\n\u0026ndash;help\t:显示帮助信息\n\u0026ndash;version\t:显示版本信息\n示例 1 2 3 4 5 6 7 8 9 $ mkdir -p /var/www/html $ ln -s /var/www/html/ myweb $ cd myweb/ $ pwd /home/yline/myweb # 逻辑路径（当前目录） $ pwd -L /home/yline/myweb # 逻辑路径 $ pwd -P /var/www/html # 物理路径 ls 介绍（查看目录） 用于显示指定工作目录下的内容 基本语法 1 ls [选项] [路径/文件] 常见选项 -a：显示所有文件（包括隐藏文件） -A：显示除.和..外的所有文件（包括隐藏文件） -l：以详细信息列出文件 -lh：以详细信息列出文件，并以可读的格式显示文件大小（如KB、MB） -t：按修改时间排序（最新优先） -r：反向排序（配合-t、-S等使用） -S：按文件大小排序（大文件优先） -R：递归列出子目录内容 示例 1 2 # 详细出当前目录所有文件（包含隐藏文件） ls -la 1 2 # 按照大小反向排序，并详细列出文件 ls -lShr 1 2 # 递归列出/opt/vmware-tools-distrib/ 及其所有子目录的内容，并显示可读的文件大小（kb） ls -lhR /opt/vmware-tools-distrib/ 1 2 # 仅显示/opt/这个目录的详细信息 ls -ld /opt 1 2 # 按修改时间排序(最新最后) ls -ltr 1 2 # 列出当前目录下所有名称是s开头的文件（最新最后） ls -ltr s* 选项 -l 详解 第一列的字符表示文件或目录的类型和权限。\n- 表示普通文件 d 表示目录 l 表示符号链接 c 表示字符设备文件 b 表示块设备文件 s 表示套接字文件 p 表示管道文件 其余 9 个字符表示文件或目录的访问权限，分别对应三个字符一组的 rwx 权限。\nr 表示读取权限 w 表示写入权限 x 表示执行权限 - 表示没有对应权限 1 2 # 前三个字符表示所有者的权限，中间三个字符表示所属组的权限，后三个字符表示其他用户的权限。 -rw-r--r-- 1 user group 4096 Feb 21 12:00 file.txt 其他常用操作 1 2 # 显示当前目录下最近修改的 5 个文件。 ls -lt | head -5 1 2 # 统计当前目录下的文件数量(不包括隐藏文件)。 ls | wc -l 注意事项 可以通过输出文件颜色，判断文件类型：\n蓝色：目录 绿色：可执行文件 红色：压缩文件 青色：链接文件 黄色：设备文件 cd 介绍（切换目录） 用于改变当前工作目录，切换到指定路径的命令。 基本语法 1 cd dirName dirName：要切换的目标目录，可以是相对路径或绝对路径。 示例 切换绝对路径 1 cd /path/to/directory 切换相对路径：指定相对于当前目录的路径来切换到目标路径 1 cd relative/path/to/directory 切换到/usr/bin/ 目录 1 cd /usr/bin 切换到上级目录 1 cd .. 切换到上上级目录 1 cd ../.. 切换到主目录（home）：使用~表示当前用户的主目录 1 cd ~ 切换到上次访问的目录 1 cd - 切换到环境变量指定的目录 1 cd $VAR_NAME mkdir 介绍（创建目录） 用于创建目录 基本语法 1 mkdir [-p] dirName 示例 在当前目录下创建一个myweb目录 1 mkdir myweb 在var下的www目录下创建一个myweb目录。（若www目录不存在，则自动创建一个） 注：不加-p参数的话，若www目录原本不存在，则会报错\n1 mkdir -p /var/www/myweb rmdir 介绍（删除目录） 用于删除空的目录 基本语法 1 mkdir [-p] dirName 示例 删除当前目录下的myweb空目录 1 rmdir myweb 若myweb不为空目录的话则报错：rmdir: failed to remove ‘myweb/’: Directory not empty\n删除www目录下名为myweb的子目录。若myweb删除后，www目录成为空目录，则www也删除 1 rmdir -p www/myweb 文件指令 touch 介绍（创建文件） 修改文件或目录的时间属性。若文件不存在，则会建立一个新文件 基本语法 1 touch 文件名 示例 创建空白文件index.html 1 touch index.html 将index.html文件的时间属性修改为当前系统时间（index.html存在，且时间不为最新时间） 1 touch index.html 创建多个空白文件 1 touch file1.txt file2.txt cp 介绍（复制文件） 用于复制文件或目录 基本语法 options : 选项 source : 源文件 dest ： 目标文件 1 cp [options] source dest 基本选项 -r 或 -R：递归复制目录及其内容（用于复制目录）。\n-i：交互模式，覆盖前提示用户确认。\n-f：强制复制，覆盖目标文件而不提示。\n-v：显示详细的复制过程（verbose）。\n-p：保留文件的原始属性（如权限、时间戳等）。\n-a：归档模式，等同于 -dpR，保留所有文件属性和递归复制目录。\n-u：仅当源文件比目标文件新时才复制（更新模式）。\n-l：创建硬链接而不是复制文件。\n-s：创建符号链接（软链接）而不是复制文件。\n示例 复制文件到目标目录 1 cp file.txt /path/to/destination 复制文件并重命名 1 cp file.txt /path/to/destination/newfile.txt 递归复制目录 1 2 # 将目录/source_dir及其目录下所有内容，递归复制到/destination目录 cp -r /path/to/source_dir /path/to/destination 交互模式复制 1 cp -i file.txt /path/to/destination 如果目标位置已存在同名文件，会提示用户确认是否覆盖，输入y就表示同意覆盖\n默认有-i选项，不加也行\n保留模式复制 1 cp -p file.txt /path/to/destinatino 复制文件并保留其原始属性（如权限、时间戳等 ）\n创建硬链接或符号链接 1 2 cp -l file.txt /path/to/destination/ # 创建硬链接 cp -s file.txt /path/to/destination/ # 创建符号链接 同时复制多个目标 1 cp *.txt /path/to/destination/ 结合find命令复制特定文件 1 2 # 查找并复制所有 .log 文件到目标目录。 find /path/to/source -name \u0026#34;*.log\u0026#34; -exec cp {} /path/to/destination/ \\; mv 介绍（移动文件【重命名】） 用来为文件或目录改名，或者移动到其他位置 基本语法 1 mv [options] source dest 基本选项 -b: 当目标文件或目录存在时，在执行覆盖前，会为其创建一个备份。 -i: 如果指定移动的源目录或文件与目标的目录或文件同名，则会先询问是否覆盖旧文件，输入 y 表示直接覆盖，输入 n 表示取消该操作。 -f: 如果指定移动的源目录或文件与目标的目录或文件同名，不会询问，直接覆盖旧文件。 -n: 不要覆盖任何已存在的文件或目录。 -u：当源文件比目标文件新或者目标文件不存在时，才执行移动操作。 基本语法 命令格式 运行结果 mv source_file dest_file 将source_file改名为dest_file mv source_file dest_dir 将source_file移动到dest_dir目录下 mv source_dir dest_dir dest_dir存在，将source_dir移动到dest_dir下；dest_dir不存在，则将source_dir改名为dest_dir 示例 将文件aaa改名为bbb 1 mv aaa bbb 将info目录放入logs目录中。（若logs不存在，则将info改名为logs） 1 mv info/ logs 将/var/www/myweb下的所有文件和目录移动到当前目录下 1 mv /var/www/myweb . cat 介绍（查看、追加文件） 用于查看和连接文件 基本语法 1 cat [options] file 基本选项 -n：显示行号，会在输出的每一行前加上行号。 -b：显示行号，但只对非空行进行编号。 -s：压缩连续的空行，只显示一个空行。 -E：在每一行的末尾显示 $ 符号。 -T：将 Tab 字符显示为 ^I。 -v：显示一些非打印字符。 示例 查看文件内容 1 cat file1.txt 输入并覆盖文件内容 1 2 3 4 5 6 $ cat file1.txt abc $ cat \u0026gt; file1.txt 123 $ cat file1.txt 123 追加内容到文件末尾 1 2 3 4 5 6 7 $ cat file1.txt 123 $ cat \u0026gt;\u0026gt; file1.txt 456 $ cat file1.txt 123 456 连接文件，将file1和file2的内容合并到file3中 1 2 3 4 5 6 7 8 9 10 $ cat file1.txt 123 456 $ cat file2.txt iop $ cat file1.txt file2.txt \u0026gt; file3.txt $ cat file3.txt 123 456 iop 显示多个文件的内容 1 cat file1.txt file2.txt 使用管道，将cat的输出作为另一个命令的输入 1 cat filename | command 查看文件的最后3行（使用管道） 1 cat file1.txt | tail -n 3 查看文件并显示行号 1 cat -n file1.txt 查看文件并显示行号（空行不显示） 1 cat -b file1.txt 显示文件，并和连续空行 1 cat -s file1.txt 可以看到上一个的9、10两个空行被并合\n将file3文件的内容加上行号覆盖到file2文件中 1 cat -n file3.txt \u0026gt; file2.txt 显示文件内容，并用$表示行结束 1 cat -e file1.txt 把 file1 和 file2 的内容加上行号（空白行不加）之后将内容加到 file3 最后 1 cat -b file1.txt file2.txt \u0026gt;\u0026gt; file3.txt 清空file2的内容 1 cat /dev/null \u0026gt; file2.txt 使用cat制作镜像 cat 也可以用来制作镜像文件。例如要制作软盘的镜像文件，将软盘放好后输入： 1 cat /dev/fd0 \u0026gt; OUTFILE 相反的，如果想把 image file 写到软盘，输入： 1 cat IMG_FILE \u0026gt; /dev/fd0 head 介绍（查看文件开头） 用于查看文件的开头部分 基本语法 1 head [options] 文件 基本选项 -q : 隐藏文件名 -v : 显示文件名 -c \u0026lt;数目\u0026gt; : 显示的字节数。 -n \u0026lt;行数\u0026gt; : 显示的行数。 示例 显示file1的开头10行。（默认带参-n 10） 1 2 3 head file1.txt # 等价于 head -n 10 file1.txt 显示file1的开头5行 1 head -n 5 file1.txt 显示file1前20个字节 1 head -c 20 file1.txt tail 介绍（查看文件结尾） 查看文件的尾部内容 基本语法 1 tail [options] 文件 基本选项 -f : 循环读取 -q : 不显示处理信息 -v : 显示详细的处理信息 -c \u0026lt;数目\u0026gt; : 显示的字节数 -n \u0026lt;行数\u0026gt; : 显示文件的尾部 n 行内容 --pid=PID : 与-f合用,表示在进程ID,PID死掉之后结束 -q : 从不输出给出文件名的首部 -s : 与-f合用,表示在每次反复的间隔休眠S秒 示例 显示file1的最后10行 1 tail file1.txt 显示file1最后10行，并随file1的更新继续向下显示（常用于跟踪日志文件） 1 tail -f file1.txt 显示file1的内容，从第20行至末尾 1 tail -n +20 file1.txt 显示文件的最后10个字符 1 tail -c 10 file1.txt echo 介绍（显示文本） 在终端显示文本信息 输出变量的值 生成格式化的字符串 向文件追加内容 基本语法 1 echo [option] 字符串 常用选项 -n : 不输出换行符 -e : 启用转义字符解释 -E : 禁用转义字符解释（默认） 示例 输出字符串 1 echo \u0026#34;Hello,World!\u0026#34; 输出变量 1 2 name=\u0026#34;Linux User\u0026#34; echo \u0026#34;Welcome,$name!\u0026#34; 不带引号输出字符串（注意特殊字符） 1 echo Hello,World! -n:禁止换行 1 2 echo -n \u0026#34;Loading...\u0026#34; echo \u0026#34; success!\u0026#34; 结果:\n1 \u0026#34;Loading... success!\u0026#34; -e:启用转义字符 1 echo -e \u0026#34;First line\\nSecond line\u0026#34; 结合转义字符输出彩色文本 1 2 echo -e \u0026#34;\\033[31mRed Text\\033[0m\u0026#34; echo -e \u0026#34;\\033[42;30mGreen Background\\033[0m\u0026#34; 常用转义字符 \\n：换行 \\t：制表符 \\\\：反斜杠 \\a：警报（蜂鸣） 颜色代码 \\033[31m：红色 \\033[32m：绿色 \\033[0m：重置颜色 高级用法 使用重定向将输出保存到文件 \u0026gt; : 覆盖文件 \u0026gt;\u0026gt; : 在末尾追加内容 1 echo \u0026#34;Log entry\u0026#34; \u0026gt;\u0026gt; log.txt 命令替换：输出其他命令的执行结果 1 echo \u0026#34;Current date: $(date)\u0026#34; 格式化输出：结合printf风格的格式化 1 echo -e \u0026#34;Name\\tAge\\n----\\t---\\nAlice\\t25\\nBob\\t30\u0026#34; 简单应用示例 (1)创建简单菜单 1 2 3 4 5 6 7 8 #!/bin/bash echo \u0026#34;============ Menu ============\u0026#34; echo \u0026#34;1. Check system info\u0026#34; echo \u0026#34;2. List directory contents\u0026#34; echo \u0026#34;3. Show current user\u0026#34; echo \u0026#34;4. Exit\u0026#34; echo \u0026#34;==============================\u0026#34; echo -n \u0026#34;Please enter your choice [1-4]: \u0026#34; (2)进度条模拟 1 2 3 4 5 6 7 #!/bin/bash echo -n \u0026#34;Progress: [\u0026#34; for i in {1..20}; do echo -n \u0026#34;#\u0026#34; sleep 0.1 done echo \u0026#34;] Done!\u0026#34; (3)配置文件生成 1 2 3 4 5 6 #!/bin/bash config_file=\u0026#34;app.conf\u0026#34; echo \u0026#34;# Application Configuration\u0026#34; \u0026gt; $config_file echo \u0026#34;LOG_LEVEL=DEBUG\u0026#34; \u0026gt;\u0026gt; $config_file echo \u0026#34;MAX_CONNECTIONS=100\u0026#34; \u0026gt;\u0026gt; $config_file echo \u0026#34;Configuration file $config_file created\u0026#34; sh文件的运行（执行shell脚本） 方法一 1 sh f1.sh 方法二 1 bash f1.sh 方法三 1 ./f1.sh 若出现 -bash: ./f1.sh: Permission denied 则需要授权\n1 2 3 4 5 # 添加可执行权限 chmod +x f1.sh # 添加所有权限 chmod 777 f1.sh 方法四 1 . f1.sh more 介绍 它不会一次性显示整个文件，而是分屏逐页显示，方便查看长文本文件。\n内置快捷键\nh：获得帮助信息 Enter：向下翻滚一行 空格：向下滚动一屏 Ctrl+f：向后滚动一页 Ctrl+b：向前滚动一页 q：退出命令 基本语法 1 more filename 示例 分页显示文件 1 more filename 从文件第n行开始显示 1 more +n filename 显示文件的前n行 1 more -n filename ln 介绍（创建链接） 为某个文件在另个位置建立同步链接\n软连接\n1.软链接，以路径的形式存在。类似于Windows操作系统中的快捷方式 2.软链接可以 跨文件系统 ，硬链接不可以 3.软链接可以对一个不存在的文件名进行链接 4.软链接可以对目录进行链接 硬链接\n1.硬链接，以文件副本的形式存在。但不占用实际空间。 2.不允许给目录创建硬链接 3.硬链接只有在同一个文件系统中才能创建 基本语法 1 ln [options] source dest 基本选项 --backup[=CONTROL] 备份已存在的目标文件 -b 类似 \u0026ndash;backup ，但不接受参数 -d 允许超级用户制作目录的硬链接 -f 强制执行 -i 交互模式，文件存在则提示用户是否覆盖 -n 把符号链接视为一般目录 -s : 软链接(符号链接) -v 显示详细的处理过程 示例 给文件创建软连接，若f1.sh丢失，fufu将失效 1 ln -s f1.sh fufu 给文件创建硬链接 1 ln f1.sh fufu2 fufu2与f1.sh文件属性都相同\n历史指令 history 介绍 记录用户在终端执行的所有命令历史。\n作用：\n追溯操作：查看之前执行过的命令 快速重用：无需重新输入长命令 问题排查：检查系统操作记录 效率提升：通过历史命令快速完成重复工作 基本语法 1 history [options] [parameter] 基本选项 -c : 清除所有历史记录\thistory -c -d : 删除指定位置的历史记录\thistory -d 1005 -a : 立即将内存中的历史写入历史文件\thistory -a -n : 从历史文件中读取未读的历史记录\thistory -n -r : 读取历史文件内容到当前会话\thistory -r -w : 将当前历史记录写入历史文件\thistory -w 示例 常看完整历史记录 1 history 查看最近10条记录 1 history 10 清除所有记录 1 history -c 删除第1010条历史记录 1 history -d 1010 使用技巧 （1）快速执行历史命令 1 2 3 !1024 # 执行历史记录中编号为1024的命令 !! # 重新执行上一条命令 !vim # 执行最近一条以vim开头的命令 （2）搜索历史命令 使用Ctrl+R可以反向搜索历史命令，输入部分关键词即可找到匹配命令\n（3）历史命令替换 1 ^old^new # 将上一条命令中的old替换为new后执行 1 2 $ cat file1.txt $ ^file1^file2 # 相当于执行 cat file2.txt （4）显示命令时间戳 在 ~/.bashrc 中添加以下配置可以显示命令执行时间：\n1 export HISTTIMEFORMAT=\u0026#34;%F %T \u0026#34; 然后执行\n1 source ~/.bashrc 之后 history 命令会显示每条命令的执行时间。\n实际应用场景 找回忘记的命令 1 history | grep \u0026#34;apt install\u0026#34; 统计最常用的命令 1 history | awk \u0026#39;{CMD[$2]++;count++;} END {for (a in CMD)print CMD[a] \u0026#34; \u0026#34; CMD[a]/count*100 \u0026#34;% \u0026#34; a;}\u0026#39; | grep -v \u0026#34;./\u0026#34; | column -c3 -s \u0026#34; \u0026#34; -t | sort -nr | nl | head -n10 备份历史记录 1 2 history -a # 确保最新命令已写入文件 cp ~/.bash_history ~/command_history_backup_$(date +%F).txt 找出最近5条使用yum的命令 1 history | grep yum | tail -5 环境变量配置 通过环境变量可以自定义 history 命令的行为： 变量 说明 推荐值 HISTSIZE 内存中保存的历史命令数量 5000 HISTFILESIZE 历史文件中保存的命令数量 10000 HISTCONTROL 控制历史记录方式 ignoredups:erasedups HISTIGNORE 指定不记录的命令 \u0026ldquo;ls:cd:pwd:exit\u0026rdquo; 示例（添加到 ~/.bashrc 中） 1 2 3 4 5 export HISTSIZE=5000 export HISTFILESIZE=10000 export HISTCONTROL=ignoredups:erasedups export HISTIGNORE=\u0026#34;ls:cd:pwd:exit\u0026#34; export HISTTIMEFORMAT=\u0026#34;%F %T \u0026#34; 注意事项 隐私安全：历史记录可能包含敏感信息（如密码），注意保护 多终端问题：不同终端会话默认不会实时共享历史记录 历史记录丢失：异常退出可能导致命令未保存 大文件处理：过大的历史文件可能影响性能 时间指令 date 介绍（显示时间） 用来显示或设定系统的日期与时间 示例 显示当前时间 1 2 3 4 5 6 7 8 9 10 11 12 # 显示日期 date #显示当前时间 date +%Y #显示当前年份 date +%m #显示当前月份 date +%d #显示当前日份 date \u0026#34;+%Y-%m-%d %H:%M:%S\u0026#34; #显示年月日时分秒 date -s 时间字符串 #修改系统时间，例：2021-4-15 12:00:00 1 cal #显示日历时间 搜索指令 find 介绍 用于在指定目录下查找文件和目录。 基本语法 1 find [path] [condition] [action] 常用参数 -name pattern：按文件名查找，支持使用通配符 * 和 ?。\n-type type：按文件类型查找，可以是 f（普通文件）、d（目录）、l（符号链接）等。\n示例 查找当前目录及其子目录下名为file.txt的文件 1 find . -name file.txt 将当前目录及其子目录下所有文件后缀.c的文件列出来 1 find . -name \u0026#34;*.c\u0026#34; 将当前目录及其子目录中所有文件列出来 1 find . -type f 查找/home目录及其子目录下大于1MB的文件 1 find /home -size +1M 查找/var/www 目录及其子目录下7天前被修改过的文件 1 find /var/www -mtime +7 查找/var/www 目录及其子目录下7天内被访问的文件 1 find /var/www -atime -7 找并执行操作（例如删除）： 这个例子中，-exec 选项允许你执行一个命令，{} 将会被匹配到的文件名替代，\\; 表示命令结束。\n1 find /path/to/search -name \u0026#34;pattern\u0026#34; -exec rm {} \\; locate 介绍 用于查找符合条件的文档。 示例 查找所有带passwd的文件 1 locate passwd 查找/var/www/myweb 下所有file开头的文件 1 locate /var/www/myweb/file 忽略大小写查找/var/www/myweb 下所有f开头的文件 1 locate -i /var/www/myweb/f grep 介绍 用于查找文件里符合条件的字符串或正则表达式 基本语法 1 2 3 4 5 # 语法一 grep [options] pattern [files] # 语法二 comman | grep [options] pattern [files] 示例 1 2 3 4 5 6 7 8 # 显示匹配行及行号 grep -n 查找内容 源文件 # 忽略大小写 grep -i 查找内容 源文件 # cat 查找后的内容用grep查找某个内容 cat 源文件 | grep 查找内容 压缩和解压 tar 介绍 用于打包和解压文件 基本语法 -f archive.tar：指定归档文件的名称。 [files\u0026hellip;]：要打包的文件和目录。 1 tar [options] -f archive.tar [files...] 基本选项 -c：创建一个新的归档文件。 -x：解压归档文件。 -t：列出归档文件的内容。 -r：向现有归档文件中追加文件。 -u：仅追加比归档文件中已有文件更新的文件。 -d：找到归档文件中与文件系统不同步的差异。 -A：将一个 .tar 文件追加到另一个 .tar 文件中。 示例 创建归档文件 : 将文件file1、file2和dir打包到一个名为arc.tar的归档文件中\n-c: 创建新的归档文件 -v: 显示详细输出，列出被添加到归档中的文件 -f: 指定归档文件的名称 1 tar -cvf arc.tar file1 file2 dir 解压归档文件：解压名为 archive.tar 的归档文件，还原其中包含的文件和目录。\n-x: 解压归档文件 -v: 显示详细输出，列出被解压的文件 -f: 指定要解压的归档文件的名称 1 tar -xvf archive.tar 压缩归档文件：将名为 directory 的目录打包成一个归档文件，然后使用 gzip 进行压缩，生成名为 archive.tar.gz 的文件。\n-c: 创建新的归档文件 -z: 使用 gzip 压缩归档文件 -v: 显示详细输出，列出被添加到归档中的文件 -f: 指定归档文件的名称 1 tar -czvf archive.tar.gz directory 列出归档文件中的内容：列出名为 archive.tar 的归档文件中包含的所有文件和目录。\n-t: 列出归档文件中的内容 -v: 显示详细输出，列出归档文件中的所有文件和目录 -f: 指定要列出内容的归档文件的名称 1 tar -tvf archive.tar 追加文件到已存在的归档中：将名为 newfile 的文件添加到已存在的名为 archive.tar 的归档文件中。\n-r: 向已存在的归档中追加文件 -v: 显示详细输出，列出被添加到归档中的文件 -f: 指定已存在的归档文件的名称 1 tar -rvf archive.tar newfile 创建一个经过 gzip 压缩的归档文件：打包 directory 目录下的所有文件和子目录，并使用 gzip 压缩，生成名为 archive.tar.gz 的归档文件。\n-z: 表示要使用 gzip 进行压缩。 -c: 表示创建新的归档文件。 -v: 表示详细输出，列出被添加到归档中的文件。 -f: archive.tar.gz: 指定归档文件的名称为 archive.tar.gz。 1 tar -zcvf archive.tar.gz directory 解压一个已经被 gzip 压缩的归档文件：解压 example.tar.gz 文件，并在当前目录下恢复其中包含的文件和目录。\n-z: 表示要使用 gzip 解压归档文件。 -x: 表示解压操作。 -v: 表示详细输出，列出被解压的文件。 -f: example.tar.gz: 指定要解压的归档文件的名称为 example.tar.gz。 1 tar -zxvf example.tar.gz 其他命令 详情请看：Linux命令大全\n","date":"2025-09-27T23:10:09+08:00","permalink":"https://YLine-hub.github.io/p/linux%E5%B8%B8%E7%94%A8%E6%8C%87%E4%BB%A4/","title":"Linux常用指令"},{"content":"CentOS7.6找回密码 通过单用户模式修改root密码，因为单用户模式不需要账号登陆\n在开机界面时按下e，进入编辑模式 在截图位置，添加rw single init=/bin/bash，然后按ctrl+x引导系统，进入单用户模式 然后输入passwd来重置root密码 1 passwd 在此处分别输入两次新密码，这里不会有东西显示。\n其中乱码部分是因为设置的系统为中文，这里无法显示。\n若是英文的话，修改成功以后这里会显示successfully 输入touch /.autorelabel更新selinux信息 1 touch /.autorelabel 运行exec /sbin/init来重启系统 1 exec /sbin/init 重新用新密码登陆即可 ","date":"2025-09-27T17:37:30+08:00","permalink":"https://YLine-hub.github.io/p/centos7.6%E6%89%BE%E5%9B%9E%E5%AF%86%E7%A0%81/","title":"CentOS7.6找回密码"},{"content":"日语翻译 各种小写输入方法 ぇ、ェ： l（小写L） + e\nぃ、ィ： l（小写L） + i\nぉ、ォ： l（小写L） + o\nXshell 输入gnome-session -version时出现弹窗 生词 転送（てんそう）：转送 要求（ようきゅう）：要求 処理（しょり）：处理 ソフトウェア：software 软件 インストール：install 安装 プログラム：program 程序；计划；节目 実行（じっこう）：实行 直接（ちょくせつ） 体験版（たいけんばん） ダウンロード：download 下载 セッション：session / ˈseʃ(ə)n / 会话；会议；会期 プロパティ：property / ˈprɑːpərti / 属性；特性；财产 接続（せつぞく）：连接 トンネリング：tunneling / ˈtʌnlɪŋ / n、隧道效应；开挖隧道 ページ：page 页；页面 オフ：off 关闭；休息 オプション：option / ˈɑːpʃ(ə)n / 选择 メッセージ：message　信息；消息；短信 フォワーディング： forwarding 转发 フォワード： forward / ˈfɔːrwərd / 转发 翻译的句子 X11転送要求を処理するには、Xmanagerソフトウェアが必要です。 Xmanagerをインストールすると、Xtermやgonome-terminalなどのX11プログラムをXshellから実行し、Windowsで直接使用することができます。 Xmanager体験版を今すぐダウンロードしますか？ （セッションプロパティ　-\u0026gt; 接続　-\u0026gt; SSH -\u0026gt;　トンネリングページでX11転送オプションをオフにすることで、このメッセージをオフにすることができます）\n翻译 对于处理X11的转发请求，Xmanager软件是必须的。 安装Xmanager就能直接在windows中使用，通过Xshell运行Xterm、gonome-terminal等X11程序。 现在马上下载Xmanager体验版吗？ （在 会话属性-\u0026gt;连接-\u0026gt;SSH-\u0026gt;开启隧道页面 中 用关闭X11转发选项，能够关闭这个消息）\n关闭该消息 右键プロパティ 点击トンネリング 关闭X11转发 再次输入没有信息弹出 Xshell的重新连接 重新连接服务器 1 reconnect VMware 点击下面叉叉关闭虚拟机时 生词 パワーオン：power on 仮想（かそう）：虚拟；假想 マシン：machine 机器；机械 引き続き（ひきつづき）：继续；连续 バックグラウンド：background 背景；幕后 サスペンド：suspend 暂停；中止；悬挂 语法 Vた後で：之后；然后；之后接着 ～たり～たり：又\u0026hellip;又\u0026hellip;；或\u0026hellip;或\u0026hellip;；有时\u0026hellip;有时\u0026hellip; 翻译的句子 「Centos　test」は現在パフーオン状態です。 仮想マシンを引き続きバックグラウンドで実行したり、サスペンドした後で使用したり、今すぐパフーオフしたりできます。 サスペンド パフーオフ バックグラウンドで実行 キャンセル\n翻译 centos test现在时开机状态。 能够继续在幕后运行虚拟机，或者现在暂停之后再使用，或者现在马上关机。 暂停 关机 挂起运行 取消\n安全中心添加排除项 生词 プライバシー：privacy 隐私；私密 セキュリティ：security 安全；防护 ウイルス：virus 病毒 脅威（きょうい）：威胁 防止（ぼうし）：防止；预防 除外（じょがい）：排除；不包括；例外 追加（ついか）：增加；追加；补充 削除（さくじょ）：删除；消除；取消 項目（こうもく）：项目 デバイス：device 设备 脆弱（ぜいじゃく）：脆弱；易碎；不牢固 含む（ふくむ）：包含 スキャン：扫描；浏览；审查 操作 打开设置 按win键，在搜索栏中输入：設定（せってい） 打开设置，点击：プライバシーとセキュリティ 点击：Windows セキュリティ 点击：Windows セキュリティを開く，打开windows安全中心 在Windows　セキュリティ中，点击：ウイルスと脅威の防止 点击ウイルスと脅威の防止の設定下的設定の管理 找到除外，点击下面的除外の追加または削除 点击除外の追加来添加排除项 翻译的句子 除外 Microsoft Defender ウイルス対策は、除外されたアイテムをスキャンしません。除外された項目には、デバイスを脆弱にする脅威が含まれている可能性があります。 除外の追加または削除\n翻译 排除项 Microsoft Defender 应对病毒是不会扫描排除的项目。对排除的项目来说，可能包含使设备脆弱的威胁。 增加或删除排除项\n","date":"2025-09-27T14:31:19+08:00","permalink":"https://YLine-hub.github.io/p/%E7%94%B5%E8%84%91%E6%97%A5%E8%AF%AD%E5%8C%96%E4%BD%BF%E7%94%A8-%E6%97%A5%E8%AF%AD%E7%BF%BB%E8%AF%91/","title":"电脑日语化使用 日语翻译"},{"content":"Linux入门 Linux简介 介绍 linux是一个开源、免费的操作系统，其稳定性、安全性、处理多并发已经得到业界的认可，目前很多中型，大型甚至是集群项目都在使用linux，很多软件公司考虑到开发成本都首选linux，在中国软件公司得到广泛的使用。 Linux发行版 Ubuntu Fedora Debian Arch Linux Suse CentOS RedHat 国产： Deepin Ubuntu Kylin StartOS Nova Linux网络连接方式 桥接模式（Bridge Mode） 将虚拟机直接连接到宿主机所在的物理网络中，虚拟机拥有与宿主机相同的网络环境。\n特点\n虚拟机与宿主机处于同一网段。 虚拟机拥有独立的真实IP地址。 虚拟机可以直接与外部网络通信。 优点：\n处于同一网段，虚拟系统可以和处于同网段的外部系统通讯。\n支持高级网络功能，如VLAN、QoS和安全策略。\n缺点：\n容易造成IP冲突，因为同一个网段最多255个IP地址。\n缺乏隔离，可能导致不必要的广播流量和潜在的安全风险。\n示例\n假设宿主机的IP地址为192.168.1.10，虚拟机的IP地址为192.168.1.22，两者处于同一网段。\n1 2 # 桥接模式下虚拟机的网络配置 ifconfig eth0 192.168.1.22 netmask 255.255.255.0 NAT模式（Network Address Translation） NAT模式通过宿主机的IP地址与外部网络通信，虚拟机的IP地址由宿主机的虚拟网络提供。\n特点\n虚拟机与宿主机不在同一网段。 虚拟机通过宿主机的网关访问外部网络。 外部网络无法直接访问虚拟机。 优点：\n简化网络管理，避免IP冲突。\n提供了一定的安全性，因为内部网络与外部网络隔离。\n缺点：\n内部设备无法直接被外部访问。\n可能会增加网络延迟，因为需要进行地址转换。\n示例\n假设宿主机的IP地址为192.168.1.10，虚拟机的IP地址为192.168.2.3。\n1 2 # NAT模式下虚拟机的网络配置 ifconfig eth0 192.168.2.3 netmask 255.255.255.0 主机模式（Host-Only Mode） 主机模式下仅允许虚拟机与宿主机之间的通信，无法直接访问外部网络。\n特点\n虚拟机与宿主机处于同一网段。 虚拟机无法直接访问外部网络。 适用于隔离环境的开发和测试场景。 优点：\n提供了一个与物理网络隔离的虚拟网络环境，适合用于开发和测试。\n提高了安全性，因为虚拟机无法直接访问外部网络。\n缺点：\n无法直接访问外部网络，需要通过宿主机进行代理或路由。 示例\n假设宿主机的IP地址为192.168.56.1，虚拟机的IP地址为192.168.56.101。\n1 2 # 仅主机模式下虚拟机的网络配置 ifconfig eth0 192.168.56.101 netmask 255.255.255.0 Linux目录结构 树状目录结构 Linux文件系统采用层级式树状目录结构，在此结构中的最上层是根目录”/“，然后再次目录下创建其他目录。 Linux的基本理念：一切皆文件 目录介绍 /dev：（Device）存放Linux的外部设备，将硬件以文件的形式存放在该目录下。\n/lib：（Library）存放着系统最基本的动态连接共享库，类似于 Windows 里的 DLL 文件。\n/selinux：Redhat/CentOS特有的目录，Selinux是一个安全机制，类似windows的防火墙，但是这套机制比较复杂，这里存放selinux的相关文件。\n/tmp：（temporary）存放临时文件。\n/lost+found：一般是空的，当系统非法关机后，这里就存放了一些文件。\n/run：临时文件系统，存储系统启动以来的信息。重启时，这个目录下的文件应该被删掉或清除。/var/run 目录，应该让它指向 run。\n重要且尽量别动 /etc：（Etcetera）存放系统管理的配置文件和子目录。\n/bin：（Binaries） 存放常用命令。\n/sbin：（Superuser Binaries）存放超级管理员使用指令。\n/usr/bin：系统用户使用的命令。\n/usr/sbin：超级用户使用的比较高级的管理程序和系统守护程序。\n重点目录 /boot：存放启动Linux时的一些核心文件，包括连接文件以及镜像文件。\n/home：用户主目录，在 Linux 中，每个用户都有一个自己的目录，目录名为用户账号名。\n/media：自动识别U盘、光驱等设备，识别后会挂载到这个目录下。\n/mnt：让用户临时挂载别的文件系统的，可以将光驱挂载在/mnt/ 上。\n/opt：（optional）给主机安装软件的目录。\n/root：超级权限者的用户主目录。\n/usr：（unix system resources）用户的很多应用程序和文件都放在这个目录下，类似于windows的program files目录。\n/usr/src：内核源代码默认的放置目录。 /var：（variable）存放经常修改的数据。如日志文件。\n以下目录尽量别动 /sys：Linux2.6内核后出现了新文件系统 sysfs 。\nsysfs 集成了3种文件系统的信息：针对进程信息的 proc 、针对设备的 devfs 、针对伪终端的 devpts 。\n/srv：存放一些服务启动之后需要提取的数据。\n/proc：（Processes）存储当前内核运行状态的特殊文件，是一个虚拟的目录，是系统内存的映射，可以通过访问这个目录来获取系统信息。\n该目录的内容在内存里，也可以直接修改其中某些文件，如可以通过下面的命令来屏蔽主机的ping命令： 1 echo 1 \u0026gt; /proc/sys/net/ipv4/icmp_echo_ignore_all Linux的运行级别 常用单词 rescue / ˈreskjuː / v、n、营救； multi / ˈmʌlti / pref、多 graphical / ˈɡræfɪkl / adj、绘画的；计算机图形的 isolate / ˈaɪsəleɪt / v、孤立，分离；单独考虑 adj、孤独的，孤立的 systemctl （ctl是 control 的缩写） 运行级别分类 运行级别 说明 适用环境 0 关机poweroff.target 系统关闭时使用 1 单用户模式rescue.target 系统维护或故障修复时使用（找回丢失密码） 2 多用户无网络模式 适用于网络功能不重要的场景 3 多用户有网络模式（常用）multi-user.target 适用于服务器环境 4 未定义（通常由系统自定义） 由系统或用户自定义功能 5 图形界面模式（常用）graphical.target 适用于桌面环境 6 重启reboot.target 系统重启时使用 运行级别配置文件：/etc/inittab (旧版本) 运行级别配置文件：/lib/systemd/system目录下的xxx.target文件(CentOS7以上) 常见Linux运行级别差异 系统版本 运行级别0 运行级别1 运行级别2 运行级别3 运行级别4 运行级别5 运行级别6 CentOS 7 关机 单用户模式 多用户模式 多用户模式 多用户模式 图形界面模式 重启 Ubuntu 关机 单用户模式 多用户模式 多用户模式 未定义 图形界面模式 重启 Slackware 关机 单用户模式 多用户模式 图形界面模式 未定义 未定义 重启 运行级别相关指令 查看当前运行级别 1 2 3 4 5 # 查看当前运行级别 runlevel # 查看默认运行级别（CentOS7以上） systemctl get-default 切换运行级别 1 2 3 4 5 6 7 # 适用于老旧系统 init 3 # 切换到运行级别3，字符界面 init 5 # 切换到运行级别5，图形界面 # 适用于现代系统 （CentOS7以上） systemctl isolate multi-user.target # 切换到运行级别3 systemctl isolate graphical.target # 切换到运行级别5 切换图形界面 切换图形界面 1 systemctl isolate graphical.target 发现并没有切换过去\n查看是否安装 1 rpm -qa | grep gnome-desktop 安装图形化界面 1 yum groupinstall \u0026#34;GNOME Desktop\u0026#34; \u0026#34;Graphical Administration Tools\u0026#34; 再次切换到图形化界面 1 systemctl isolate graphical.target 虚拟机已经成功切换到图形界面\n如果要设置默认启动图形化界面 1 systemctl set-default graphical.target ","date":"2025-09-26T17:30:21+08:00","permalink":"https://YLine-hub.github.io/p/linux%E5%85%A5%E9%97%A8/","title":"Linux入门"},{"content":"Centos打开80端口 查看端口是否开启 1 firewall-cmd --query-port=80/tcp 开启80端口，permanent永久，重启以后端口还会开启，若不加的话，重启以后端口要重新打开 单词：permanent / ˈpɜːrmənənt / adj.永久的 \u0026ndash;zone=public 指的是，指定添加服务的区域名称为public\n1 firewall-cmd --zone=public --add-port=80/tcp --permanent 关闭80端口命令 1 firewall-cmd --zone=public --remove-port=80/tcp --permanent 重启防火墙，要重启防火墙后开启端口才会生效 1 firewall-cmd --reload ","date":"2025-09-26T17:22:53+08:00","permalink":"https://YLine-hub.github.io/p/centos%E6%89%93%E5%BC%8080%E7%AB%AF%E5%8F%A3/","title":"Centos打开80端口"},{"content":"VMware的Centos安装VMwareTools VMwareTools镜像准备 （1）VMware Tools 安装VMware Tools VMware安装VMTools的DVD 点击设置 添加一个DVD 使用VMware Tools镜像 启动centos 将VMTools挂载在虚拟机上 观察磁盘分区 1 lsblk 发现VMTools在磁盘sr0上\n创建一个目录作为挂载点 1 mkdir /media/dvd 将dvd挂载到创建的目录下 1 mount /dev/sr0 /media/dvd 查看dvd中的内容 1 ll /media/dvd 成功挂载到dvd目录下\n安装 将VMwareTools-10.3.26-22085142.tar.gz，复制到/opt目录下并命名为vm.tar.gz 1 cp /media/dvd/VMwareTools-10.3.26-22085142.tar.gz /opt/vm.tar.gz 在/opt目录下查看文件，并解压vm.tar.gz 1 2 3 cd /opt ll tar -zxvf vm.tar.gz 进入vmware-tools-distrib目录，并输入./vmware-install.pl尝试安装 1 2 3 cd vmware-tools-distrib/ ll ./vmware-install.pl 出现报错：-bash: ./vmware-install.pl: /usr/bin/perl: bad interpreter: No such file or directory，表明未安装编译环境\n安装编译环境 1 yum -y install perl gcc make kernel-headers kernel-devel 安装完成后再次尝试安装，安装时一直回车即可 1 ./vmware-install.pl 出现问题：The path \u0026quot;\u0026quot; is not a valid path to the 3.10.0-693.el7.x86_64 kernel headers\nctrl+c退出安装，使用yum更新再次重新安装 1 2 yum -y update ./vmware-install.pl 安装完成后，可以通过以下命令检查 VMware Tools 是否正常运行： 1 vmware-toolbox-cmd -v ","date":"2025-09-26T16:24:54+08:00","permalink":"https://YLine-hub.github.io/p/vmware%E7%9A%84centos%E5%AE%89%E8%A3%85vmwaretools/","title":"VMware的Centos安装VMwareTools"},{"content":"使用yum进行安装软件时出现报错：curl#6 - \u0026ldquo;Could not resolve host: mirrorlist.centos.org; Unknown error\u0026rdquo; 备份默认源文件 1 2 sudo mkdir -p /etc/yum.repos.d/backup sudo mv /etc/yum.repos.d/CentOS-*.repo /etc/yum.repos.d/backup/ 下载阿里云源文件 1 2 3 4 5 # 基础源文件 sudo curl -o /etc/yum.repos.d/CentOS-Base.repo https://mirrors.aliyun.com/repo/Centos-7.repo # 下载EPEL扩展源（可选） sudo curl -o /etc/yum.repos.d/epel.repo https://mirrors.aliyun.com/repo/epel-7.repo 清理并重建yum缓存 1 2 yum clean all yum makecache fast 检验是否更新，查看仓库列表 1 sudo yum repolist 再次安装已经能正常安装 ","date":"2025-09-26T16:12:03+08:00","permalink":"https://YLine-hub.github.io/p/linux%E6%9B%B4%E6%8D%A2yum%E6%BA%90%E4%B8%BA%E9%98%BF%E9%87%8C%E4%BA%91%E6%BA%90/","title":"Linux更换yum源为阿里云源"},{"content":"创建第一个Centos虚拟机 软件准备 （1）VMware Download VMware Workstaion Pro（Win/Linux）\nVMware Fusion (Mac) （2）Centos 7.6 ISO （清华源） （3）xshell 创建虚拟机 创建虚拟机 自定义（高级） 之后选择iso 选择Linux3.x\nCentos 7系列对应Linux3.x\nCentos 8系列对应Linux4.x\n设置虚拟机名和安装路径 选择2核2G 选择15G最大容量 初次开机前先对虚拟机进行设置 不需要声音就将其移除即可 CD/DVD选择自己下载的Centos7.6 iso镜像 点击ok后启动 安装Centos 选择安装Centos 选择自己需要的语言并进入 设置时间 设置分区 点击自己配置，后点击Done 配置后点击Done，然后点击接受改变 配置网络 注意记住ip，若没记住进入虚拟机后输入hostname -i 也可也查询ip 配置完成，点击安装 在等待安装时，分别设置root用户密码和第一个用户账户 创建好账号以后就可以等待安装了 安装完成后点击重启 xshell 远程连接centos 进入Centos后查询ip 1 hostname -i 在xshell中点击新建 输入服务器名称和ip后点击连接 点击保存 输入用户名和密码 连接成功 ","date":"2025-09-26T15:04:30+08:00","permalink":"https://YLine-hub.github.io/p/%E5%88%9B%E5%BB%BA%E7%AC%AC%E4%B8%80%E4%B8%AAcentos%E8%99%9A%E6%8B%9F%E6%9C%BA/","title":"创建第一个Centos虚拟机"},{"content":"github自动部署 创建新的仓库-项目主仓库 创建项目主仓库，存放项目源码，并将其设置为私有仓库 将不需要上传的文件忽略 在根目录下创建文件.gitignore\n1 2 3 4 public resources .hugo_build.lock hugo.exe 上传程序代码 1 2 3 4 5 6 git init git add . git commit -m \u0026#34;first commit\u0026#34; git branch -M main git remote add origin https://github.com/YLine-hub/hugo-dev.git git push -u origin main 移除错误上传文件 突然发现多上传了hugo.exe，这时候就需要将它移除\n移除hugo.exe 1 git rm --cached hugo.exe 重新提交代码并推送 1 2 git commit -m \u0026#34;移除hugo.exe\u0026#34; git push -u origin main 自动部署 官方文档：hugo:Host on GitHub Pages\n(1)前往Settings -\u0026gt; Developer Settings -\u0026gt; Personal access tokens，创建一个token，用于上面传到仓库\n(2)设置无限时间，作用范围选择repo和workflow (3)之后点击生成，获取token (4)使用注入变量注入token\n到项目仓库下，点击Settings 点击Secrets and variables，里面的Actions 创建一个新的环境变量TOKEN (5)在hugo主文件创建一个.githubb/workflows/xxxx.yaml文件，将以下内容复制进入，具体详情：查看【Github Action文档】\nhugo_deploy.yaml\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 name: deploy # 代码提交到main分支时触发github action on: # 监听，当推送到分支main时将会自动触发 push: branches: - main jobs: deploy: runs-on: ubuntu-latest # 运行在ubuntu的最新版本上 steps: # 运行了四个脚本 - name: Chekout uses: actions/checkout@v4 # 比如该脚本来自 https://github.com/actions/checkout with: fetch-depth: 0 - name: Setup Hugo uses: peaceiris/actions-hugo@v3 with: hugo-version: \u0026#34;latest\u0026#34; # 安装的版本为最新 extended: true # 并且带有extended - name: Build Web # 生成静态页面 run: hugo -D # 生成脚本 - name: Deploy Web # 部署到静态页面仓库 uses: peaceiris/actions-gh-pages@v4 with: PERSONAL_TOKEN: ${{ secrets.你的token变量名 }} EXTERNAL_REPOSITORY: 你的github名/你的仓库名 PUBLISH_BRANCH: main PUBLISH_DIR: ./public commit_message: auto deploy # 提交信息 配置以下信息 1 2 3 4 5 6 7 8 9 10 jobs: ...... - name: Deploy Web # 部署到静态页面仓库 uses: peaceirls/actions-gh-pages@v4 with: PERSONAL_TOKEN: ${{ secrets.TOKEN }} EXTERNAL_REPOSITORY: YLine-hub/YLine-hub.github.io PUBLISH_BRANCH: main PUBLISH_DIR: ./public commit_message: auto deploy # 提交信息 提交代码 1 2 3 git add . git commit -m \u0026#34;update\u0026#34; git push 查看仓库是否运行了代码 运行失败，发现仓库名打错了，重新输入并上传 再次进入action，代码正在运行 运行成功以后，对本地和线上页面进行比较，发现还没更新 查看仓库以后，发现原来设置的仓库错了 恢复仓库 (1)查看历史版本 1 git relog/log (2)强制回滚历史版本 1 git reset 82c1130af45eeee3930b3d2e403458282f9f0296 (3)提交 1 git push origin main --force --force 为强制提交\n仓库回到历史版本\n(4)修改完代码以后重新提交，修改成功 ","date":"2025-09-25T19:34:37+08:00","permalink":"https://YLine-hub.github.io/p/github%E8%87%AA%E5%8A%A8%E9%83%A8%E7%BD%B2hugo/","title":"github自动部署hugo"},{"content":"stack自主配置 注：官方文档：stack-config\n核心配置文件hugo.yaml 语言配置 1 2 3 4 # Theme i18n support # Available values: ar, bn, ca, de, el, en, es, fr, hu, id, it, ja, ko, nl, pt-br, th, uk, zh-cn, zh-hk, zh-tw // 设置默认中文 DefaultContentLanguage: zh-cn 刷新后，界面默认变成中文\n建议：若默认语言为中文时，设置为true 1 2 3 # Set hasCJKLanguage to true if DefaultContentLanguage is in [zh-cn ja ko] # This will make .Summary and .WordCount behave correctly for CJK languages. hasCJKLanguage: true 配置国际化语言 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 languages: en: languageName: English title: Example Site weight: 1 params: sidebar: subtitle: Example description zh-cn: languageName: 中文 title: 演示站点 weight: 2 params: sidebar: subtitle: 演示说明 ar: languageName: عربي languagedirection: rtl title: موقع تجريبي weight: 3 params: sidebar: subtitle: وصف تجريبي 目前我只留下中文，同时国际化选项被去除 1 2 3 4 5 6 7 8 languages: zh-cn: languageName: 中文 title: 演示站点 weight: 2 params: sidebar: subtitle: 演示说明 该处title和subtitle分别能够修改这两处 1 2 3 4 5 6 7 8 languages: zh-cn: languageName: 中文 title: りんぼの個人ブログ weight: 2 params: sidebar: subtitle: 每天都要努力学习 设置图标\n推荐站点：free icons 下载以后，将图标名称改为favicon.ico，并将其放在static文件夹下 配置图标路径 1 2 3 params: ...... favicon: ./favicon.ico # e.g.: favicon placed in `static/favicon.ico` of your site folder, then set this field to `/favicon.ico` (`/` is necessary) 配置完后使用ctrl+f5进行强制刷新，就能看到图标出现了 日期格式化配置 当前日期格式:\n1 2 3 dateFormat: published: Jan 02, 2006 lastUpdated: Jan 02, 2006 15:04 MST 若要改成yyyy-MM-dd格式，只需要如下设置\n1 2 3 dateFormat: published: 2006-01-02 lastUpdated: Jan 02, 2006 15:04 MST 配置emoji 1 2 3 sidebar: emoji: 🏖️ ...... 设置头像 由于150x150的尺寸，不过由于自动缩放，所以只需要找等比例头像即可，将原先的头像名称复制给他并，放在dev/assets/img文件夹下 这时，头像也变成自己需要的头像\n关闭阅读时间和license 1 2 3 4 5 6 7 article: math: false toc: true readingTime: false # 关闭阅读时间啊 license: enabled: false # 关闭license default: Licensed under CC BY-NC-SA 4.0 关闭评论 单词：disqus(读作discuss) 留言功能， discuss 讨论，utterance 言论；表达\n1 2 3 comments: enabled: false # 关闭评论 provider: disqus 关闭标签云 1 2 3 4 5 6 7 8 9 10 11 12 13 14 widgets: homepage: - type: search # 搜索 - type: archives params: limit: 5 - type: categories # 分类 params: limit: 10 # - type: tag-cloud # params: # limit: 10 page: - type: toc 关闭github与twitter，等后期需要再加上 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 ### Custom menu ### See https://stack.jimmycai.com/config/menu ### To remove about, archive and search page menu item, remove `menu` field from their FrontMatter # 注释掉，目前没啥用 # menu: # main: [] # social: # - identifier: github # name: GitHub # url: https://github.com/CaiJimmy/hugo-theme-stack # params: # icon: brand-github # - identifier: twitter # name: Twitter # url: https://twitter.com # params: # icon: brand-twitter 若需要这块功能的图标可以在：https://tabler.io/icons 找\n创建第一篇文章 所有文章放在/dev/content/post下\n创建第一篇文章 1 hugo new content post/myFirstBlog/index.md 创建后自动在文件夹中生成\n","date":"2025-09-25T16:19:14+08:00","permalink":"https://YLine-hub.github.io/p/stack-config/","title":"Stack Config"},{"content":"hugo+github搭建博客 下载hugo 进入hugo官网：hugo 点击github 找到历史版本 下载windows版本 (hugo_extended_0.151.0_windows-amd64.zip) 安装hugo 将下载的压缩包解压 在当前目录下打开cmd 创建项目 1 hugo new site dev 将hugo.exe复制到文件夹内 使用cmd进入文件夹中 1 cd dev 启动服务 1 hugo server -d 打开链接 http://localhost:1313/\n安装主题 在官网点击Themes 选择自己喜欢的主题并下载 将文件放在根目录下的themes文件夹中并解压 exampleSite为样例文件夹 将里面的content和hugo.yaml复制到根目录下 删去post下的rich-content文件夹，原因：其中引用的youtube中的视频，会导致超时 打开配置文件 hugo.yaml 删去配置文件hugo.toml\n根据主题名字修改文件夹名 重启服务 上传github 在github创建仓库 在hugo.yaml修改基础路径 重新生成一下文件 1 hugo -D 在根目录下生成的public，就是我们需要的生成的静态目录 命令行进入public文件夹下 根据github提供的命令上传文件 1 2 3 4 5 6 git init // 初始化git git add . // 将全部添加到本地仓库 git commit -m \u0026#34;first commit\u0026#34; // 提交 git branch -M main // 设置main git remote add origin https://github.com/YLine-hub/YLine-hub.github.io.git // 设置仓库地址 git push -u origin main // 推送到仓库 推送时出现报错，连接服务器失败 原因：经过查阅资料后，发现这是由于在使用 Git 时启用了网络代理，导致 Git 改变了默认端口，从而无法连接到 GitHub。因此，我们需要手动配置 Git 的代理端口来解决该问题。\n查看代理端口 \u0026ndash; 在wifi下，选择proxy \u0026ndash; 选择使用一个代理服务器后的set up \u0026ndash; 找到代理端口 打开命令行\n打开命令行（如 CMD 或 Git Bash），输入以下命令为 Git 配置 HTTP 和 HTTPS 的代理：\n1 2 git config --global http.proxy http://127.0.0.1:7890 git config --global https.proxy http://127.0.0.1:7890 再次提交代码 再次出现报错\n打开魔法，之后再次提交 使用账号登陆 双重验证 连接 同时代码上传成功 打开github，发现代码正常 开启静态页面 点击setting下的pages 选择主分支下的root，并点击保存 出现地址，就说明已经成功了 使用该链接就能进入网站中 ","date":"2025-09-25T15:58:33+08:00","permalink":"https://YLine-hub.github.io/p/hugo-github%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2/","title":"hugo+github搭建博客"}]